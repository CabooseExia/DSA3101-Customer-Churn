{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries & Data Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "np.random.seed(3101)\n",
    "random_state = np.random.RandomState(3101)\n",
    "fake = Faker()\n",
    "pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df_train = pd.read_csv('./data/main/train.csv')\n",
    "n_train = bank_df_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Irrelevant Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df_train = bank_df_train.drop([\"id\", \"CustomerId\", \"Surname\", \"CreditScore\", \"Geography\", \"HasCrCard\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing given columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed those with 0 balance and used Normal dist from the remaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0 entries in 'Balance': 0.00%\n",
      "count   165034.000000\n",
      "mean    121351.823171\n",
      "std      24958.566254\n",
      "min         18.330000\n",
      "25%     104784.230000\n",
      "50%     121798.530000\n",
      "75%     137853.000000\n",
      "max     250898.090000\n",
      "Name: Balance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "zero_count = (bank_df_train['Balance'] == 0).sum()\n",
    "total_count = len(bank_df_train)\n",
    "zero_percentage = (zero_count / total_count) * 100\n",
    "\n",
    "print(f\"Percentage of 0 entries in 'Balance': {zero_percentage:.2f}%\")\n",
    "\n",
    "non_zero_data = bank_df_train.loc[bank_df_train['Balance'] != 0, 'Balance']\n",
    "mean_non_zero = non_zero_data.mean()\n",
    "std_non_zero = non_zero_data.std()\n",
    "\n",
    "zero_indices = bank_df_train.index[bank_df_train['Balance'] == 0]\n",
    "num_zeros = len(zero_indices)\n",
    "random_samples = np.random.normal(loc=mean_non_zero, scale=std_non_zero, size=num_zeros)\n",
    "bank_df_train.loc[zero_indices, 'Balance'] = random_samples\n",
    "\n",
    "print(bank_df_train['Balance'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bank_df_train['Balance'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Balance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Balance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to int type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df_train['Age'] = bank_df_train['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KIV: Tenure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14573901 0.14650078 0.61684768 ... 0.63779928 0.3787059  0.12594681]\n",
      "0      5\n",
      "1      1\n",
      "2     19\n",
      "3      4\n",
      "4      9\n",
      "5      8\n",
      "6     14\n",
      "7      2\n",
      "8      8\n",
      "9      8\n",
      "10    10\n",
      "11     5\n",
      "12    17\n",
      "13    10\n",
      "14    12\n",
      "15    10\n",
      "16    12\n",
      "17     7\n",
      "18    14\n",
      "19     1\n",
      "Name: Tenure, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "aug_2022 = datetime(2022, 8, 31) #when GXS opened \n",
    "today = datetime.now()\n",
    "months_since_aug_2022 = (today.year - aug_2022.year) * 12 + today.month - aug_2022.month - 2\n",
    "def scale_int_to_months(int_val):\n",
    "    return int_val * (months_since_aug_2022 / 10)\n",
    "bank_df_train['Tenure'] = bank_df_train['Tenure'] * (months_since_aug_2022 / 10)\n",
    "bank_df_train['Tenure'] = bank_df_train['Tenure'].astype(int)\n",
    "\n",
    "random_numbers = np.random.rand(n_train)\n",
    "threshold = 0.5\n",
    "print(random_numbers)\n",
    "bank_df_train.loc[random_numbers > threshold, 'Tenure'] += 1\n",
    "\n",
    "print(bank_df_train['Tenure'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customer Id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_id = np.arange(1,n_train+1,1)\n",
    "bank_df_train['CustomerId'] = cust_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KIV: Churn Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KIV: Months Inactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transaction Freq & Amt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df = pd.read_csv('./data/Daily Household Transactions.csv')\n",
    "\n",
    "trans_df['Date'] = pd.to_datetime(trans_df['Date'], errors='coerce')\n",
    "\n",
    "trans_df = trans_df.dropna(subset=['Date'])\n",
    "\n",
    "trans_df['Date'] = trans_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "trans_df['Year'] = trans_df['Date'].str[:4].astype(int)\n",
    "trans_df['Month'] = trans_df['Date'].str[5:7].astype(int)\n",
    "trans_df['Day'] = trans_df['Date'].str[8:10].astype(int)\n",
    "# print(trans_df['Date'].head(20))\n",
    "\n",
    "exchange_rate_inr_to_sgd = 0.016\n",
    "trans_df['Amount'] = trans_df['Amount'] * exchange_rate_inr_to_sgd\n",
    "trans_df['Amount'] = trans_df['Amount'].round(2)\n",
    "\n",
    "\n",
    "monthly_data = trans_df.groupby(['Year', 'Month']).agg({'Amount': 'sum', 'Date': 'count'}).reset_index()\n",
    "monthly_data.rename(columns={'Amount': 'TotalAmount', 'Date': 'Frequency'}, inplace=True)\n",
    "monthly_data['AvgTransactionPerMonth'] = monthly_data['TotalAmount'] / monthly_data['Frequency']\n",
    "\n",
    "# print(monthly_data.head(20))\n",
    "\n",
    "\n",
    "kde_freq = KernelDensity(bandwidth=1, kernel='gaussian')\n",
    "kde_amount = KernelDensity(bandwidth=25, kernel='gaussian')\n",
    "\n",
    "kde_freq.fit(monthly_data['Frequency'].values.reshape(-1, 1))\n",
    "kde_amount.fit(monthly_data['AvgTransactionPerMonth'].values.reshape(-1, 1))\n",
    "\n",
    "new_freq_samples = kde_freq.sample(len(bank_df_train)).reshape(-1)\n",
    "new_amount_samples = kde_amount.sample(len(bank_df_train)).reshape(-1)\n",
    "\n",
    "new_freq_samples_2 = kde_freq.sample(len(bank_df_test)).reshape(-1)\n",
    "new_amount_samples_2 = kde_amount.sample(len(bank_df_test)).reshape(-1)\n",
    "\n",
    "bank_df_train['TransactionFreq'] = new_freq_samples\n",
    "bank_df_train['TransactionFreq'] = bank_df_train['TransactionFreq'].astype(int)\n",
    "bank_df_train['TransactionAmt'] = new_amount_samples\n",
    "percentile_75 = bank_df_train['TransactionAmt'].quantile(0.75)\n",
    "# bank_df_train['TransactionAmt'] = bank_df_train['TransactionAmt'].apply(lambda x: max(x, percentile_75))\n",
    "\n",
    "min_value = bank_df_train['TransactionAmt'].min()\n",
    "max_value = bank_df_train['TransactionAmt'].max()\n",
    "bank_df_train['TransactionAmt'] = ((bank_df_train['TransactionAmt'] - min_value) / (max_value - min_value)) * (percentile_75 - min_value) + percentile_75\n",
    "print(bank_df_train[['TransactionFreq', 'TransactionAmt']].head(10))\n",
    "\n",
    "\n",
    "bank_df_train['TransactionAmt'] = bank_df_train['TransactionAmt'] * bank_df_train['TransactionFreq']\n",
    "\n",
    "\n",
    "bank_df_test['TransactionFreq'] = new_freq_samples_2\n",
    "bank_df_test['TransactionFreq'] = bank_df_test['TransactionFreq'].astype(int)\n",
    "bank_df_test['TransactionAmt'] = new_amount_samples_2\n",
    "\n",
    "bank_df_train.loc[(bank_df_train['Exited'] == 1) | (bank_df_train['MonthsInactive'] > 0), ['TransactionFreq', 'TransactionAmt']] = 0\n",
    "\n",
    "non_zero_mask = (bank_df_train['TransactionFreq'] != 0) & (bank_df_train['TransactionAmt'] != 0)\n",
    "noise_freq = np.random.normal(0, 0.00, len(bank_df_train))\n",
    "noise_amt = np.random.normal(1000, 500, len(bank_df_train))\n",
    "\n",
    "bank_df_train.loc[non_zero_mask, 'TransactionFreq'] += noise_freq[non_zero_mask]\n",
    "bank_df_train.loc[non_zero_mask, 'TransactionAmt'] += noise_amt[non_zero_mask]\n",
    "\n",
    "bank_df_train['TransactionAmt'] = bank_df_train['TransactionAmt'].abs().round(2)\n",
    "\n",
    "print(bank_df_train[['TransactionFreq', 'TransactionAmt']].head(10))\n",
    "print(bank_df_train.describe)\n",
    "\n",
    "\n",
    "\n",
    "non_zero_rows = bank_df_train[bank_df_train['TransactionAmt'] != 0] \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(non_zero_rows['TransactionFreq'], non_zero_rows['TransactionAmt'], color='skyblue')\n",
    "plt.title('Transaction Frequency vs. Transaction Amount (Non-Zero Transactions)')\n",
    "plt.xlabel('Transaction Frequency')\n",
    "plt.ylabel('Transaction Amount')\n",
    "plt.grid(axis='both', linestyle='--', alpha=0.5)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Service Support Freq (per mth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes missed calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   165034.000000\n",
      "mean        13.348552\n",
      "std         12.490492\n",
      "min          0.000000\n",
      "25%          4.000000\n",
      "50%          9.000000\n",
      "75%         20.000000\n",
      "max         73.000000\n",
      "Name: ServiceSupportFrequency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['ServiceSupportFrequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "\n",
    "print(bank_df_train['ServiceSupportFrequency'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Net Promoter Score (NPS)\n",
    "Measure of customer satisfaction and loyalty.\n",
    "Scaled from 1 to 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   165034.000000\n",
      "mean         5.737745\n",
      "std          2.986255\n",
      "min          0.000000\n",
      "25%          4.000000\n",
      "50%          7.000000\n",
      "75%          8.000000\n",
      "max         10.000000\n",
      "Name: NPS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "nps = pd.read_csv('./data/NPS.csv')\n",
    "\n",
    "nps_data = nps.groupby('Customer Name').agg({'NPS':'mean'}).reset_index()\n",
    "kde = gaussian_kde(nps_data['NPS'])\n",
    "bank_df_train['NPS'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "bank_df_train['NPS'] = np.ceil(bank_df_train['NPS']/12*10)\n",
    "\n",
    "print(bank_df_train['NPS'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education\n",
    "Education level might influence financial behavior and churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bachelors' 'Masters' 'Diploma' 'O/N' 'PHD' 'Post-Doc' 'PSLE']\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "education = education_marital['Education_Level'].unique()\n",
    "edu, counts = np.unique(education, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(edu)}\n",
    "numerical_data = [value_to_index[value] for value in education]\n",
    "kde = gaussian_kde(numerical_data)\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "resampled_values = [edu[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Education'] = resampled_values\n",
    "bank_df_train['Education'].replace({'Unknown': 'PSLE'}, inplace=True)\n",
    "bank_df_train['Education'].replace({'Uneducated': np.random.choice(['A', 'Diploma'])}, inplace=True)\n",
    "bank_df_train['Education'].replace({'High School': 'Bachelors'}, inplace=True)\n",
    "bank_df_train['Education'].replace({'College': 'O/N'}, inplace=True)\n",
    "bank_df_train['Education'].replace({'Graduate': 'Masters'}, inplace=True)\n",
    "bank_df_train['Education'].replace({'Post-Graduate': 'PHD'}, inplace=True)\n",
    "bank_df_train['Education'].replace({'Doctorate': 'Post-Doc'}, inplace=True)\n",
    "\n",
    "print(bank_df_train['Education'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Bachelors    27923\n",
       "Masters      26974\n",
       "PHD          26673\n",
       "Diploma      23896\n",
       "Post-Doc     23838\n",
       "O/N          17868\n",
       "PSLE         17862\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df_train['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employment Status\n",
    "Indicates financial stability, affecting churn likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parttime' 'Fulltime' 'Self-employed' 'Student' 'Retired' 'Unemployed']\n"
     ]
    }
   ],
   "source": [
    "employment = pd.read_csv(\"./data/employment.csv\")\n",
    "\n",
    "employment_data = employment['job'].unique()\n",
    "\n",
    "employment_status, counts = np.unique(employment_data, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(employment_status)}\n",
    "numerical_data = [value_to_index[value] for value in employment_data]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [employment_status[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['EmploymentStatus'] = resampled_values\n",
    "\n",
    "bank_df_train['EmploymentStatus'].replace({'admin.': 'Fulltime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'blue-collar': 'Fulltime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'entrepreneur': 'Fulltime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'housemaid': 'Parttime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'management': 'Fulltime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'retired': 'Retired'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'student': 'Student'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'services': 'Fulltime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'self-employed': 'Self-employed'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'technician': 'Parttime'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'unemployed': 'Unemployed'}, inplace=True)\n",
    "bank_df_train['EmploymentStatus'].replace({'unknown': 'Parttime'}, inplace=True)\n",
    "\n",
    "print(bank_df_train['EmploymentStatus'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marital Status\n",
    "Can impact financial decision-making and churn behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Married' 'Single' 'Widowed' 'Divorced']\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "marital_status = education_marital['Marital_Status'].unique()\n",
    "\n",
    "marital, counts = np.unique(marital_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(marital)}\n",
    "numerical_data = [value_to_index[value] for value in marital_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [marital[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['MaritalStatus'] = resampled_values\n",
    "\n",
    "bank_df_train['MaritalStatus'].replace({'Unknown': 'Widowed'}, inplace=True)\n",
    "\n",
    "print(bank_df_train['MaritalStatus'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Housing Status\n",
    "Reflects stability and long-term commitment, influencing churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['owned' 'norent_noown' 'rented']\n"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "\n",
    "housing_status = housing['House_Ownership'].unique()\n",
    "\n",
    "house, counts = np.unique(housing_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(house)}\n",
    "numerical_data = [value_to_index[value] for value in housing_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [house[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['HousingStatus'] = resampled_values\n",
    "\n",
    "print(bank_df_train['HousingStatus'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Dependents\n",
    "Impacts financial priorities and risk tolerance, affecting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   165034.000000\n",
      "mean         2.343687\n",
      "std          1.305842\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          6.000000\n",
      "Name: Dependants, dtype: float64\n",
      "[3 4 2 0 1 5 6]\n"
     ]
    }
   ],
   "source": [
    "dependants_df = pd.read_csv('./data/education+dependents+maritalstatus/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(dependants_df['Dependent_count'])\n",
    "\n",
    "bank_df_train['Dependants'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_train['Dependants'] = np.round(bank_df_train['Dependants']).astype(int)\n",
    "\n",
    "print(bank_df_train['Dependants'].describe())\n",
    "print(bank_df_train['Dependants'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marketing Offers Accepted\n",
    "Indicates responsiveness to incentives, affecting churn. Range 0-1, (percentage of marketing offers they accept, e.g.5 offer, 4 accepted, the value of the column 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   165034.000000\n",
      "mean         0.068896\n",
      "std          0.133310\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.009626\n",
      "75%          0.046468\n",
      "max          0.878459\n",
      "Name: MarketingOffersAcceptance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "marketing_df = pd.read_csv('./data/marketing offers/marketing_campaign.csv', sep=';')\n",
    "\n",
    "marketing_df[\"MarketingOffersAcceptance\"] = (marketing_df['AcceptedCmp1'] + marketing_df['AcceptedCmp2'] + marketing_df['AcceptedCmp3'] + marketing_df['AcceptedCmp4'] + marketing_df['AcceptedCmp5']) / 5\n",
    "\n",
    "kde = gaussian_kde(marketing_df['MarketingOffersAcceptance'])\n",
    "\n",
    "bank_df_train['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "\n",
    "print(bank_df_train['MarketingOffersAcceptance'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preferred Payment Methods \n",
    "Reflects preferred banking channels and engagement level. \n",
    "faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PayNow' 'Intrabank transfer (GXS Savings Account only)' 'Debit card'\n",
      " 'FAST']\n"
     ]
    }
   ],
   "source": [
    "transaction_channel_df = pd.read_csv('./data/main_payment_method/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "methods = transaction_channel_df['PaymentMethod'].unique().tolist()\n",
    "faked_data = [random.choice(methods) for _ in range(len(bank_df_train))]\n",
    "\n",
    "bank_df_train['PaymentMethod'] = faked_data\n",
    "\n",
    "bank_df_train['PaymentMethod'].replace({'Bank transfer (automatic)': 'Intrabank transfer (GXS Savings Account only)'}, inplace=True)\n",
    "bank_df_train['PaymentMethod'].replace({'Electronic check': 'PayNow'}, inplace=True)\n",
    "bank_df_train['PaymentMethod'].replace({'Credit card (automatic)': 'Debit card'}, inplace=True)\n",
    "bank_df_train['PaymentMethod'].replace({'Mailed check': 'FAST'}, inplace=True)\n",
    "\n",
    "print(bank_df_train['PaymentMethod'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand Satisfaction\n",
    "Provides direct feedback on satisfaction levels, predicting churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   165034.000000\n",
      "mean         3.011573\n",
      "std          1.410494\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max          5.000000\n",
      "Name: BrandSatisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cust_satisfaction_df = pd.read_csv('./data/satisfaction score/Customer-Churn-Records.csv')\n",
    "\n",
    "kde = gaussian_kde(cust_satisfaction_df['Satisfaction Score'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 5)\n",
    "fake_data = np.round(fake_data).astype(int)\n",
    "\n",
    "bank_df_train['BrandSatisfaction'] = fake_data\n",
    "\n",
    "print(bank_df_train['BrandSatisfaction'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 5 2 3]\n",
      "count   165034.000000\n",
      "mean         2.816517\n",
      "std          1.508244\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max          5.000000\n",
      "Name: FeatureSatisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with your overall delivery experience at Ali?                    1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['FeatureSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_train['FeatureSatisfaction'] = bank_df_train['FeatureSatisfaction']\n",
    "bank_df_train['FeatureSatisfaction'] = bank_df_train['FeatureSatisfaction'].astype(int)\n",
    "print(bank_df_train['FeatureSatisfaction'].unique())\n",
    "print(bank_df_train['FeatureSatisfaction'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 1 5 2 0]\n",
      "count   165034.000000\n",
      "mean         2.825278\n",
      "std          1.491990\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          4.000000\n",
      "max          5.000000\n",
      "Name: SupportSatisfaction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with the speed of delivery at Alis?                                1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['SupportSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['SupportSatisfaction'].unique())\n",
    "print(bank_df_train['SupportSatisfaction'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
