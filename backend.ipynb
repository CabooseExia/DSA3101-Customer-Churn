{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "np.random.seed(3101)\n",
    "random_state = np.random.RandomState(3101)\n",
    "fake = Faker()\n",
    "pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data:\n",
    "bank1 = archive  \n",
    "bank2 = bank+marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd())\n",
    "bank_df_train = pd.read_csv('./data/main/train.csv')\n",
    "bank_df_test = pd.read_csv('./data/main/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender       Age  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male 33.000000   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male 33.000000   \n",
      "2   2    15694510           Hsueh          678    France   Male 40.000000   \n",
      "3   3    15741417             Kao          581    France   Male 34.000000   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male 33.000000   \n",
      "\n",
      "   Tenure       Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       3      0.000000              2   1.000000        0.000000   \n",
      "1       1      0.000000              2   1.000000        1.000000   \n",
      "2      10      0.000000              2   1.000000        0.000000   \n",
      "3       2 148882.540000              1   1.000000        1.000000   \n",
      "4       5      0.000000              2   1.000000        1.000000   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0    181449.970000       0  \n",
      "1     49503.500000       0  \n",
      "2    184866.690000       0  \n",
      "3     84560.880000       0  \n",
      "4     15068.830000       0  \n",
      "165034\n"
     ]
    }
   ],
   "source": [
    "print(bank_df_train.head())\n",
    "print(len(bank_df_train))\n",
    "\n",
    "# bank_df_train_clean = bank_df_train.drop_duplicates(subset=\"CustomerId\", keep=\"first\")\n",
    "# print(len(bank_df_train_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  CustomerId    Surname  CreditScore Geography  Gender       Age  \\\n",
      "0  165034    15773898   Lucchese          586    France  Female 23.000000   \n",
      "1  165035    15782418       Nott          683    France  Female 46.000000   \n",
      "2  165036    15807120         K?          656    France  Female 34.000000   \n",
      "3  165037    15808905  O'Donnell          681    France    Male 36.000000   \n",
      "4  165038    15607314    Higgins          752   Germany    Male 38.000000   \n",
      "\n",
      "   Tenure       Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2      0.000000              2   0.000000        1.000000   \n",
      "1       2      0.000000              1   1.000000        0.000000   \n",
      "2       7      0.000000              2   1.000000        0.000000   \n",
      "3       8      0.000000              1   1.000000        0.000000   \n",
      "4      10 121263.620000              1   1.000000        0.000000   \n",
      "\n",
      "   EstimatedSalary  \n",
      "0    160976.750000  \n",
      "1     72549.270000  \n",
      "2    138882.090000  \n",
      "3    113931.570000  \n",
      "4    139431.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110023"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bank_df_test.head())\n",
    "len(bank_df_test)\n",
    "# duplicates = bank_df_test.duplicated(subset=['CustomerId'], keep=False)\n",
    "# print(duplicates)\n",
    "#no \"exited\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "\n",
    "Removed CustomerId column in both test & train since it is an unused var in the original dataset\n",
    "All other columns returns no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23221\n"
     ]
    }
   ],
   "source": [
    "# bank_df_train = bank_df_train.loc[:, bank_df_train.columns!='CustomerId'] # extract all columns except for CustomerId\n",
    "# print(bank_df_train[bank_df_train.duplicated() == True]) # check for duplicate columns \n",
    "\n",
    "# bank_df_test = bank_df_test.loc[:, bank_df_test.columns!='CustomerId']\n",
    "\n",
    "### DELETE OR COMMENT OUT THIS LATER ###\n",
    "bank_df_train.drop_duplicates(subset=['CustomerId'], inplace=True)\n",
    "bank_df_test.drop_duplicates(subset=['CustomerId'], inplace=True)\n",
    "n_train = len(bank_df_train)\n",
    "print(n_train)\n",
    "### DELETE OR COMMENT OUT THIS LATER ###\n",
    "\n",
    "# n_test = len(bank_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding and populating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Churn Date: The exact date the customer decided to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           nan\n",
      "1           nan\n",
      "2           nan\n",
      "3           nan\n",
      "4           nan\n",
      "5    2023-07-20\n",
      "6           nan\n",
      "7           nan\n",
      "8           nan\n",
      "9           nan\n",
      "Name: ChurnDate, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "random_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "random_dates_str = random_dates.strftime('%Y-%m-%d')\n",
    "bank_df_train['ChurnDate'] = np.where(bank_df_train['Exited'] == 1, np.random.choice(random_dates_str) , np.nan) \n",
    "print(bank_df_train['ChurnDate'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Sign Up Date: When did the customer create an account\n",
    "has to be linked with churn date if any, and tenure. Tenure is usually rounded down, so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SignDate   ChurnDate  Tenure\n",
      "0  2020-03-08         nan       3\n",
      "1  2022-12-17         nan       1\n",
      "2  2013-06-08         nan      10\n",
      "3  2021-07-08         nan       2\n",
      "4  2018-05-19         nan       5\n",
      "5  2019-05-26  2023-07-20       4\n",
      "6  2015-07-29         nan       8\n",
      "7  2022-08-11         nan       1\n",
      "8  2019-04-15         nan       4\n",
      "9  2019-01-22         nan       4\n"
     ]
    }
   ],
   "source": [
    "def generate_signon_date(churn_date, tenure, exited):\n",
    "    if exited == 0:\n",
    "        churn_date = \"2023-12-31\"\n",
    "    churn_date = pd.to_datetime(churn_date)\n",
    "    max = churn_date - pd.DateOffset(years=tenure)\n",
    "    min = churn_date - pd.DateOffset(years=(tenure + 1))\n",
    "    random_dates = pd.date_range(min, max, freq='D').strftime('%Y-%m-%d')\n",
    "    random_date = np.random.choice(random_dates)\n",
    "    return random_date\n",
    "\n",
    "\n",
    "bank_df_train['SignDate'] = bank_df_train.apply(lambda row: generate_signon_date(row['ChurnDate'], row['Tenure'], row['Exited']), axis = 1)\n",
    "print(bank_df_train[['SignDate', 'ChurnDate', 'Tenure']].head(10))\n",
    "\n",
    "bank_df_test['SignDate'] = bank_df_train.apply(lambda row: generate_signon_date(\"2023-12-31\", row['Tenure'], 0), axis = 1)\n",
    "# print(bank_df_train_clean.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.Transaction History 1\n",
    "Detailed transaction data offers insights into spending patterns and engagement. (Transaction frequency in the last 28 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = pd.read_excel('./data/transaction_history.xlsx')\n",
    "\n",
    "# print(transaction_df.head())\n",
    "transaction_df['DATE'] = pd.to_datetime(transaction_df['DATE'])\n",
    "\n",
    "grouped_df = transaction_df.groupby('Account No')\n",
    "\n",
    "results = []\n",
    "for group_name, group_data in grouped_df:\n",
    "    # Get max and min dates for the group\n",
    "    max_date = group_data['DATE'].max()\n",
    "    min_date = max_date - pd.Timedelta(days=28)\n",
    "    \n",
    "    # Filter group data for transactions within the date range\n",
    "    filtered_group = group_data[(group_data['DATE'] >= min_date) & (group_data['DATE'] <= max_date)]\n",
    "    \n",
    "    # Calculate transaction frequency and amount for the group\n",
    "    transaction_frequency = len(filtered_group)\n",
    "    transaction_amount = filtered_group['DEPOSIT AMT'].sum()\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Account No': group_name,\n",
    "        'Total Transaction Amount': transaction_amount,\n",
    "        'Transaction Frequency': transaction_frequency\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df['Total Transaction Amount'] = result_df['Total Transaction Amount'].astype(int)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "# print(result_df['Total Transaction Amount'])\n",
    "\n",
    "# print(\"Minimum date in the dataset:\", min_date)\n",
    "# print(\"Maximum date in the dataset:\", max_date)\n",
    "\n",
    "kde_freq = gaussian_kde(result_df['Transaction Frequency'])\n",
    "kde_amnt = gaussian_kde(result_df['Total Transaction Amount'])\n",
    "# print(result_df['Total Transaction Amount'])\n",
    "\n",
    "fake_data_freq = kde_freq.resample(len(bank_df_train)).flatten()\n",
    "fake_data_freq = np.round(fake_data_freq).astype(int)\n",
    "bank_df_train['TransactionFreq'] = fake_data_freq\n",
    "fake_data_freq = kde_freq.resample(len(bank_df_test)).flatten()\n",
    "fake_data_freq = np.round(fake_data_freq).astype(int)\n",
    "bank_df_test['TransactionFreq'] = fake_data_freq\n",
    "\n",
    "# fake_data_amt = kde_amnt.resample(len(bank_df_train)).flatten()\n",
    "# # fake_data_amt = np.round(fake_data_amt).astype(int)\n",
    "# bank_df_train['TransactionAmnt'] = fake_data_amt\n",
    "# fake_data_amt = kde_amnt.resample(len(bank_df_test)).flatten()\n",
    "# # fake_data_amt = np.round(fake_data_amt).astype(int)\n",
    "# bank_df_test['TransactionAmnt'] = fake_data_amt\n",
    "\n",
    "# print(bank_df_train['TransactionAmnt'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Transaction History 2\n",
    "Detailed transaction data offers insights into spending patterns and engagement. (Transaction amount in the last 28 days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reference set\n",
    "# Warning: File size slightly big\n",
    "trans_hist_data = pd.read_excel('./data/transaction_history.xlsx')\n",
    "\n",
    "trans_hist_data.dtypes\n",
    "# trans_hist_data.describe()\n",
    "\n",
    "# Extract the most recent 2 sets of 3 months assuming the most recent data is the most accurate\n",
    "trans_1st_3mths = trans_hist_data[(trans_hist_data['DATE'] >= pd.to_datetime('2019-01')) & (trans_hist_data['DATE'] <= pd.to_datetime('2019-03'))]\n",
    "trans_2ns_3mths = trans_hist_data[(trans_hist_data['DATE'] >= pd.to_datetime('2018-10')) & (trans_hist_data['DATE'] <= pd.to_datetime('2018-12'))]\n",
    "\n",
    "trans_dist_data = trans_1st_3mths.groupby('Account No').agg({'VALUE DATE': 'size', 'WITHDRAWAL AMT':'sum', 'DEPOSIT AMT': 'sum'}).reset_index()\n",
    "trans_dist_data['TOTAL AMT'] = -trans_dist_data['WITHDRAWAL AMT'] + trans_dist_data['DEPOSIT AMT']\n",
    "\n",
    "# kde = gaussian_kde(trans_dist_data['VALUE DATE'])\n",
    "# train['Transaction Freq'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "\n",
    "kde = gaussian_kde(trans_dist_data['TOTAL AMT'])\n",
    "bank_df_train['Transaction Amt'] = kde.resample(n_train).flatten().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Call support frequency\n",
    "Higher calls might indicate issues and dissatisfaction, affecting churn. Past year. Past month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0        0              2          1               0          181,450       0   \n",
      "1        0              2          1               1           49,504       0   \n",
      "2        0              2          1               0          184,867       0   \n",
      "3  148,883              1          1               1           84,561       0   \n",
      "4        0              2          1               1           15,069       0   \n",
      "\n",
      "  ChurnDate    SignDate  TransactionFreq  Transaction Amt  \\\n",
      "0       nan  2020-03-08             1120          133,874   \n",
      "1       nan  2022-12-17                3       -1,469,355   \n",
      "2       nan  2013-06-08             -364        3,924,558   \n",
      "3       nan  2021-07-08              356       -3,401,110   \n",
      "4       nan  2018-05-19              318          285,150   \n",
      "\n",
      "   call support frequency  \n",
      "0                      17  \n",
      "1                      33  \n",
      "2                       9  \n",
      "3                       2  \n",
      "4                      16  \n"
     ]
    }
   ],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['call support frequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "print(bank_df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.Relationship Count\n",
    "Reflects the breadth of the customer's relationship with the bank.\n",
    "Shld be correlated to 6: No. of products   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    412575\n",
      "1      2661\n",
      "2     31184\n",
      "3     21980\n",
      "4    299740\n",
      "Name: RelationshipCount, dtype: int32\n",
      "9636647\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "relationship_count = pd.read_csv('./data/loan/credit_train.csv')\n",
    "relationship_count['Current Loan Amount'].fillna(0, inplace=True) \n",
    "\n",
    "if np.any(np.isinf(relationship_count['Current Loan Amount'])):\n",
    "    # Handle infinite values, such as replacing them with a large finite value\n",
    "    relationship_count['Current Loan Amount'].replace([np.inf, -np.inf], np.finfo(np.float64).max, inplace=True)\n",
    "\n",
    "\n",
    "median_loan_amount = relationship_count['Current Loan Amount'].median()\n",
    "below_median = relationship_count[relationship_count['Current Loan Amount'] < median_loan_amount]\n",
    "above_median = relationship_count[relationship_count['Current Loan Amount'] >= median_loan_amount]\n",
    "\n",
    "# print(above_median)\n",
    "kde_upper = gaussian_kde(above_median['Current Loan Amount'])\n",
    "kde_lower = gaussian_kde(below_median['Current Loan Amount'])\n",
    "\n",
    "bank_df_train['RelationshipCount'] = np.where(bank_df_train['CustomerSatisfaction'] >= 4, abs(kde_upper.resample(n_train).flatten()/12).astype(int) , abs(kde_lower.resample(n_train).flatten()/12).astype(int))\n",
    "\n",
    "\n",
    "# kde = gaussian_kde(relationship_count['Current Loan Amount'])\n",
    "# bank_df_train['RelationshipCount'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "\n",
    "print(bank_df_train['RelationshipCount'].head())\n",
    "print(bank_df_train['RelationshipCount'].max())\n",
    "print(bank_df_train['RelationshipCount'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Months Inactive\n",
    "Indicates customer disengagement, potentially preceding churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    1\n",
      "5    2\n",
      "6    3\n",
      "7    1\n",
      "8    1\n",
      "9    0\n",
      "10   0\n",
      "11   0\n",
      "12   0\n",
      "13   1\n",
      "14   0\n",
      "15   1\n",
      "16   3\n",
      "17   0\n",
      "18   2\n",
      "19   1\n",
      "Name: MonthsInactive, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3101)\n",
    "bank_df_train['MonthsInactive'] = np.minimum(np.random.normal(0.5, 1.5, n_train), bank_df_train['Tenure'] * 12)\n",
    "bank_df_train['MonthsInactive'] = np.maximum(bank_df_train['MonthsInactive'], 0)\n",
    "\n",
    "print(bank_df_train['MonthsInactive'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Net Promoter Score (NPS)\n",
    "Measure of customer satisfaction and loyalty.\n",
    "Scaled from 1 to 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1         10\n",
      "2          0\n",
      "3          4\n",
      "4         10\n",
      "          ..\n",
      "164879     3\n",
      "164931     9\n",
      "164961     2\n",
      "164998     7\n",
      "165012     8\n",
      "Name: NPS, Length: 23221, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "nps = pd.read_csv('./data/NPS.csv')\n",
    "\n",
    "nps_data = nps.groupby('Customer Name').agg({'NPS':'mean'}).reset_index()\n",
    "kde = gaussian_kde(nps_data['NPS'])\n",
    "bank_df_train['NPS'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "\n",
    "print(bank_df_train['NPS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Education\n",
    "Education level might influence financial behavior and churn.\n",
    "Shld be correlated to 5. Acct Balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Exited  ChurnDate    SignDate  \\\n",
      "0        0              2  ...       0        nan  2020-03-08   \n",
      "1        0              2  ...       0        nan  2022-12-17   \n",
      "2        0              2  ...       0        nan  2013-06-08   \n",
      "3  148,883              1  ...       0        nan  2021-07-08   \n",
      "4        0              2  ...       0        nan  2018-05-19   \n",
      "\n",
      "   TransactionFreq Transaction Amt call support frequency  RelationshipCount  \\\n",
      "0             1120         133,874                     17              95970   \n",
      "1                3      -1,469,355                     33              14953   \n",
      "2             -364       3,924,558                      9             265627   \n",
      "3              356      -3,401,110                      2            8700126   \n",
      "4              318         285,150                     16              52412   \n",
      "\n",
      "   MonthsInactive  NPS      Education  \n",
      "0               1    0        Unknown  \n",
      "1               1   10        College  \n",
      "2               2    0  Post-Graduate  \n",
      "3               0    4    High School  \n",
      "4               1   10        Unknown  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "education = education_marital['Education_Level'].unique()\n",
    "\n",
    "edu, counts = np.unique(education, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(edu)}\n",
    "numerical_data = [value_to_index[value] for value in education]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [edu[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Education'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22 Employment Status\n",
    "Indicates financial stability, affecting churn likelihood. \n",
    "Shld be correlated to 5. Acct Balance & 21. Education  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  ChurnDate    SignDate  TransactionFreq  \\\n",
      "0        0              2  ...        nan  2020-03-08             1120   \n",
      "1        0              2  ...        nan  2022-12-17                3   \n",
      "2        0              2  ...        nan  2013-06-08             -364   \n",
      "3  148,883              1  ...        nan  2021-07-08              356   \n",
      "4        0              2  ...        nan  2018-05-19              318   \n",
      "\n",
      "   Transaction Amt call support frequency RelationshipCount  MonthsInactive  \\\n",
      "0          133,874                     17             95970               1   \n",
      "1       -1,469,355                     33             14953               1   \n",
      "2        3,924,558                      9            265627               2   \n",
      "3       -3,401,110                      2           8700126               0   \n",
      "4          285,150                     16             52412               1   \n",
      "\n",
      "   NPS      Education  Employment Status  \n",
      "0    0        Unknown            student  \n",
      "1   10        College         technician  \n",
      "2    0  Post-Graduate             admin.  \n",
      "3    4    High School       entrepreneur  \n",
      "4   10        Unknown      self-employed  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "employment = pd.read_csv(\"./data/employment.csv\")\n",
    "\n",
    "employment_data = employment['job'].unique()\n",
    "\n",
    "employment_status, counts = np.unique(employment_data, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(employment_status)}\n",
    "numerical_data = [value_to_index[value] for value in employment_data]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [employment_status[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Employment Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. Marital Status\n",
    "Can impact financial decision-making and churn behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...    SignDate  TransactionFreq  Transaction Amt  \\\n",
      "0        0              2  ...  2020-03-08             1120          133,874   \n",
      "1        0              2  ...  2022-12-17                3       -1,469,355   \n",
      "2        0              2  ...  2013-06-08             -364        3,924,558   \n",
      "3  148,883              1  ...  2021-07-08              356       -3,401,110   \n",
      "4        0              2  ...  2018-05-19              318          285,150   \n",
      "\n",
      "   call support frequency RelationshipCount MonthsInactive  NPS  \\\n",
      "0                      17             95970              1    0   \n",
      "1                      33             14953              1   10   \n",
      "2                       9            265627              2    0   \n",
      "3                       2           8700126              0    4   \n",
      "4                      16             52412              1   10   \n",
      "\n",
      "       Education  Employment Status  Marital Status  \n",
      "0        Unknown            student        Divorced  \n",
      "1        College         technician        Divorced  \n",
      "2  Post-Graduate             admin.          Single  \n",
      "3    High School       entrepreneur         Married  \n",
      "4        Unknown      self-employed        Divorced  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "marital_status = education_marital['Marital_Status'].unique()\n",
    "\n",
    "marital, counts = np.unique(marital_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(marital)}\n",
    "numerical_data = [value_to_index[value] for value in marital_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [marital[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Marital Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. Housing Status\n",
    "Reflects stability and long-term commitment, influencing churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  TransactionFreq  Transaction Amt  \\\n",
      "0        0              2  ...             1120          133,874   \n",
      "1        0              2  ...                3       -1,469,355   \n",
      "2        0              2  ...             -364        3,924,558   \n",
      "3  148,883              1  ...              356       -3,401,110   \n",
      "4        0              2  ...              318          285,150   \n",
      "\n",
      "   call support frequency  RelationshipCount MonthsInactive NPS  \\\n",
      "0                      17              95970              1   0   \n",
      "1                      33              14953              1  10   \n",
      "2                       9             265627              2   0   \n",
      "3                       2            8700126              0   4   \n",
      "4                      16              52412              1  10   \n",
      "\n",
      "       Education  Employment Status  Marital Status  Housing Status  \n",
      "0        Unknown            student        Divorced    norent_noown  \n",
      "1        College         technician        Divorced    norent_noown  \n",
      "2  Post-Graduate             admin.          Single    norent_noown  \n",
      "3    High School       entrepreneur         Married          rented  \n",
      "4        Unknown      self-employed        Divorced           owned  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "\n",
    "housing_status = housing['House_Ownership'].unique()\n",
    "\n",
    "house, counts = np.unique(housing_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(house)}\n",
    "numerical_data = [value_to_index[value] for value in housing_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [house[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Housing Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Number of Dependents\n",
    "Impacts financial priorities and risk tolerance, affecting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Transaction Amt  call support frequency  \\\n",
      "0        0              2  ...          133,874                      17   \n",
      "1        0              2  ...       -1,469,355                      33   \n",
      "2        0              2  ...        3,924,558                       9   \n",
      "3  148,883              1  ...       -3,401,110                       2   \n",
      "4        0              2  ...          285,150                      16   \n",
      "\n",
      "   RelationshipCount  MonthsInactive NPS      Education  Employment Status  \\\n",
      "0              95970               1   0        Unknown            student   \n",
      "1              14953               1  10        College         technician   \n",
      "2             265627               2   0  Post-Graduate             admin.   \n",
      "3            8700126               0   4    High School       entrepreneur   \n",
      "4              52412               1  10        Unknown      self-employed   \n",
      "\n",
      "   Marital Status  Housing Status  Dependants  \n",
      "0        Divorced    norent_noown           2  \n",
      "1        Divorced    norent_noown           3  \n",
      "2          Single    norent_noown           3  \n",
      "3         Married          rented           4  \n",
      "4        Divorced           owned           2  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "dependants_df = pd.read_csv('./data/education+dependents+maritalstatus/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(dependants_df['Dependent_count'])\n",
    "\n",
    "bank_df_train['Dependants'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_train['Dependants'] = np.round(bank_df_train['Dependants']).astype(int)\n",
    "bank_df_test['Dependants'] = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "bank_df_test['Dependants'] = np.round(bank_df_test['Dependants']).astype(int)\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Marketing Offers Accepted\n",
    "Indicates responsiveness to incentives, affecting churn. Range 0-1, (percentage of marketing offers they accept, e.g.5 offer, 4 accepted, the value of the column 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  call support frequency  RelationshipCount  \\\n",
      "0        0              2  ...                      17              95970   \n",
      "1        0              2  ...                      33              14953   \n",
      "2        0              2  ...                       9             265627   \n",
      "3  148,883              1  ...                       2            8700126   \n",
      "4        0              2  ...                      16              52412   \n",
      "\n",
      "   MonthsInactive  NPS      Education Employment Status  Marital Status  \\\n",
      "0               1    0        Unknown           student        Divorced   \n",
      "1               1   10        College        technician        Divorced   \n",
      "2               2    0  Post-Graduate            admin.          Single   \n",
      "3               0    4    High School      entrepreneur         Married   \n",
      "4               1   10        Unknown     self-employed        Divorced   \n",
      "\n",
      "   Housing Status  Dependants  MarketingOffersAcceptance  \n",
      "0    norent_noown           2                          0  \n",
      "1    norent_noown           3                          0  \n",
      "2    norent_noown           3                          0  \n",
      "3          rented           4                          0  \n",
      "4           owned           2                          0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "marketing_df = pd.read_csv('./data/marketing offers/marketing_campaign.csv', sep=';')\n",
    "\n",
    "\n",
    "marketing_df[\"MarketingOffersAcceptance\"] = (marketing_df['AcceptedCmp1'] + marketing_df['AcceptedCmp2'] + marketing_df['AcceptedCmp3'] + marketing_df['AcceptedCmp4'] + marketing_df['AcceptedCmp5']) / 5\n",
    "# print(marketing_df.head())\n",
    "\n",
    "kde = gaussian_kde(marketing_df['MarketingOffersAcceptance'])\n",
    "\n",
    "bank_df_train['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_test['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Channel Used for Transactions\n",
    "Reflects preferred banking channels and engagement level. \n",
    "faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  RelationshipCount  MonthsInactive  NPS  \\\n",
      "0        0              2  ...              95970               1    0   \n",
      "1        0              2  ...              14953               1   10   \n",
      "2        0              2  ...             265627               2    0   \n",
      "3  148,883              1  ...            8700126               0    4   \n",
      "4        0              2  ...              52412               1   10   \n",
      "\n",
      "       Education Employment Status Marital Status  Housing Status  Dependants  \\\n",
      "0        Unknown           student       Divorced    norent_noown           2   \n",
      "1        College        technician       Divorced    norent_noown           3   \n",
      "2  Post-Graduate            admin.         Single    norent_noown           3   \n",
      "3    High School      entrepreneur        Married          rented           4   \n",
      "4        Unknown     self-employed       Divorced           owned           2   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod  \n",
      "0                          0  Bank transfer (automatic)  \n",
      "1                          0    Credit card (automatic)  \n",
      "2                          0           Electronic check  \n",
      "3                          0  Bank transfer (automatic)  \n",
      "4                          0           Electronic check  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "transaction_channel_df = pd.read_csv('./data/main_payment_method/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# print(transaction_channel_df.head())\n",
    "methods = transaction_channel_df['PaymentMethod'].unique().tolist()\n",
    "print(methods)\n",
    "faked_data = [random.choice(methods) for _ in range(len(bank_df_train))]\n",
    "faked_data_2 = [random.choice(methods) for _ in range(len(bank_df_test))]\n",
    "\n",
    "bank_df_train['PaymentMethod'] = faked_data\n",
    "bank_df_test['PaymentMethod'] = faked_data_2\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Customer Satisfaction Surveys\n",
    "Provides direct feedback on satisfaction levels, predicting churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    2\n",
      "2    4\n",
      "3    2\n",
      "4    5\n",
      "5    2\n",
      "6    2\n",
      "7    3\n",
      "8    4\n",
      "9    4\n",
      "Name: CustomerSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "cust_satisfaction_df = pd.read_csv('./data/satisfaction score/Customer-Churn-Records.csv')\n",
    "\n",
    "kde = gaussian_kde(cust_satisfaction_df['Satisfaction Score'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 5)\n",
    "fake_data = np.round(fake_data).astype(int)\n",
    "\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 5)\n",
    "fake_data_2 = np.round(fake_data_2).astype(int)\n",
    "\n",
    "bank_df_train['CustomerSatisfaction'] = fake_data\n",
    "bank_df_test['CustomerSatisfaction'] = fake_data_2\n",
    "# print(len(bank_df_test))\n",
    "# print(len(fake_data_2))\n",
    "\n",
    "print(bank_df_train['CustomerSatisfaction'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. Feature Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    4\n",
      "2    4\n",
      "3    5\n",
      "4    4\n",
      "Name: FeatureSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with your overall delivery experience at Ali?                    1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['FeatureSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_test['FeatureSatisfaction'] = kde.resample(len(bank_df_test)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['FeatureSatisfaction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30. Support Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    1\n",
      "2    0\n",
      "3    4\n",
      "4    5\n",
      "Name: SupportSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with the speed of delivery at Alis?                                1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['SupportSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_test['SupportSatisfaction'] = kde.resample(len(bank_df_test)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['SupportSatisfaction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.Service Support Frequency (per mth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['service support frequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Income Source\n",
    "Indicates financial stability and potential churn risk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Private', 'Local-gov', 'Self-emp-not-inc', 'Federal-gov', 'State-gov', 'Self-emp-inc', 'Without-pay', 'Never-worked']\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Marital Status  Housing Status  Dependants  \\\n",
      "0        0              2  ...        Divorced    norent_noown           2   \n",
      "1        0              2  ...        Divorced    norent_noown           3   \n",
      "2        0              2  ...          Single    norent_noown           3   \n",
      "3  148,883              1  ...         Married          rented           4   \n",
      "4        0              2  ...        Divorced           owned           2   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod CustomerSatisfaction  \\\n",
      "0                          0  Bank transfer (automatic)                    4   \n",
      "1                          0    Credit card (automatic)                    2   \n",
      "2                          0           Electronic check                    4   \n",
      "3                          0  Bank transfer (automatic)                    2   \n",
      "4                          0           Electronic check                    5   \n",
      "\n",
      "   FeatureSatisfaction  SupportSatisfaction  service support frequency  \\\n",
      "0                    5                    2                          4   \n",
      "1                    4                    1                         16   \n",
      "2                    4                    0                          4   \n",
      "3                    5                    4                          5   \n",
      "4                    4                    5                         52   \n",
      "\n",
      "   IncomeSource  \n",
      "0     State-gov  \n",
      "1     State-gov  \n",
      "2  Never-worked  \n",
      "3  Self-emp-inc  \n",
      "4  Never-worked  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "income_source_df = pd.read_csv('./data/income source/adult.csv')\n",
    "\n",
    "# print(transaction_channel_df.head())\n",
    "income_sourcs = income_source_df['workclass'].unique().tolist()\n",
    "income_sourcs.remove('?')\n",
    "print(income_sourcs)\n",
    "faked_data = [random.choice(income_sourcs) for _ in range(len(bank_df_train))]\n",
    "faked_data_2 = [random.choice(income_sourcs) for _ in range(len(bank_df_test))]\n",
    "\n",
    "bank_df_train['IncomeSource'] = faked_data\n",
    "bank_df_test['IncomeSource'] = faked_data_2\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Credit Utilization\n",
    "Reflects financial health and potential churn risk for credit customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Housing Status  Dependants  \\\n",
      "0        0              2  ...    norent_noown           2   \n",
      "1        0              2  ...    norent_noown           3   \n",
      "2        0              2  ...    norent_noown           3   \n",
      "3  148,883              1  ...          rented           4   \n",
      "4        0              2  ...           owned           2   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod CustomerSatisfaction  \\\n",
      "0                          0  Bank transfer (automatic)                    4   \n",
      "1                          0    Credit card (automatic)                    2   \n",
      "2                          0           Electronic check                    4   \n",
      "3                          0  Bank transfer (automatic)                    2   \n",
      "4                          0           Electronic check                    5   \n",
      "\n",
      "  FeatureSatisfaction  SupportSatisfaction  service support frequency  \\\n",
      "0                   5                    2                          4   \n",
      "1                   4                    1                         16   \n",
      "2                   4                    0                          4   \n",
      "3                   5                    4                          5   \n",
      "4                   4                    5                         52   \n",
      "\n",
      "   IncomeSource  CreditUtilization  \n",
      "0     State-gov                  1  \n",
      "1     State-gov                  1  \n",
      "2  Never-worked                  0  \n",
      "3  Self-emp-inc                  1  \n",
      "4  Never-worked                  0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_df = pd.read_csv('./data/credit utilization/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(credit_df['Avg_Utilization_Ratio'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 1)\n",
    "# fake_data = np.round(fake_data).astype(int)\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 1)\n",
    "\n",
    "bank_df_train['CreditUtilization'] = fake_data\n",
    "bank_df_test['CreditUtilization'] = fake_data_2\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. Response to Previous Retention Efforts\n",
    "Records success or failure of previous retention efforts, guiding future strategies. % 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000000\n",
      "1    0.000000\n",
      "2    0.000558\n",
      "3    0.004380\n",
      "4    0.003791\n",
      "5    0.001137\n",
      "6    0.040838\n",
      "7    0.010878\n",
      "8    0.049369\n",
      "9    0.000000\n",
      "10   0.000000\n",
      "11   0.004515\n",
      "12   0.000000\n",
      "13   0.003814\n",
      "14   0.000000\n",
      "15   0.013351\n",
      "16   0.000000\n",
      "17   0.012190\n",
      "18   0.015541\n",
      "19   0.055209\n",
      "Name: Retention, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "retention_df = pd.read_csv('./data/retention/HR_comma_sep.csv')\n",
    "\n",
    "kde = gaussian_kde(retention_df['promotion_last_5years'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 1)\n",
    "\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 1)\n",
    "\n",
    "\n",
    "bank_df_train['Retention'] = fake_data\n",
    "bank_df_test['Retention'] = fake_data_2\n",
    "\n",
    "print(bank_df_train['Retention'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. Change in behavior before n after\n",
    "Average of percentage of increase/decrease (ranging from 0 - infinity, but most of the times it will be ard 0-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   1\n",
      "6   1\n",
      "7   1\n",
      "8   1\n",
      "9   1\n",
      "Name: ChangeInBehaviourMkt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bank_df_train['ChangeInBehaviourMkt'] = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "bank_df_test['ChangeInBehaviourMkt']= np.random.normal(1, 0.25, len(bank_df_test))\n",
    "# test = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "# # print(test)\n",
    "# bank_df_train['ChangeInBehaviourMkt'] = test.astype(float)\n",
    "\n",
    "print(bank_df_train['ChangeInBehaviourMkt'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. Change in behavior before n after for Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   0\n",
      "Name: ChanegInBehaviourCust, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bank_df_train['ChanegInBehaviourCust'] = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "bank_df_test['ChanegInBehaviourCust']= np.random.normal(1, 0.25, len(bank_df_test))\n",
    "\n",
    "print(bank_df_train['ChanegInBehaviourCust'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. Previous Lifecycle status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Reactivated\n",
      "1        Dormant\n",
      "2        Dormant\n",
      "3    Reactivated\n",
      "4    Reactivated\n",
      "5        Churned\n",
      "6        Dormant\n",
      "7         Active\n",
      "8        Dormant\n",
      "9    Reactivated\n",
      "Name: PrevLifecycle, dtype: object\n"
     ]
    }
   ],
   "source": [
    "life_cycles = ['Active', 'Dormant', 'Reactivated'] #everything but churned\n",
    "\n",
    "bank_df_train['PrevLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['Exited'] == 1 else np.random.choice(life_cycles), axis=1)\n",
    "\n",
    "print(bank_df_train['PrevLifecycle'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Current Lifecycle status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PrevLifecycle CurrLifecycle\n",
      "0   Reactivated        Active\n",
      "1       Dormant       Dormant\n",
      "2       Dormant   Reactivated\n",
      "3   Reactivated       Dormant\n",
      "4   Reactivated       Dormant\n",
      "5       Churned       Churned\n",
      "6       Dormant   Reactivated\n",
      "7        Active       Dormant\n",
      "8       Dormant       Dormant\n",
      "9   Reactivated       Dormant\n"
     ]
    }
   ],
   "source": [
    "prev_active = ['Active', 'Dormant'] #excluding churn, also same for reactivated\n",
    "prev_dormant = ['Dormant', 'Reactivated'] #excluding churn\n",
    "\n",
    "bank_df_train['CurrLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['PrevLifecycle'] == 'Churned' else \\\n",
    "                                                    np.random.choice(prev_active) if (row['PrevLifecycle'] == 'Active' or row['PrevLifecycle'] == 'Reactivated') else \\\n",
    "                                                    np.random.choice(prev_dormant) if row['PrevLifecycle'] == 'Dormant' else \\\n",
    "                                                    np.nan, axis=1)\n",
    "\n",
    "print(bank_df_train[['PrevLifecycle', 'CurrLifecycle']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. Customer Happiness Status \n",
    "1 == happy, 0 == unhappy\n",
    "\n",
    "Customer satisfaction survey score \n",
    "\n",
    "Relationship Count \n",
    "\n",
    "Response to previous retention efforts (no more yay)\n",
    "\n",
    "if we want the top 15.9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: Happiness, dtype: int64\n",
      "percentage happy = 20.18431592093364\n"
     ]
    }
   ],
   "source": [
    "happiness_benchmark = 84.1\n",
    "\n",
    "# bank_df_train['Happiness'] = bank_df_train.apply(lambda row: 1 if row['CustomerSatisfaction'] + \\\n",
    "#                                                                   row['FeatureSatisfaction'] + \\\n",
    "#                                                                   row['SupportSatisfaction'] + \\\n",
    "#                                                                   row['NPS'] + \\\n",
    "#                                                                   row['Tenure'] >= happiness_benchmark else \\\n",
    "#                                                                   0, axis=1)\n",
    "\n",
    "\n",
    "# need to delete Custpercentile, RsPercentile and ResponsePercentile later\n",
    "bank_df_train['CustPercentile'] = bank_df_train['CustomerSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "bank_df_train['RsPercentile'] = bank_df_train['RelationshipCount'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "\n",
    "# print(bank_df_train['CustPercentile'].head(10))\n",
    "bank_df_train['Happiness'] = bank_df_train.apply(lambda row: 1 if (row['CustPercentile'] > happiness_benchmark and row['RsPercentile'] > happiness_benchmark ) else 0, axis=1)\n",
    "bank_df_train.drop(columns=['CustPercentile', 'RsPercentile'], inplace=True)\n",
    "\n",
    "print(bank_df_train['Happiness'].head(10))\n",
    "print(\"percentage happy =\", (bank_df_train['Happiness'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40. Customer Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41. Price Sensitivity %\n",
    "26. marketing offers accepted %\n",
    "35. change in behaviour %\n",
    "\n",
    "Mkting Offers Accepted\n",
    "Change in behavior before n after for mkting offer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    49.677016\n",
      "1    65.389087\n",
      "2    26.637526\n",
      "3    70.884114\n",
      "4    23.862021\n",
      "5    77.733517\n",
      "6    16.282675\n",
      "7    81.859093\n",
      "8    27.162913\n",
      "9    40.304035\n",
      "10   65.201757\n",
      "11   50.613669\n",
      "12   41.651953\n",
      "13   45.060506\n",
      "14   52.870247\n",
      "15   37.883812\n",
      "16   48.109470\n",
      "17   49.534904\n",
      "18   13.597606\n",
      "19   63.668662\n",
      "Name: PriceSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# distribution = bank_df_train['MarketingOffersAcceptance'].astype(float) * bank_df_train['ChangeInBehaviourMkt']\n",
    "# pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))\n",
    "# # print(distribution)\n",
    "# percentiles = np.percentile(distribution, [0, 25, 50, 75, 100])\n",
    "\n",
    "# def assign_percentile(metric):\n",
    "#     if metric <= percentiles[1]:\n",
    "#         return ((metric / percentiles[1]) * 25)\n",
    "#     elif metric <= percentiles[2]:\n",
    "#         return (25 + ((metric - percentiles[1]) / (percentiles[2] - percentiles[1])) * 25)\n",
    "#     elif metric <= percentiles[3]:\n",
    "#         return (50 + ((metric - percentiles[2]) / (percentiles[3] - percentiles[2])) * 25)\n",
    "#     else:\n",
    "#         return (75 + ((metric - percentiles[3]) / (percentiles[4] - percentiles[3])) * 25)\n",
    "        \n",
    "# bank_df_train['PriceSensitivity'] = distribution.apply(assign_percentile)\n",
    "# bank_df_train['PriceSensitivity'] = bank_df_train['PriceSensitivity'].replace(np.NaN, 0, regex=True)\n",
    "\n",
    "\n",
    "MarketingOffersAcceptance_df = bank_df_train['MarketingOffersAcceptance'].apply(lambda x: stats.percentileofscore(bank_df_train['MarketingOffersAcceptance'], x))\n",
    "ChangeInBehaviourMkt_df = bank_df_train['ChangeInBehaviourMkt'].apply(lambda x: stats.percentileofscore(bank_df_train['ChangeInBehaviourMkt'], x))\n",
    "# print(MarketingOffersAcceptance_df.head())\n",
    "# print(ChangeInBehaviourMkt_df.head())\n",
    "bank_df_train['PriceSensitivity'] = (MarketingOffersAcceptance_df + ChangeInBehaviourMkt_df) / 2\n",
    "\n",
    "print(bank_df_train['PriceSensitivity'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42. Feature Driven % \n",
    "28. Customer satisfaction survey 0-5\n",
    "6. num products 1-4\n",
    "29. Feature Satisfaction 0-5\n",
    "\n",
    "Number of products last 1 year\n",
    "Feature Satisfaction Column (0 to 1)\n",
    "Feature Support freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    85.000000\n",
      "1    62.500000\n",
      "2    80.000000\n",
      "3    62.500000\n",
      "4    85.000000\n",
      "5    16.666667\n",
      "6    16.666667\n",
      "7    20.833333\n",
      "8    75.000000\n",
      "9    50.000000\n",
      "10   62.500000\n",
      "11   50.000000\n",
      "12   25.000000\n",
      "13   75.000000\n",
      "14   25.000000\n",
      "15   75.000000\n",
      "16   50.000000\n",
      "17   80.000000\n",
      "18   20.833333\n",
      "19   75.000000\n",
      "Name: FeatureSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(bank_df_train['NumOfProducts'].max())\n",
    "# print(bank_df_train['NumOfProducts'].min())\n",
    "\n",
    "feature_driven = bank_df_train['CustomerSatisfaction'] + bank_df_train['NumOfProducts'] + bank_df_train['FeatureSatisfaction']\n",
    "percentiles = np.percentile(feature_driven, [0, 25, 50, 75, 100]) \n",
    "\n",
    "def assign_percentile(metric):\n",
    "    if metric <= percentiles[1]:\n",
    "        return ((metric / percentiles[1]) * 25)\n",
    "    elif metric <= percentiles[2]:\n",
    "        return (25 + ((metric - percentiles[1]) / (percentiles[2] - percentiles[1])) * 25)\n",
    "    elif metric <= percentiles[3]:\n",
    "        return (50 + ((metric - percentiles[2]) / (percentiles[3] - percentiles[2])) * 25)\n",
    "    else:\n",
    "        return (75 + ((metric - percentiles[3]) / (percentiles[4] - percentiles[3])) * 25)\n",
    "        \n",
    "bank_df_train['FeatureSensitivity'] = feature_driven.apply(assign_percentile)\n",
    "bank_df_train['FeatureSensitivity'] = bank_df_train['FeatureSensitivity'].replace(np.NaN, 0, regex=True)\n",
    "\n",
    "print(bank_df_train['FeatureSensitivity'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43. Service Driven % \n",
    "31. service support freq per month number\n",
    "39. Customer Happiness Status binary\n",
    "36. Change in behavior before n after for Support %\n",
    "\n",
    "CALL Support frequency\n",
    "Support Satisfaction Column (0 to 1)\n",
    "Change in behavior before n after support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. Social Influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "1. covarience matrix\n",
    "2. LDA\n",
    "3. apriori\n",
    "4. domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#domain knowledge...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training:\n",
    "1. Random forest\n",
    "2. XGBoost\n",
    "3. Logistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
