{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from datetime import datetime\n",
    "from faker import Faker\n",
    "np.random.seed(3101)\n",
    "random_state = np.random.RandomState(3101)\n",
    "fake = Faker()\n",
    "pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data:\n",
    "bank1 = archive  \n",
    "bank2 = bank+marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd())\n",
    "bank_df_train = pd.read_csv('./data/main/train.csv')\n",
    "bank_df_test = pd.read_csv('./data/main/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender       Age  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male 33.000000   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male 33.000000   \n",
      "2   2    15694510           Hsueh          678    France   Male 40.000000   \n",
      "3   3    15741417             Kao          581    France   Male 34.000000   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male 33.000000   \n",
      "\n",
      "   Tenure       Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       3      0.000000              2   1.000000        0.000000   \n",
      "1       1      0.000000              2   1.000000        1.000000   \n",
      "2      10      0.000000              2   1.000000        0.000000   \n",
      "3       2 148882.540000              1   1.000000        1.000000   \n",
      "4       5      0.000000              2   1.000000        1.000000   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0    181449.970000       0  \n",
      "1     49503.500000       0  \n",
      "2    184866.690000       0  \n",
      "3     84560.880000       0  \n",
      "4     15068.830000       0  \n",
      "165034\n"
     ]
    }
   ],
   "source": [
    "print(bank_df_train.head())\n",
    "print(len(bank_df_train))\n",
    "\n",
    "# bank_df_train_clean = bank_df_train.drop_duplicates(subset=\"CustomerId\", keep=\"first\")\n",
    "# print(len(bank_df_train_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  CustomerId    Surname  CreditScore Geography  Gender       Age  \\\n",
      "0  165034    15773898   Lucchese          586    France  Female 23.000000   \n",
      "1  165035    15782418       Nott          683    France  Female 46.000000   \n",
      "2  165036    15807120         K?          656    France  Female 34.000000   \n",
      "3  165037    15808905  O'Donnell          681    France    Male 36.000000   \n",
      "4  165038    15607314    Higgins          752   Germany    Male 38.000000   \n",
      "\n",
      "   Tenure       Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2      0.000000              2   0.000000        1.000000   \n",
      "1       2      0.000000              1   1.000000        0.000000   \n",
      "2       7      0.000000              2   1.000000        0.000000   \n",
      "3       8      0.000000              1   1.000000        0.000000   \n",
      "4      10 121263.620000              1   1.000000        0.000000   \n",
      "\n",
      "   EstimatedSalary  \n",
      "0    160976.750000  \n",
      "1     72549.270000  \n",
      "2    138882.090000  \n",
      "3    113931.570000  \n",
      "4    139431.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110023"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bank_df_test.head())\n",
    "len(bank_df_test)\n",
    "# duplicates = bank_df_test.duplicated(subset=['CustomerId'], keep=False)\n",
    "# print(duplicates)\n",
    "#no \"exited\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "\n",
    "Removed CustomerId column in both test & train since it is an unused var in the original dataset\n",
    "All other columns returns no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23221\n"
     ]
    }
   ],
   "source": [
    "# bank_df_train = bank_df_train.loc[:, bank_df_train.columns!='CustomerId'] # extract all columns except for CustomerId\n",
    "# print(bank_df_train[bank_df_train.duplicated() == True]) # check for duplicate columns \n",
    "\n",
    "# bank_df_test = bank_df_test.loc[:, bank_df_test.columns!='CustomerId']\n",
    "\n",
    "### DELETE OR COMMENT OUT THIS LATER ###\n",
    "bank_df_train.drop_duplicates(subset=['CustomerId'], inplace=True)\n",
    "bank_df_test.drop_duplicates(subset=['CustomerId'], inplace=True)\n",
    "n_train = len(bank_df_train)\n",
    "print(n_train)\n",
    "### DELETE OR COMMENT OUT THIS LATER ###\n",
    "\n",
    "# n_test = len(bank_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding and populating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Churn Date: The exact date the customer decided to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           nan\n",
      "1           nan\n",
      "2           nan\n",
      "3           nan\n",
      "4           nan\n",
      "5    2023-07-20\n",
      "6           nan\n",
      "7           nan\n",
      "8           nan\n",
      "9           nan\n",
      "Name: ChurnDate, dtype: object\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "random_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "random_dates_str = random_dates.strftime('%Y-%m-%d')\n",
    "bank_df_train['ChurnDate'] = np.where(bank_df_train['Exited'] == 1, np.random.choice(random_dates_str) , np.nan) \n",
    "print(bank_df_train['ChurnDate'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Sign Up Date: When did the customer create an account\n",
    "has to be linked with churn date if any, and tenure. Tenure is usually rounded down, so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SignDate   ChurnDate  Tenure\n",
      "0  2020-03-08         nan       3\n",
      "1  2022-12-17         nan       1\n",
      "2  2013-06-08         nan      10\n",
      "3  2021-07-08         nan       2\n",
      "4  2018-05-19         nan       5\n",
      "5  2019-05-26  2023-07-20       4\n",
      "6  2015-07-29         nan       8\n",
      "7  2022-08-11         nan       1\n",
      "8  2019-04-15         nan       4\n",
      "9  2019-01-22         nan       4\n"
     ]
    }
   ],
   "source": [
    "def generate_signon_date(churn_date, tenure, exited):\n",
    "    if exited == 0:\n",
    "        churn_date = \"2023-12-31\"\n",
    "    churn_date = pd.to_datetime(churn_date)\n",
    "    max = churn_date - pd.DateOffset(years=tenure)\n",
    "    min = churn_date - pd.DateOffset(years=(tenure + 1))\n",
    "    random_dates = pd.date_range(min, max, freq='D').strftime('%Y-%m-%d')\n",
    "    random_date = np.random.choice(random_dates)\n",
    "    return random_date\n",
    "\n",
    "\n",
    "bank_df_train['SignDate'] = bank_df_train.apply(lambda row: generate_signon_date(row['ChurnDate'], row['Tenure'], row['Exited']), axis = 1)\n",
    "print(bank_df_train[['SignDate', 'ChurnDate', 'Tenure']].head(10))\n",
    "\n",
    "bank_df_test['SignDate'] = bank_df_train.apply(lambda row: generate_signon_date(\"2023-12-31\", row['Tenure'], 0), axis = 1)\n",
    "# print(bank_df_train_clean.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.Transaction History 1\n",
    "Detailed transaction data offers insights into spending patterns and engagement. (Transaction frequency in the last 28 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = pd.read_excel('./data/transaction_history.xlsx')\n",
    "\n",
    "# print(transaction_df.head())\n",
    "transaction_df['DATE'] = pd.to_datetime(transaction_df['DATE'])\n",
    "\n",
    "grouped_df = transaction_df.groupby('Account No')\n",
    "\n",
    "results = []\n",
    "for group_name, group_data in grouped_df:\n",
    "    # Get max and min dates for the group\n",
    "    max_date = group_data['DATE'].max()\n",
    "    min_date = max_date - pd.Timedelta(days=28)\n",
    "    \n",
    "    # Filter group data for transactions within the date range\n",
    "    filtered_group = group_data[(group_data['DATE'] >= min_date) & (group_data['DATE'] <= max_date)]\n",
    "    \n",
    "    # Calculate transaction frequency and amount for the group\n",
    "    transaction_frequency = len(filtered_group)\n",
    "    transaction_amount = filtered_group['DEPOSIT AMT'].sum()\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Account No': group_name,\n",
    "        'Total Transaction Amount': transaction_amount,\n",
    "        'Transaction Frequency': transaction_frequency\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df['Total Transaction Amount'] = result_df['Total Transaction Amount'].astype(int)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "# print(result_df['Total Transaction Amount'])\n",
    "\n",
    "# print(\"Minimum date in the dataset:\", min_date)\n",
    "# print(\"Maximum date in the dataset:\", max_date)\n",
    "\n",
    "kde_freq = gaussian_kde(result_df['Transaction Frequency'])\n",
    "kde_amnt = gaussian_kde(result_df['Total Transaction Amount'])\n",
    "# print(result_df['Total Transaction Amount'])\n",
    "\n",
    "fake_data_freq = kde_freq.resample(len(bank_df_train)).flatten()\n",
    "fake_data_freq = np.round(fake_data_freq).astype(int)\n",
    "bank_df_train['TransactionFreq'] = fake_data_freq\n",
    "fake_data_freq = kde_freq.resample(len(bank_df_test)).flatten()\n",
    "fake_data_freq = np.round(fake_data_freq).astype(int)\n",
    "bank_df_test['TransactionFreq'] = fake_data_freq\n",
    "\n",
    "# fake_data_amt = kde_amnt.resample(len(bank_df_train)).flatten()\n",
    "# # fake_data_amt = np.round(fake_data_amt).astype(int)\n",
    "# bank_df_train['TransactionAmnt'] = fake_data_amt\n",
    "# fake_data_amt = kde_amnt.resample(len(bank_df_test)).flatten()\n",
    "# # fake_data_amt = np.round(fake_data_amt).astype(int)\n",
    "# bank_df_test['TransactionAmnt'] = fake_data_amt\n",
    "\n",
    "# print(bank_df_train['TransactionAmnt'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Transaction History 2\n",
    "Detailed transaction data offers insights into spending patterns and engagement. (Transaction amount in the last 28 days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reference set\n",
    "# Warning: File size slightly big\n",
    "trans_hist_data = pd.read_excel('./data/transaction_history.xlsx')\n",
    "\n",
    "trans_hist_data.dtypes\n",
    "# trans_hist_data.describe()\n",
    "\n",
    "# Extract the most recent 2 sets of 3 months assuming the most recent data is the most accurate\n",
    "trans_1st_3mths = trans_hist_data[(trans_hist_data['DATE'] >= pd.to_datetime('2019-01')) & (trans_hist_data['DATE'] <= pd.to_datetime('2019-03'))]\n",
    "trans_2ns_3mths = trans_hist_data[(trans_hist_data['DATE'] >= pd.to_datetime('2018-10')) & (trans_hist_data['DATE'] <= pd.to_datetime('2018-12'))]\n",
    "\n",
    "trans_dist_data = trans_1st_3mths.groupby('Account No').agg({'VALUE DATE': 'size', 'WITHDRAWAL AMT':'sum', 'DEPOSIT AMT': 'sum'}).reset_index()\n",
    "trans_dist_data['TOTAL AMT'] = -trans_dist_data['WITHDRAWAL AMT'] + trans_dist_data['DEPOSIT AMT']\n",
    "\n",
    "# kde = gaussian_kde(trans_dist_data['VALUE DATE'])\n",
    "# train['Transaction Freq'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "\n",
    "kde = gaussian_kde(trans_dist_data['TOTAL AMT'])\n",
    "bank_df_train['Transaction Amt'] = kde.resample(n_train).flatten().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Service support frequency\n",
    "Higher calls might indicate issues and dissatisfaction, affecting churn. Past year. Past month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0        0              2          1               0          181,450       0   \n",
      "1        0              2          1               1           49,504       0   \n",
      "2        0              2          1               0          184,867       0   \n",
      "3  148,883              1          1               1           84,561       0   \n",
      "4        0              2          1               1           15,069       0   \n",
      "\n",
      "  ChurnDate    SignDate  TransactionFreq  Transaction Amt  \\\n",
      "0       nan  2020-03-08             1120       -1,708,075   \n",
      "1       nan  2022-12-17                3       -3,138,542   \n",
      "2       nan  2013-06-08             -364        5,550,146   \n",
      "3       nan  2021-07-08              356        1,274,320   \n",
      "4       nan  2018-05-19              318        2,055,941   \n",
      "\n",
      "   CallSupportFrequency  \n",
      "0                    14  \n",
      "1                    47  \n",
      "2                    36  \n",
      "3                     7  \n",
      "4                    15  \n"
     ]
    }
   ],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['ServiceSupportFrequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "print(bank_df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.Months Inactive\n",
    "Indicates customer disengagement, potentially preceding churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    2\n",
      "3    0\n",
      "4    1\n",
      "5    2\n",
      "6    3\n",
      "7    1\n",
      "8    1\n",
      "9    0\n",
      "10   0\n",
      "11   0\n",
      "12   0\n",
      "13   1\n",
      "14   0\n",
      "15   1\n",
      "16   3\n",
      "17   0\n",
      "18   2\n",
      "19   1\n",
      "Name: MonthsInactive, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3101)\n",
    "bank_df_train['MonthsInactive'] = np.minimum(np.random.normal(0.5, 1.5, n_train), bank_df_train['Tenure'] * 12)\n",
    "bank_df_train['MonthsInactive'] = np.maximum(bank_df_train['MonthsInactive'], 0)\n",
    "\n",
    "print(bank_df_train['MonthsInactive'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.Net Promoter Score (NPS)\n",
    "Measure of customer satisfaction and loyalty.\n",
    "Scaled from 1 to 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1         10\n",
      "2          0\n",
      "3          4\n",
      "4         10\n",
      "          ..\n",
      "164879     3\n",
      "164931     9\n",
      "164961     2\n",
      "164998     7\n",
      "165012     8\n",
      "Name: NPS, Length: 23221, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "nps = pd.read_csv('./data/NPS.csv')\n",
    "\n",
    "nps_data = nps.groupby('Customer Name').agg({'NPS':'mean'}).reset_index()\n",
    "kde = gaussian_kde(nps_data['NPS'])\n",
    "bank_df_train['NPS'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "\n",
    "print(bank_df_train['NPS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.Education\n",
    "Education level might influence financial behavior and churn.\n",
    "Shld be correlated to 5. Acct Balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  EstimatedSalary  Exited  ChurnDate  \\\n",
      "0        0              2  ...          181,450       0        nan   \n",
      "1        0              2  ...           49,504       0        nan   \n",
      "2        0              2  ...          184,867       0        nan   \n",
      "3  148,883              1  ...           84,561       0        nan   \n",
      "4        0              2  ...           15,069       0        nan   \n",
      "\n",
      "     SignDate TransactionFreq Transaction Amt  CallSupportFrequency  \\\n",
      "0  2020-03-08            1120      -1,708,075                    14   \n",
      "1  2022-12-17               3      -3,138,542                    47   \n",
      "2  2013-06-08            -364       5,550,146                    36   \n",
      "3  2021-07-08             356       1,274,320                     7   \n",
      "4  2018-05-19             318       2,055,941                    15   \n",
      "\n",
      "   MonthsInactive  NPS      Education  \n",
      "0               1    0        Unknown  \n",
      "1               1   10        College  \n",
      "2               2    0  Post-Graduate  \n",
      "3               0    4    High School  \n",
      "4               1   10        Unknown  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "education = education_marital['Education_Level'].unique()\n",
    "\n",
    "edu, counts = np.unique(education, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(edu)}\n",
    "numerical_data = [value_to_index[value] for value in education]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [edu[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Education'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.Employment Status\n",
    "Indicates financial stability, affecting churn likelihood. \n",
    "Shld be correlated to 5. Acct Balance & 21. Education  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Exited  ChurnDate    SignDate  \\\n",
      "0        0              2  ...       0        nan  2020-03-08   \n",
      "1        0              2  ...       0        nan  2022-12-17   \n",
      "2        0              2  ...       0        nan  2013-06-08   \n",
      "3  148,883              1  ...       0        nan  2021-07-08   \n",
      "4        0              2  ...       0        nan  2018-05-19   \n",
      "\n",
      "   TransactionFreq Transaction Amt CallSupportFrequency  MonthsInactive  NPS  \\\n",
      "0             1120      -1,708,075                   14               1    0   \n",
      "1                3      -3,138,542                   47               1   10   \n",
      "2             -364       5,550,146                   36               2    0   \n",
      "3              356       1,274,320                    7               0    4   \n",
      "4              318       2,055,941                   15               1   10   \n",
      "\n",
      "       Education  Employment Status  \n",
      "0        Unknown            student  \n",
      "1        College         technician  \n",
      "2  Post-Graduate             admin.  \n",
      "3    High School       entrepreneur  \n",
      "4        Unknown      self-employed  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "employment = pd.read_csv(\"./data/employment.csv\")\n",
    "\n",
    "employment_data = employment['job'].unique()\n",
    "\n",
    "employment_status, counts = np.unique(employment_data, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(employment_status)}\n",
    "numerical_data = [value_to_index[value] for value in employment_data]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [employment_status[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Employment Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.Marital Status\n",
    "Can impact financial decision-making and churn behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  ChurnDate    SignDate  TransactionFreq  \\\n",
      "0        0              2  ...        nan  2020-03-08             1120   \n",
      "1        0              2  ...        nan  2022-12-17                3   \n",
      "2        0              2  ...        nan  2013-06-08             -364   \n",
      "3  148,883              1  ...        nan  2021-07-08              356   \n",
      "4        0              2  ...        nan  2018-05-19              318   \n",
      "\n",
      "   Transaction Amt CallSupportFrequency MonthsInactive  NPS      Education  \\\n",
      "0       -1,708,075                   14              1    0        Unknown   \n",
      "1       -3,138,542                   47              1   10        College   \n",
      "2        5,550,146                   36              2    0  Post-Graduate   \n",
      "3        1,274,320                    7              0    4    High School   \n",
      "4        2,055,941                   15              1   10        Unknown   \n",
      "\n",
      "   Employment Status  Marital Status  \n",
      "0            student        Divorced  \n",
      "1         technician        Divorced  \n",
      "2             admin.          Single  \n",
      "3       entrepreneur         Married  \n",
      "4      self-employed        Divorced  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "marital_status = education_marital['Marital_Status'].unique()\n",
    "\n",
    "marital, counts = np.unique(marital_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(marital)}\n",
    "numerical_data = [value_to_index[value] for value in marital_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [marital[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Marital Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.Housing Status\n",
    "Reflects stability and long-term commitment, influencing churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...    SignDate  TransactionFreq  Transaction Amt  \\\n",
      "0        0              2  ...  2020-03-08             1120       -1,708,075   \n",
      "1        0              2  ...  2022-12-17                3       -3,138,542   \n",
      "2        0              2  ...  2013-06-08             -364        5,550,146   \n",
      "3  148,883              1  ...  2021-07-08              356        1,274,320   \n",
      "4        0              2  ...  2018-05-19              318        2,055,941   \n",
      "\n",
      "   CallSupportFrequency MonthsInactive NPS      Education  Employment Status  \\\n",
      "0                    14              1   0        Unknown            student   \n",
      "1                    47              1  10        College         technician   \n",
      "2                    36              2   0  Post-Graduate             admin.   \n",
      "3                     7              0   4    High School       entrepreneur   \n",
      "4                    15              1  10        Unknown      self-employed   \n",
      "\n",
      "   Marital Status  Housing Status  \n",
      "0        Divorced    norent_noown  \n",
      "1        Divorced    norent_noown  \n",
      "2          Single    norent_noown  \n",
      "3         Married          rented  \n",
      "4        Divorced           owned  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "\n",
    "housing_status = housing['House_Ownership'].unique()\n",
    "\n",
    "house, counts = np.unique(housing_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(house)}\n",
    "numerical_data = [value_to_index[value] for value in housing_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [house[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Housing Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.Number of Dependents\n",
    "Impacts financial priorities and risk tolerance, affecting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  TransactionFreq  Transaction Amt  \\\n",
      "0        0              2  ...             1120       -1,708,075   \n",
      "1        0              2  ...                3       -3,138,542   \n",
      "2        0              2  ...             -364        5,550,146   \n",
      "3  148,883              1  ...              356        1,274,320   \n",
      "4        0              2  ...              318        2,055,941   \n",
      "\n",
      "   CallSupportFrequency  MonthsInactive NPS      Education  Employment Status  \\\n",
      "0                    14               1   0        Unknown            student   \n",
      "1                    47               1  10        College         technician   \n",
      "2                    36               2   0  Post-Graduate             admin.   \n",
      "3                     7               0   4    High School       entrepreneur   \n",
      "4                    15               1  10        Unknown      self-employed   \n",
      "\n",
      "   Marital Status  Housing Status  Dependants  \n",
      "0        Divorced    norent_noown           2  \n",
      "1        Divorced    norent_noown           3  \n",
      "2          Single    norent_noown           3  \n",
      "3         Married          rented           4  \n",
      "4        Divorced           owned           2  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "dependants_df = pd.read_csv('./data/education+dependents+maritalstatus/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(dependants_df['Dependent_count'])\n",
    "\n",
    "bank_df_train['Dependants'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_train['Dependants'] = np.round(bank_df_train['Dependants']).astype(int)\n",
    "bank_df_test['Dependants'] = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "bank_df_test['Dependants'] = np.round(bank_df_test['Dependants']).astype(int)\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25.Marketing Offers Accepted\n",
    "Indicates responsiveness to incentives, affecting churn. Range 0-1, (percentage of marketing offers they accept, e.g.5 offer, 4 accepted, the value of the column 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Transaction Amt  CallSupportFrequency  \\\n",
      "0        0              2  ...       -1,708,075                    14   \n",
      "1        0              2  ...       -3,138,542                    47   \n",
      "2        0              2  ...        5,550,146                    36   \n",
      "3  148,883              1  ...        1,274,320                     7   \n",
      "4        0              2  ...        2,055,941                    15   \n",
      "\n",
      "   MonthsInactive  NPS      Education Employment Status  Marital Status  \\\n",
      "0               1    0        Unknown           student        Divorced   \n",
      "1               1   10        College        technician        Divorced   \n",
      "2               2    0  Post-Graduate            admin.          Single   \n",
      "3               0    4    High School      entrepreneur         Married   \n",
      "4               1   10        Unknown     self-employed        Divorced   \n",
      "\n",
      "   Housing Status  Dependants  MarketingOffersAcceptance  \n",
      "0    norent_noown           2                          0  \n",
      "1    norent_noown           3                          0  \n",
      "2    norent_noown           3                          0  \n",
      "3          rented           4                          0  \n",
      "4           owned           2                          0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "marketing_df = pd.read_csv('./data/marketing offers/marketing_campaign.csv', sep=';')\n",
    "\n",
    "\n",
    "marketing_df[\"MarketingOffersAcceptance\"] = (marketing_df['AcceptedCmp1'] + marketing_df['AcceptedCmp2'] + marketing_df['AcceptedCmp3'] + marketing_df['AcceptedCmp4'] + marketing_df['AcceptedCmp5']) / 5\n",
    "# print(marketing_df.head())\n",
    "\n",
    "kde = gaussian_kde(marketing_df['MarketingOffersAcceptance'])\n",
    "\n",
    "bank_df_train['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_test['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.Channel Used for Transactions\n",
    "Reflects preferred banking channels and engagement level. \n",
    "faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  CallSupportFrequency  MonthsInactive  NPS  \\\n",
      "0        0              2  ...                    14               1    0   \n",
      "1        0              2  ...                    47               1   10   \n",
      "2        0              2  ...                    36               2    0   \n",
      "3  148,883              1  ...                     7               0    4   \n",
      "4        0              2  ...                    15               1   10   \n",
      "\n",
      "       Education Employment Status Marital Status  Housing Status  Dependants  \\\n",
      "0        Unknown           student       Divorced    norent_noown           2   \n",
      "1        College        technician       Divorced    norent_noown           3   \n",
      "2  Post-Graduate            admin.         Single    norent_noown           3   \n",
      "3    High School      entrepreneur        Married          rented           4   \n",
      "4        Unknown     self-employed       Divorced           owned           2   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod  \n",
      "0                          0               Mailed check  \n",
      "1                          0               Mailed check  \n",
      "2                          0  Bank transfer (automatic)  \n",
      "3                          0               Mailed check  \n",
      "4                          0               Mailed check  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "transaction_channel_df = pd.read_csv('./data/main_payment_method/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# print(transaction_channel_df.head())\n",
    "methods = transaction_channel_df['PaymentMethod'].unique().tolist()\n",
    "print(methods)\n",
    "faked_data = [random.choice(methods) for _ in range(len(bank_df_train))]\n",
    "faked_data_2 = [random.choice(methods) for _ in range(len(bank_df_test))]\n",
    "\n",
    "bank_df_train['PaymentMethod'] = faked_data\n",
    "bank_df_test['PaymentMethod'] = faked_data_2\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27.Customer Satisfaction Surveys\n",
    "Provides direct feedback on satisfaction levels, predicting churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    3\n",
      "2    2\n",
      "3    4\n",
      "4    1\n",
      "5    2\n",
      "6    5\n",
      "7    4\n",
      "8    5\n",
      "9    3\n",
      "Name: CustomerSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "cust_satisfaction_df = pd.read_csv('./data/satisfaction score/Customer-Churn-Records.csv')\n",
    "\n",
    "kde = gaussian_kde(cust_satisfaction_df['Satisfaction Score'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 5)\n",
    "fake_data = np.round(fake_data).astype(int)\n",
    "\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 5)\n",
    "fake_data_2 = np.round(fake_data_2).astype(int)\n",
    "\n",
    "bank_df_train['CustomerSatisfaction'] = fake_data\n",
    "bank_df_test['CustomerSatisfaction'] = fake_data_2\n",
    "# print(len(bank_df_test))\n",
    "# print(len(fake_data_2))\n",
    "\n",
    "print(bank_df_train['CustomerSatisfaction'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.Feature Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    4\n",
      "2    3\n",
      "3    1\n",
      "4    1\n",
      "Name: FeatureSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with your overall delivery experience at Ali?                    1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['FeatureSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_test['FeatureSatisfaction'] = kde.resample(len(bank_df_test)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['FeatureSatisfaction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29.Support Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    5\n",
      "2    2\n",
      "3    3\n",
      "4    2\n",
      "Name: SupportSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with the speed of delivery at Alis?                                1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['SupportSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_test['SupportSatisfaction'] = kde.resample(len(bank_df_test)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['SupportSatisfaction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.Service Support Frequency (per mth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         11\n",
      "1         36\n",
      "2          4\n",
      "3         17\n",
      "4         34\n",
      "          ..\n",
      "164879     9\n",
      "164931     7\n",
      "164961    35\n",
      "164998     2\n",
      "165012     7\n",
      "Name: ServiceSupportFrequency, Length: 23221, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['ServiceSupportFrequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "\n",
    "print(bank_df_train['ServiceSupportFrequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.Relationship Count\n",
    "Reflects the breadth of the customer's relationship with the bank.\n",
    "Shld be correlated to 6: No. of products   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    469145\n",
      "1     19338\n",
      "2     14960\n",
      "3     15249\n",
      "4      6305\n",
      "Name: RelationshipCount, dtype: int32\n",
      "9635798\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "relationship_count = pd.read_csv('./data/loan/credit_train.csv')\n",
    "relationship_count['Current Loan Amount'].fillna(0, inplace=True) \n",
    "\n",
    "if np.any(np.isinf(relationship_count['Current Loan Amount'])):\n",
    "    # Handle infinite values, such as replacing them with a large finite value\n",
    "    relationship_count['Current Loan Amount'].replace([np.inf, -np.inf], np.finfo(np.float64).max, inplace=True)\n",
    "\n",
    "\n",
    "median_loan_amount = relationship_count['Current Loan Amount'].median()\n",
    "below_median = relationship_count[relationship_count['Current Loan Amount'] < median_loan_amount]\n",
    "above_median = relationship_count[relationship_count['Current Loan Amount'] >= median_loan_amount]\n",
    "\n",
    "# print(above_median)\n",
    "kde_upper = gaussian_kde(above_median['Current Loan Amount'])\n",
    "kde_lower = gaussian_kde(below_median['Current Loan Amount'])\n",
    "\n",
    "bank_df_train['RelationshipCount'] = np.where(bank_df_train['CustomerSatisfaction'] >= 4, abs(kde_upper.resample(n_train).flatten()/12).astype(int) , abs(kde_lower.resample(n_train).flatten()/12).astype(int))\n",
    "\n",
    "\n",
    "# kde = gaussian_kde(relationship_count['Current Loan Amount'])\n",
    "# bank_df_train['RelationshipCount'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "\n",
    "print(bank_df_train['RelationshipCount'].head())\n",
    "print(bank_df_train['RelationshipCount'].max())\n",
    "print(bank_df_train['RelationshipCount'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Income Source\n",
    "Indicates financial stability and potential churn risk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Private', 'Local-gov', 'Self-emp-not-inc', 'Federal-gov', 'State-gov', 'Self-emp-inc', 'Without-pay', 'Never-worked']\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Housing Status  Dependants  \\\n",
      "0        0              2  ...    norent_noown           2   \n",
      "1        0              2  ...    norent_noown           3   \n",
      "2        0              2  ...    norent_noown           3   \n",
      "3  148,883              1  ...          rented           4   \n",
      "4        0              2  ...           owned           2   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod CustomerSatisfaction  \\\n",
      "0                          0               Mailed check                    4   \n",
      "1                          0               Mailed check                    3   \n",
      "2                          0  Bank transfer (automatic)                    2   \n",
      "3                          0               Mailed check                    4   \n",
      "4                          0               Mailed check                    1   \n",
      "\n",
      "  FeatureSatisfaction  SupportSatisfaction  ServiceSupportFrequency  \\\n",
      "0                   2                    2                       11   \n",
      "1                   4                    5                       36   \n",
      "2                   3                    2                        4   \n",
      "3                   1                    3                       17   \n",
      "4                   1                    2                       34   \n",
      "\n",
      "   RelationshipCount  IncomeSource  \n",
      "0             469145  Self-emp-inc  \n",
      "1              19338   Federal-gov  \n",
      "2              14960       Private  \n",
      "3              15249  Never-worked  \n",
      "4               6305  Self-emp-inc  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "income_source_df = pd.read_csv('./data/income source/adult.csv')\n",
    "\n",
    "# print(transaction_channel_df.head())\n",
    "income_sourcs = income_source_df['workclass'].unique().tolist()\n",
    "income_sourcs.remove('?')\n",
    "print(income_sourcs)\n",
    "faked_data = [random.choice(income_sourcs) for _ in range(len(bank_df_train))]\n",
    "faked_data_2 = [random.choice(income_sourcs) for _ in range(len(bank_df_test))]\n",
    "\n",
    "bank_df_train['IncomeSource'] = faked_data\n",
    "bank_df_test['IncomeSource'] = faked_data_2\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Credit Utilization\n",
    "Reflects financial health and potential churn risk for credit customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Dependants  MarketingOffersAcceptance  \\\n",
      "0        0              2  ...           2                          0   \n",
      "1        0              2  ...           3                          0   \n",
      "2        0              2  ...           3                          0   \n",
      "3  148,883              1  ...           4                          0   \n",
      "4        0              2  ...           2                          0   \n",
      "\n",
      "               PaymentMethod  CustomerSatisfaction FeatureSatisfaction  \\\n",
      "0               Mailed check                     4                   2   \n",
      "1               Mailed check                     3                   4   \n",
      "2  Bank transfer (automatic)                     2                   3   \n",
      "3               Mailed check                     4                   1   \n",
      "4               Mailed check                     1                   1   \n",
      "\n",
      "  SupportSatisfaction  ServiceSupportFrequency  RelationshipCount  \\\n",
      "0                   2                       11             469145   \n",
      "1                   5                       36              19338   \n",
      "2                   2                        4              14960   \n",
      "3                   3                       17              15249   \n",
      "4                   2                       34               6305   \n",
      "\n",
      "   IncomeSource  CreditUtilization  \n",
      "0  Self-emp-inc                  1  \n",
      "1   Federal-gov                  0  \n",
      "2       Private                  0  \n",
      "3  Never-worked                  0  \n",
      "4  Self-emp-inc                  0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_df = pd.read_csv('./data/credit utilization/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(credit_df['Avg_Utilization_Ratio'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 1)\n",
    "# fake_data = np.round(fake_data).astype(int)\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 1)\n",
    "\n",
    "bank_df_train['CreditUtilization'] = fake_data\n",
    "bank_df_test['CreditUtilization'] = fake_data_2\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. Response to Previous Retention Efforts\n",
    "Records success or failure of previous retention efforts, guiding future strategies. % 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "10   0\n",
      "11   0\n",
      "12   0\n",
      "13   0\n",
      "14   0\n",
      "15   0\n",
      "16   1\n",
      "17   0\n",
      "18   0\n",
      "19   0\n",
      "Name: Retention, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "retention_df = pd.read_csv('./data/retention/HR_comma_sep.csv')\n",
    "\n",
    "kde = gaussian_kde(retention_df['promotion_last_5years'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 1)\n",
    "\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 1)\n",
    "\n",
    "\n",
    "bank_df_train['Retention'] = fake_data\n",
    "bank_df_test['Retention'] = fake_data_2\n",
    "\n",
    "print(bank_df_train['Retention'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. Change in behavior before n after\n",
    "Average of percentage of increase/decrease (ranging from 0 - infinity, but most of the times it will be ard 0-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   1\n",
      "6   1\n",
      "7   1\n",
      "8   1\n",
      "9   1\n",
      "Name: ChangeInBehaviourMkt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bank_df_train['ChangeInBehaviourMkt'] = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "bank_df_test['ChangeInBehaviourMkt']= np.random.normal(1, 0.25, len(bank_df_test))\n",
    "# test = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "# # print(test)\n",
    "# bank_df_train['ChangeInBehaviourMkt'] = test.astype(float)\n",
    "\n",
    "print(bank_df_train['ChangeInBehaviourMkt'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. Change in behavior before n after for Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1\n",
      "1   0\n",
      "2   1\n",
      "3   1\n",
      "4   0\n",
      "Name: ChanegInBehaviourCust, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bank_df_train['ChanegInBehaviourCust'] = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "bank_df_test['ChanegInBehaviourCust']= np.random.normal(1, 0.25, len(bank_df_test))\n",
    "\n",
    "print(bank_df_train['ChanegInBehaviourCust'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. Previous Lifecycle status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Reactivated\n",
      "1    Reactivated\n",
      "2        Dormant\n",
      "3        Dormant\n",
      "4        Dormant\n",
      "5        Churned\n",
      "6        Dormant\n",
      "7    Reactivated\n",
      "8    Reactivated\n",
      "9    Reactivated\n",
      "Name: PrevLifecycle, dtype: object\n"
     ]
    }
   ],
   "source": [
    "life_cycles = ['Active', 'Dormant', 'Reactivated'] #everything but churned\n",
    "\n",
    "bank_df_train['PrevLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['Exited'] == 1 else np.random.choice(life_cycles), axis=1)\n",
    "\n",
    "print(bank_df_train['PrevLifecycle'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Current Lifecycle status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PrevLifecycle CurrLifecycle\n",
      "0   Reactivated        Active\n",
      "1   Reactivated       Dormant\n",
      "2       Dormant       Dormant\n",
      "3       Dormant   Reactivated\n",
      "4       Dormant       Dormant\n",
      "5       Churned       Churned\n",
      "6       Dormant       Dormant\n",
      "7   Reactivated       Dormant\n",
      "8   Reactivated        Active\n",
      "9   Reactivated       Dormant\n"
     ]
    }
   ],
   "source": [
    "prev_active = ['Active', 'Dormant'] #excluding churn, also same for reactivated\n",
    "prev_dormant = ['Dormant', 'Reactivated'] #excluding churn\n",
    "\n",
    "bank_df_train['CurrLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['PrevLifecycle'] == 'Churned' else \\\n",
    "                                                    np.random.choice(prev_active) if (row['PrevLifecycle'] == 'Active' or row['PrevLifecycle'] == 'Reactivated') else \\\n",
    "                                                    np.random.choice(prev_dormant) if row['PrevLifecycle'] == 'Dormant' else \\\n",
    "                                                    np.nan, axis=1)\n",
    "\n",
    "print(bank_df_train[['PrevLifecycle', 'CurrLifecycle']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. Customer Happiness Status \n",
    "1 == happy, 0 == unhappy\n",
    "\n",
    "Customer satisfaction survey score \n",
    "\n",
    "Relationship Count \n",
    "\n",
    "Response to previous retention efforts (no more yay)\n",
    "\n",
    "if we want the top 15.9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    1\n",
      "7    0\n",
      "8    1\n",
      "9    0\n",
      "Name: Happiness, dtype: int64\n",
      "percentage happy = 20.046509624908488\n"
     ]
    }
   ],
   "source": [
    "happiness_benchmark = 84.1\n",
    "\n",
    "# bank_df_train['Happiness'] = bank_df_train.apply(lambda row: 1 if row['CustomerSatisfaction'] + \\\n",
    "#                                                                   row['FeatureSatisfaction'] + \\\n",
    "#                                                                   row['SupportSatisfaction'] + \\\n",
    "#                                                                   row['NPS'] + \\\n",
    "#                                                                   row['Tenure'] >= happiness_benchmark else \\\n",
    "#                                                                   0, axis=1)\n",
    "\n",
    "\n",
    "# need to delete Custpercentile, RsPercentile and ResponsePercentile later\n",
    "bank_df_train['CustPercentile'] = bank_df_train['CustomerSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "bank_df_train['RsPercentile'] = bank_df_train['RelationshipCount'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "\n",
    "# print(bank_df_train['CustPercentile'].head(10))\n",
    "bank_df_train['Happiness'] = bank_df_train.apply(lambda row: 1 if (row['CustPercentile'] > happiness_benchmark and row['RsPercentile'] > happiness_benchmark ) else 0, axis=1)\n",
    "bank_df_train.drop(columns=['CustPercentile', 'RsPercentile'], inplace=True)\n",
    "\n",
    "print(bank_df_train['Happiness'].head(10))\n",
    "print(\"percentage happy =\", (bank_df_train['Happiness'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40.Price Sensitivity %\n",
    "26. marketing offers accepted %\n",
    "35. change in behaviour %\n",
    "\n",
    "Mkting Offers Accepted\n",
    "Change in behavior before n after for mkting offer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    35\n",
      "1    49\n",
      "2    37\n",
      "3    57\n",
      "4    28\n",
      "5    56\n",
      "6    52\n",
      "7    66\n",
      "8    83\n",
      "9    60\n",
      "10   29\n",
      "11   77\n",
      "12   57\n",
      "13   46\n",
      "14   36\n",
      "15   20\n",
      "16   89\n",
      "17   29\n",
      "18   70\n",
      "19   33\n",
      "Name: PriceSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MarketingOffersAcceptance_df = bank_df_train['MarketingOffersAcceptance'].apply(lambda x: stats.percentileofscore(bank_df_train['MarketingOffersAcceptance'], x))\n",
    "ChangeInBehaviourMkt_df = bank_df_train['ChangeInBehaviourMkt'].apply(lambda x: stats.percentileofscore(bank_df_train['ChangeInBehaviourMkt'], x))\n",
    "# print(MarketingOffersAcceptance_df.head())\n",
    "# print(ChangeInBehaviourMkt_df.head())\n",
    "bank_df_train['PriceSensitivity'] = (MarketingOffersAcceptance_df + ChangeInBehaviourMkt_df) / 2\n",
    "\n",
    "print(bank_df_train['PriceSensitivity'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41.Feature Driven % \n",
    "28. Customer satisfaction survey 0-5\n",
    "6. num products 1-4\n",
    "29. Feature Satisfaction 0-5\n",
    "\n",
    "Number of products last 1 year\n",
    "Feature Satisfaction Column (0 to 1)\n",
    "Feature Support freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59\n",
      "1    65\n",
      "2    52\n",
      "3    36\n",
      "4    32\n",
      "5    29\n",
      "6    62\n",
      "7    32\n",
      "8    85\n",
      "9    49\n",
      "10   72\n",
      "11   49\n",
      "12   35\n",
      "13   36\n",
      "14   55\n",
      "15   65\n",
      "16   65\n",
      "17   59\n",
      "18   36\n",
      "19   35\n",
      "Name: FeatureSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(bank_df_train['NumOfProducts'].max())\n",
    "# print(bank_df_train['NumOfProducts'].min())\n",
    "\n",
    "# feature_driven = bank_df_train['CustomerSatisfaction'] + bank_df_train['NumOfProducts'] + bank_df_train['FeatureSatisfaction']\n",
    "# percentiles = np.percentile(feature_driven, [0, 25, 50, 75, 100]) \n",
    "\n",
    "# def assign_percentile(metric):\n",
    "#     if metric <= percentiles[1]:\n",
    "#         return ((metric / percentiles[1]) * 25)\n",
    "#     elif metric <= percentiles[2]:\n",
    "#         return (25 + ((metric - percentiles[1]) / (percentiles[2] - percentiles[1])) * 25)\n",
    "#     elif metric <= percentiles[3]:\n",
    "#         return (50 + ((metric - percentiles[2]) / (percentiles[3] - percentiles[2])) * 25)\n",
    "#     else:\n",
    "#         return (75 + ((metric - percentiles[3]) / (percentiles[4] - percentiles[3])) * 25)\n",
    "        \n",
    "# bank_df_train['FeatureSensitivity'] = feature_driven.apply(assign_percentile)\n",
    "# bank_df_train['FeatureSensitivity'] = bank_df_train['FeatureSensitivity'].replace(np.NaN, 0, regex=True)\n",
    "\n",
    "CustomerSatisfaction_df = bank_df_train['CustomerSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "NumOfProducts_df = bank_df_train['NumOfProducts'].apply(lambda x: stats.percentileofscore(bank_df_train['NumOfProducts'], x))\n",
    "FeatureSatisfaction_df = bank_df_train['FeatureSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['FeatureSatisfaction'], x))\n",
    "\n",
    "bank_df_train['FeatureSensitivity'] = (CustomerSatisfaction_df + NumOfProducts_df + FeatureSatisfaction_df) / 3\n",
    "\n",
    "print(bank_df_train['FeatureSensitivity'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42.Service Driven % \n",
    "31. service support freq per month number\n",
    "39. Customer Happiness Status binary\n",
    "36. Change in behavior before n after for Support %\n",
    "\n",
    "CALL Support frequency\n",
    "Support Satisfaction Column (0 to 1)\n",
    "Change in behavior before n after support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   46\n",
      "1   71\n",
      "2   47\n",
      "3   45\n",
      "4   48\n",
      "Name: ServiceSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(bank_df_train['ServiceSupportFrequency'])\n",
    "CallSupportFrequency_df = bank_df_train['CallSupportFrequency'].apply(lambda x: stats.percentileofscore(bank_df_train['CallSupportFrequency'], x))\n",
    "ServiceSupportFrequency_df = bank_df_train['ServiceSupportFrequency'].apply(lambda x: stats.percentileofscore(bank_df_train['ServiceSupportFrequency'], x))\n",
    "SupportSatisfaction_df = bank_df_train['SupportSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['SupportSatisfaction'], x))\n",
    "ChanegInBehaviourCust_df = bank_df_train['ChanegInBehaviourCust'].apply(lambda x: stats.percentileofscore(bank_df_train['ChanegInBehaviourCust'], x))\n",
    "\n",
    "bank_df_train['ServiceSensitivity'] = (CallSupportFrequency_df + ServiceSupportFrequency_df + SupportSatisfaction_df + ChanegInBehaviourCust_df) / 4\n",
    "\n",
    "print(bank_df_train['ServiceSensitivity'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43.Customer Personas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PriceSensitivity  FeatureSensitivity  ServiceSensitivity  \\\n",
      "0                     25                  42                  33   \n",
      "1                     27                  35                  38   \n",
      "2                     27                  38                  35   \n",
      "3                     41                  26                  32   \n",
      "4                     26                  30                  44   \n",
      "...                  ...                 ...                 ...   \n",
      "164879                30                  35                  35   \n",
      "164931                37                  34                  28   \n",
      "164961                43                  17                  40   \n",
      "164998                34                  34                  32   \n",
      "165012                32                  32                  36   \n",
      "\n",
      "           CustomerPersona  \n",
      "0       FeatureSensitivity  \n",
      "1       ServiceSensitivity  \n",
      "2       FeatureSensitivity  \n",
      "3         PriceSensitivity  \n",
      "4       ServiceSensitivity  \n",
      "...                    ...  \n",
      "164879  ServiceSensitivity  \n",
      "164931    PriceSensitivity  \n",
      "164961    PriceSensitivity  \n",
      "164998    PriceSensitivity  \n",
      "165012  ServiceSensitivity  \n",
      "\n",
      "[23221 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['PriceSensitivity', 'FeatureSensitivity', 'ServiceSensitivity']\n",
    "\n",
    "bank_df_train[columns_to_normalize] = bank_df_train[columns_to_normalize].div(bank_df_train[columns_to_normalize].sum(axis=1), axis=0) * 100\n",
    "bank_df_train['CustomerPersona'] = bank_df_train[columns_to_normalize].idxmax(axis=1)\n",
    "\n",
    "print(bank_df_train[['PriceSensitivity', 'FeatureSensitivity', 'ServiceSensitivity', 'CustomerPersona']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. Social Influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: SocialInfluencer, dtype: int64\n",
      "percentage social influencer = 16.618578011282892\n"
     ]
    }
   ],
   "source": [
    "social_benchmark = 84.1\n",
    "\n",
    "bank_df_train['SocialInfluencer'] = bank_df_train['NPS'].apply(lambda x: stats.percentileofscore(bank_df_train['NPS'], x))\n",
    "bank_df_train['SocialInfluencer'] = bank_df_train.apply(lambda row: 1 if (row['SocialInfluencer'] > happiness_benchmark) else 0, axis=1)\n",
    "\n",
    "print(bank_df_train['SocialInfluencer'].head(10))\n",
    "print(\"percentage social influencer =\", (bank_df_train['SocialInfluencer'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "1. covarience matrix\n",
    "2. LDA\n",
    "3. apriori\n",
    "4. domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#domain knowledge...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training:\n",
    "1. Random forest\n",
    "2. XGBoost\n",
    "3. Logistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
