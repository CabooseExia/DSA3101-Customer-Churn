{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "np.random.seed(3101)\n",
    "random_state = np.random.RandomState(3101)\n",
    "fake = Faker()\n",
    "pd.set_option('display.float_format', lambda x: '{:.6f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data:\n",
    "bank1 = archive  \n",
    "bank2 = bank+marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.getcwd())\n",
    "bank_df_train = pd.read_csv('./data/main/train.csv')\n",
    "bank_df_test = pd.read_csv('./data/main/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender       Age  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male 33.000000   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male 33.000000   \n",
      "2   2    15694510           Hsueh          678    France   Male 40.000000   \n",
      "3   3    15741417             Kao          581    France   Male 34.000000   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male 33.000000   \n",
      "\n",
      "   Tenure       Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       3      0.000000              2   1.000000        0.000000   \n",
      "1       1      0.000000              2   1.000000        1.000000   \n",
      "2      10      0.000000              2   1.000000        0.000000   \n",
      "3       2 148882.540000              1   1.000000        1.000000   \n",
      "4       5      0.000000              2   1.000000        1.000000   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0    181449.970000       0  \n",
      "1     49503.500000       0  \n",
      "2    184866.690000       0  \n",
      "3     84560.880000       0  \n",
      "4     15068.830000       0  \n",
      "165034\n"
     ]
    }
   ],
   "source": [
    "print(bank_df_train.head())\n",
    "print(len(bank_df_train))\n",
    "\n",
    "# bank_df_train_clean = bank_df_train.drop_duplicates(subset=\"CustomerId\", keep=\"first\")\n",
    "# print(len(bank_df_train_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  CustomerId    Surname  CreditScore Geography  Gender       Age  \\\n",
      "0  165034    15773898   Lucchese          586    France  Female 23.000000   \n",
      "1  165035    15782418       Nott          683    France  Female 46.000000   \n",
      "2  165036    15807120         K?          656    France  Female 34.000000   \n",
      "3  165037    15808905  O'Donnell          681    France    Male 36.000000   \n",
      "4  165038    15607314    Higgins          752   Germany    Male 38.000000   \n",
      "\n",
      "   Tenure       Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2      0.000000              2   0.000000        1.000000   \n",
      "1       2      0.000000              1   1.000000        0.000000   \n",
      "2       7      0.000000              2   1.000000        0.000000   \n",
      "3       8      0.000000              1   1.000000        0.000000   \n",
      "4      10 121263.620000              1   1.000000        0.000000   \n",
      "\n",
      "   EstimatedSalary  \n",
      "0    160976.750000  \n",
      "1     72549.270000  \n",
      "2    138882.090000  \n",
      "3    113931.570000  \n",
      "4    139431.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110023"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bank_df_test.head())\n",
    "len(bank_df_test)\n",
    "# duplicates = bank_df_test.duplicated(subset=['CustomerId'], keep=False)\n",
    "# print(duplicates)\n",
    "#no \"exited\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "\n",
    "Removed CustomerId column in both test & train since it is an unused var in the original dataset\n",
    "All other columns returns no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23221\n"
     ]
    }
   ],
   "source": [
    "# bank_df_train = bank_df_train.loc[:, bank_df_train.columns!='CustomerId'] # extract all columns except for CustomerId\n",
    "# print(bank_df_train[bank_df_train.duplicated() == True]) # check for duplicate columns \n",
    "\n",
    "# bank_df_test = bank_df_test.loc[:, bank_df_test.columns!='CustomerId']\n",
    "\n",
    "### DELETE OR COMMENT OUT THIS LATER ###\n",
    "bank_df_train.drop_duplicates(subset=['CustomerId'], inplace=True)\n",
    "bank_df_test.drop_duplicates(subset=['CustomerId'], inplace=True)\n",
    "n_train = len(bank_df_train)\n",
    "print(n_train)\n",
    "### DELETE OR COMMENT OUT THIS LATER ###\n",
    "\n",
    "# n_test = len(bank_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding and populating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Churn Date: The exact date the customer decided to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          NaT\n",
      "1          NaT\n",
      "2          NaT\n",
      "3          NaT\n",
      "4          NaT\n",
      "5   2023-07-20\n",
      "6          NaT\n",
      "7          NaT\n",
      "8          NaT\n",
      "9          NaT\n",
      "Name: ChurnDate, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2023-01-01\"\n",
    "end_date = end_date = datetime.now().strftime('%Y-%m-%d') \n",
    "\n",
    "# random_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# random_dates_str = random_dates.strftime('%Y-%m-%d')\n",
    "# bank_df_train['ChurnDate'] = np.where(bank_df_train['Exited'] == 1, np.random.choice(random_dates_str) , np.nan) \n",
    "def generate_random_date(exited):\n",
    "    if exited == 1:\n",
    "        random_date = np.random.choice(pd.date_range(start=start_date, end=end_date, freq='D'))\n",
    "        return random_date\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "bank_df_train['ChurnDate'] = bank_df_train['Exited'].apply(generate_random_date)\n",
    "bank_df_train['ChurnDate'] = pd.to_datetime(bank_df_train['ChurnDate'])\n",
    "print(bank_df_train['ChurnDate'].head(10))\n",
    "# print(bank_df_train['ChurnDate'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Sign Up Date: When did the customer create an account\n",
    "has to be linked with churn date if any, and tenure. Tenure is usually rounded down, so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SignDate  ChurnDate  Tenure\n",
      "0  2020-06-02        NaT       3\n",
      "1  2022-12-24        NaT       1\n",
      "2  2013-05-09        NaT      10\n",
      "3  2021-01-18        NaT       2\n",
      "4  2018-06-30        NaT       5\n",
      "5  2019-01-02 2023-07-20       4\n",
      "6  2015-06-10        NaT       8\n",
      "7  2022-01-06        NaT       1\n",
      "8  2019-04-29        NaT       4\n",
      "9  2019-02-11        NaT       4\n"
     ]
    }
   ],
   "source": [
    "def generate_signon_date(churn_date, tenure, exited):\n",
    "    if exited == 0:\n",
    "        churn_date = \"2023-12-31\"\n",
    "    churn_date = pd.to_datetime(churn_date)\n",
    "    max = churn_date - pd.DateOffset(years=tenure)\n",
    "    min = churn_date - pd.DateOffset(years=(tenure + 1))\n",
    "    random_dates = pd.date_range(min, max, freq='D').strftime('%Y-%m-%d')\n",
    "    random_date = np.random.choice(random_dates)\n",
    "    return random_date\n",
    "\n",
    "\n",
    "bank_df_train['SignDate'] = bank_df_train.apply(lambda row: generate_signon_date(row['ChurnDate'], row['Tenure'], row['Exited']), axis = 1)\n",
    "print(bank_df_train[['SignDate', 'ChurnDate', 'Tenure']].head(10))\n",
    "\n",
    "bank_df_test['SignDate'] = bank_df_train.apply(lambda row: generate_signon_date(\"2023-12-31\", row['Tenure'], 0), axis = 1)\n",
    "# print(bank_df_train_clean.head(10))\n",
    "bank_df_train['SignDate'] = pd.to_datetime(bank_df_train['SignDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.Transaction History 1\n",
    "Detailed transaction data offers insights into spending patterns and engagement. (Transaction frequency in the last 28 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ChurnDate  TransactionFreq\n",
      "0         NaT              182\n",
      "1         NaT               78\n",
      "2         NaT                0\n",
      "3         NaT              481\n",
      "4         NaT                0\n",
      "5  2023-07-20                0\n",
      "6         NaT              721\n",
      "7         NaT              405\n",
      "8         NaT              418\n",
      "9         NaT               93\n",
      "10        NaT                0\n",
      "11        NaT              426\n",
      "12        NaT              265\n",
      "13        NaT              104\n",
      "14        NaT              293\n",
      "15        NaT              245\n",
      "16        NaT               14\n",
      "17        NaT              285\n",
      "18 2023-03-10                0\n",
      "19 2023-12-18                0\n"
     ]
    }
   ],
   "source": [
    "transaction_df = pd.read_excel('./data/transaction_history.xlsx')\n",
    "\n",
    "# print(transaction_df.head())\n",
    "transaction_df['DATE'] = pd.to_datetime(transaction_df['DATE'])\n",
    "\n",
    "grouped_df = transaction_df.groupby('Account No')\n",
    "\n",
    "results = []\n",
    "for group_name, group_data in grouped_df:\n",
    "    # Get max and min dates for the group\n",
    "    max_date = group_data['DATE'].max()\n",
    "    min_date = max_date - pd.Timedelta(days=28)\n",
    "    \n",
    "    # Filter group data for transactions within the date range\n",
    "    filtered_group = group_data[(group_data['DATE'] >= min_date) & (group_data['DATE'] <= max_date)]\n",
    "    \n",
    "    # Calculate transaction frequency and amount for the group\n",
    "    transaction_frequency = len(filtered_group)\n",
    "    transaction_amount = filtered_group['DEPOSIT AMT'].sum()\n",
    "    \n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        'Account No': group_name,\n",
    "        'Total Transaction Amount': transaction_amount,\n",
    "        'Transaction Frequency': transaction_frequency\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df['Total Transaction Amount'] = result_df['Total Transaction Amount'].astype(int)\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "# print(result_df['Total Transaction Amount'])\n",
    "\n",
    "# print(\"Minimum date in the dataset:\", min_date)\n",
    "# print(\"Maximum date in the dataset:\", max_date)\n",
    "\n",
    "kde_freq = gaussian_kde(result_df['Transaction Frequency'])\n",
    "kde_amnt = gaussian_kde(result_df['Total Transaction Amount'])\n",
    "# print(result_df['Total Transaction Amount'])\n",
    "\n",
    "fake_data_freq = kde_freq.resample(len(bank_df_train)).flatten()\n",
    "fake_data_freq = np.round(fake_data_freq).astype(int)\n",
    "bank_df_train['TransactionFreq'] = fake_data_freq\n",
    "fake_data_freq = kde_freq.resample(len(bank_df_test)).flatten()\n",
    "fake_data_freq = np.round(fake_data_freq).astype(int)\n",
    "bank_df_test['TransactionFreq'] = fake_data_freq\n",
    "\n",
    "# fake_data_amt = kde_amnt.resample(len(bank_df_train)).flatten()\n",
    "# # fake_data_amt = np.round(fake_data_amt).astype(int)\n",
    "# bank_df_train['TransactionAmnt'] = fake_data_amt\n",
    "# fake_data_amt = kde_amnt.resample(len(bank_df_test)).flatten()\n",
    "# # fake_data_amt = np.round(fake_data_amt).astype(int)\n",
    "# bank_df_test['TransactionAmnt'] = fake_data_amt\n",
    "\n",
    "# print(bank_df_train['TransactionAmnt'].head())\n",
    "date_28_days_ago = datetime.now() - timedelta(days=28)\n",
    "\n",
    "bank_df_train['TransactionFreq'] = np.where(\n",
    "    (bank_df_train['ChurnDate'] <= date_28_days_ago),\n",
    "    0,\n",
    "    bank_df_train['TransactionFreq']\n",
    ")\n",
    "\n",
    "bank_df_train['TransactionFreq'] = np.maximum(bank_df_train['TransactionFreq'], 0)\n",
    "\n",
    "print(bank_df_train[['ChurnDate', 'TransactionFreq']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Transaction History 2\n",
    "Detailed transaction data offers insights into spending patterns and engagement. (Transaction amount in the last 28 days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ChurnDate  TransactionFreq  Transaction Amt\n",
      "0         NaT              182      -10,186,409\n",
      "1         NaT               78       -2,244,355\n",
      "2         NaT                0                0\n",
      "3         NaT              481       -5,583,581\n",
      "4         NaT                0                0\n",
      "5  2023-07-20                0                0\n",
      "6         NaT              721        2,206,348\n",
      "7         NaT              405       -1,800,680\n",
      "8         NaT              418      -14,381,827\n",
      "9         NaT               93          -52,953\n",
      "10        NaT                0                0\n",
      "11        NaT              426       -3,693,888\n",
      "12        NaT              265        2,417,362\n",
      "13        NaT              104       -3,133,668\n",
      "14        NaT              293          204,837\n",
      "15        NaT              245           -9,039\n",
      "16        NaT               14       -2,767,129\n",
      "17        NaT              285        3,776,797\n",
      "18 2023-03-10                0                0\n",
      "19 2023-12-18                0                0\n"
     ]
    }
   ],
   "source": [
    "# Import reference set\n",
    "# Warning: File size slightly big\n",
    "trans_hist_data = pd.read_excel('./data/transaction_history.xlsx')\n",
    "\n",
    "trans_hist_data.dtypes\n",
    "# trans_hist_data.describe()\n",
    "\n",
    "# Extract the most recent 2 sets of 3 months assuming the most recent data is the most accurate\n",
    "trans_1st_3mths = trans_hist_data[(trans_hist_data['DATE'] >= pd.to_datetime('2019-01')) & (trans_hist_data['DATE'] <= pd.to_datetime('2019-03'))]\n",
    "trans_2ns_3mths = trans_hist_data[(trans_hist_data['DATE'] >= pd.to_datetime('2018-10')) & (trans_hist_data['DATE'] <= pd.to_datetime('2018-12'))]\n",
    "\n",
    "trans_dist_data = trans_1st_3mths.groupby('Account No').agg({'VALUE DATE': 'size', 'WITHDRAWAL AMT':'sum', 'DEPOSIT AMT': 'sum'}).reset_index()\n",
    "trans_dist_data['TOTAL AMT'] = -trans_dist_data['WITHDRAWAL AMT'] + trans_dist_data['DEPOSIT AMT']\n",
    "\n",
    "# kde = gaussian_kde(trans_dist_data['VALUE DATE'])\n",
    "# train['Transaction Freq'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "\n",
    "kde = gaussian_kde(trans_dist_data['TOTAL AMT'])\n",
    "bank_df_train['Transaction Amt'] = kde.resample(n_train).flatten().astype(float)\n",
    "\n",
    "date_28_days_ago = datetime.now() - timedelta(days=28)\n",
    "\n",
    "bank_df_train['Transaction Amt'] = np.where(\n",
    "    (bank_df_train['ChurnDate'] <= date_28_days_ago),\n",
    "    0,\n",
    "    bank_df_train['Transaction Amt']\n",
    ")\n",
    "\n",
    "bank_df_train['Transaction Amt'] = np.where(\n",
    "    (bank_df_train['TransactionFreq'] == 0),\n",
    "    0,\n",
    "    bank_df_train['Transaction Amt']\n",
    ")\n",
    "\n",
    "# bank_df_train['Transaction Amt'] = np.maximum(bank_df_train['Transaction Amt'], 0)\n",
    "\n",
    "print(bank_df_train[['ChurnDate', 'TransactionFreq', 'Transaction Amt']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Service support frequency\n",
    "Higher calls might indicate issues and dissatisfaction, affecting churn. Past year. Past month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0        0              2          1               0          181,450       0   \n",
      "1        0              2          1               1           49,504       0   \n",
      "2        0              2          1               0          184,867       0   \n",
      "3  148,883              1          1               1           84,561       0   \n",
      "4        0              2          1               1           15,069       0   \n",
      "\n",
      "  ChurnDate   SignDate  TransactionFreq  Transaction Amt  \\\n",
      "0       NaT 2020-06-02              182      -10,186,409   \n",
      "1       NaT 2022-12-24               78       -2,244,355   \n",
      "2       NaT 2013-05-09                0                0   \n",
      "3       NaT 2021-01-18              481       -5,583,581   \n",
      "4       NaT 2018-06-30                0                0   \n",
      "\n",
      "   ServiceSupportFrequency  \n",
      "0                        6  \n",
      "1                       21  \n",
      "2                        9  \n",
      "3                        2  \n",
      "4                       42  \n"
     ]
    }
   ],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['ServiceSupportFrequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "print(bank_df_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.Months Inactive\n",
    "Indicates customer disengagement, potentially preceding churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "5    2\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "10   0\n",
      "11   0\n",
      "12   0\n",
      "13   0\n",
      "14   0\n",
      "15   0\n",
      "16   0\n",
      "17   0\n",
      "18   1\n",
      "19   2\n",
      "Name: MonthsInactive, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3101)\n",
    "# bank_df_train['MonthsInactive'] = np.minimum(np.random.normal(0.5, 1.5, n_train), bank_df_train['Tenure'] * 12)\n",
    "# bank_df_train['MonthsInactive'] = np.maximum(bank_df_train['MonthsInactive'], 0)\n",
    "# bank_df_train['MonthsInactive'] = bank_df_train['TransactionFreq'].apply(lambda x: 0 if x > 0 else  \\\n",
    "#                                                                               np.maximum(np.minimum(np.random.normal(0.5, 1.5, n_train), bank_df_train['Tenure'] * 12), 0))\n",
    "bank_df_train['MonthsInactive'] = bank_df_train.apply(lambda row: \n",
    "    np.random.normal(0.5, 1.5) if row['TransactionFreq'] == 0 else 0,\n",
    "    axis=1)\n",
    "\n",
    "print(bank_df_train['MonthsInactive'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.Net Promoter Score (NPS)\n",
    "Measure of customer satisfaction and loyalty.\n",
    "Scaled from 1 to 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4\n",
      "1         0\n",
      "2         1\n",
      "3         7\n",
      "4         8\n",
      "         ..\n",
      "164879    8\n",
      "164931    2\n",
      "164961    8\n",
      "164998    6\n",
      "165012    8\n",
      "Name: NPS, Length: 23221, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "nps = pd.read_csv('./data/NPS.csv')\n",
    "\n",
    "nps_data = nps.groupby('Customer Name').agg({'NPS':'mean'}).reset_index()\n",
    "kde = gaussian_kde(nps_data['NPS'])\n",
    "bank_df_train['NPS'] = abs(kde.resample(n_train).flatten()).astype(int)\n",
    "\n",
    "print(bank_df_train['NPS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.Education\n",
    "Education level might influence financial behavior and churn.\n",
    "Shld be correlated to 5. Acct Balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  EstimatedSalary  Exited  ChurnDate   SignDate  \\\n",
      "0        0              2  ...          181,450       0        NaT 2020-06-02   \n",
      "1        0              2  ...           49,504       0        NaT 2022-12-24   \n",
      "2        0              2  ...          184,867       0        NaT 2013-05-09   \n",
      "3  148,883              1  ...           84,561       0        NaT 2021-01-18   \n",
      "4        0              2  ...           15,069       0        NaT 2018-06-30   \n",
      "\n",
      "  TransactionFreq Transaction Amt  ServiceSupportFrequency  MonthsInactive  \\\n",
      "0             182     -10,186,409                        6               0   \n",
      "1              78      -2,244,355                       21               0   \n",
      "2               0               0                        9               1   \n",
      "3             481      -5,583,581                        2               0   \n",
      "4               0               0                       42               1   \n",
      "\n",
      "   NPS      Education  \n",
      "0    4      Doctorate  \n",
      "1    0        College  \n",
      "2    1     Uneducated  \n",
      "3    7    High School  \n",
      "4    8  Post-Graduate  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "education = education_marital['Education_Level'].unique()\n",
    "\n",
    "edu, counts = np.unique(education, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(edu)}\n",
    "numerical_data = [value_to_index[value] for value in education]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [edu[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Education'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.Employment Status\n",
    "Indicates financial stability, affecting churn likelihood. \n",
    "Shld be correlated to 5. Acct Balance & 21. Education  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Exited  ChurnDate   SignDate  TransactionFreq  \\\n",
      "0        0              2  ...       0        NaT 2020-06-02              182   \n",
      "1        0              2  ...       0        NaT 2022-12-24               78   \n",
      "2        0              2  ...       0        NaT 2013-05-09                0   \n",
      "3  148,883              1  ...       0        NaT 2021-01-18              481   \n",
      "4        0              2  ...       0        NaT 2018-06-30                0   \n",
      "\n",
      "  Transaction Amt ServiceSupportFrequency  MonthsInactive  NPS      Education  \\\n",
      "0     -10,186,409                       6               0    4      Doctorate   \n",
      "1      -2,244,355                      21               0    0        College   \n",
      "2               0                       9               1    1     Uneducated   \n",
      "3      -5,583,581                       2               0    7    High School   \n",
      "4               0                      42               1    8  Post-Graduate   \n",
      "\n",
      "   Employment Status  \n",
      "0        blue-collar  \n",
      "1       entrepreneur  \n",
      "2        blue-collar  \n",
      "3           services  \n",
      "4             admin.  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "employment = pd.read_csv(\"./data/employment.csv\")\n",
    "\n",
    "employment_data = employment['job'].unique()\n",
    "\n",
    "employment_status, counts = np.unique(employment_data, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(employment_status)}\n",
    "numerical_data = [value_to_index[value] for value in employment_data]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [employment_status[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Employment Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.Marital Status\n",
    "Can impact financial decision-making and churn behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  ChurnDate   SignDate  TransactionFreq  \\\n",
      "0        0              2  ...        NaT 2020-06-02              182   \n",
      "1        0              2  ...        NaT 2022-12-24               78   \n",
      "2        0              2  ...        NaT 2013-05-09                0   \n",
      "3  148,883              1  ...        NaT 2021-01-18              481   \n",
      "4        0              2  ...        NaT 2018-06-30                0   \n",
      "\n",
      "   Transaction Amt ServiceSupportFrequency MonthsInactive  NPS      Education  \\\n",
      "0      -10,186,409                       6              0    4      Doctorate   \n",
      "1       -2,244,355                      21              0    0        College   \n",
      "2                0                       9              1    1     Uneducated   \n",
      "3       -5,583,581                       2              0    7    High School   \n",
      "4                0                      42              1    8  Post-Graduate   \n",
      "\n",
      "   Employment Status  Marital Status  \n",
      "0        blue-collar        Divorced  \n",
      "1       entrepreneur        Divorced  \n",
      "2        blue-collar         Married  \n",
      "3           services        Divorced  \n",
      "4             admin.          Single  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "education_marital = pd.read_csv(\"./data/education_marital.csv\")\n",
    "\n",
    "marital_status = education_marital['Marital_Status'].unique()\n",
    "\n",
    "marital, counts = np.unique(marital_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(marital)}\n",
    "numerical_data = [value_to_index[value] for value in marital_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [marital[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Marital Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.Housing Status\n",
    "Reflects stability and long-term commitment, influencing churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...   SignDate  TransactionFreq  Transaction Amt  \\\n",
      "0        0              2  ... 2020-06-02              182      -10,186,409   \n",
      "1        0              2  ... 2022-12-24               78       -2,244,355   \n",
      "2        0              2  ... 2013-05-09                0                0   \n",
      "3  148,883              1  ... 2021-01-18              481       -5,583,581   \n",
      "4        0              2  ... 2018-06-30                0                0   \n",
      "\n",
      "   ServiceSupportFrequency MonthsInactive NPS      Education  \\\n",
      "0                        6              0   4      Doctorate   \n",
      "1                       21              0   0        College   \n",
      "2                        9              1   1     Uneducated   \n",
      "3                        2              0   7    High School   \n",
      "4                       42              1   8  Post-Graduate   \n",
      "\n",
      "   Employment Status  Marital Status  Housing Status  \n",
      "0        blue-collar        Divorced          rented  \n",
      "1       entrepreneur        Divorced           owned  \n",
      "2        blue-collar         Married           owned  \n",
      "3           services        Divorced           owned  \n",
      "4             admin.          Single           owned  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "housing = pd.read_csv(\"./data/housing.csv\")\n",
    "\n",
    "housing_status = housing['House_Ownership'].unique()\n",
    "\n",
    "house, counts = np.unique(housing_status, return_counts=True)\n",
    "value_to_index = {value: i for i, value in enumerate(house)}\n",
    "numerical_data = [value_to_index[value] for value in housing_status]\n",
    "\n",
    "kde = gaussian_kde(numerical_data)\n",
    "\n",
    "x_values = np.unique(numerical_data)\n",
    "pdf_values = kde(x_values)\n",
    "\n",
    "pmf = pdf_values / np.sum(pdf_values)\n",
    "\n",
    "resampled_indices = np.random.choice(x_values, size=n_train, p=pmf)\n",
    "\n",
    "resampled_values = [house[index] for index in resampled_indices]\n",
    "\n",
    "bank_df_train['Housing Status'] = resampled_values\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.Number of Dependents\n",
    "Impacts financial priorities and risk tolerance, affecting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  TransactionFreq  Transaction Amt  \\\n",
      "0        0              2  ...              182      -10,186,409   \n",
      "1        0              2  ...               78       -2,244,355   \n",
      "2        0              2  ...                0                0   \n",
      "3  148,883              1  ...              481       -5,583,581   \n",
      "4        0              2  ...                0                0   \n",
      "\n",
      "   ServiceSupportFrequency  MonthsInactive NPS      Education  \\\n",
      "0                        6               0   4      Doctorate   \n",
      "1                       21               0   0        College   \n",
      "2                        9               1   1     Uneducated   \n",
      "3                        2               0   7    High School   \n",
      "4                       42               1   8  Post-Graduate   \n",
      "\n",
      "   Employment Status  Marital Status  Housing Status  Dependants  \n",
      "0        blue-collar        Divorced          rented           1  \n",
      "1       entrepreneur        Divorced           owned           1  \n",
      "2        blue-collar         Married           owned           3  \n",
      "3           services        Divorced           owned           1  \n",
      "4             admin.          Single           owned           0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "dependants_df = pd.read_csv('./data/education+dependents+maritalstatus/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(dependants_df['Dependent_count'])\n",
    "\n",
    "bank_df_train['Dependants'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_train['Dependants'] = np.round(bank_df_train['Dependants']).astype(int)\n",
    "bank_df_test['Dependants'] = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "bank_df_test['Dependants'] = np.round(bank_df_test['Dependants']).astype(int)\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25.Marketing Offers Accepted\n",
    "Indicates responsiveness to incentives, affecting churn. Range 0-1, (percentage of marketing offers they accept, e.g.5 offer, 4 accepted, the value of the column 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Transaction Amt  ServiceSupportFrequency  \\\n",
      "0        0              2  ...      -10,186,409                        6   \n",
      "1        0              2  ...       -2,244,355                       21   \n",
      "2        0              2  ...                0                        9   \n",
      "3  148,883              1  ...       -5,583,581                        2   \n",
      "4        0              2  ...                0                       42   \n",
      "\n",
      "   MonthsInactive  NPS      Education Employment Status  Marital Status  \\\n",
      "0               0    4      Doctorate       blue-collar        Divorced   \n",
      "1               0    0        College      entrepreneur        Divorced   \n",
      "2               1    1     Uneducated       blue-collar         Married   \n",
      "3               0    7    High School          services        Divorced   \n",
      "4               1    8  Post-Graduate            admin.          Single   \n",
      "\n",
      "   Housing Status  Dependants  MarketingOffersAcceptance  \n",
      "0          rented           1                          0  \n",
      "1           owned           1                          0  \n",
      "2           owned           3                          0  \n",
      "3           owned           1                          0  \n",
      "4           owned           0                          0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "marketing_df = pd.read_csv('./data/marketing offers/marketing_campaign.csv', sep=';')\n",
    "\n",
    "\n",
    "marketing_df[\"MarketingOffersAcceptance\"] = (marketing_df['AcceptedCmp1'] + marketing_df['AcceptedCmp2'] + marketing_df['AcceptedCmp3'] + marketing_df['AcceptedCmp4'] + marketing_df['AcceptedCmp5']) / 5\n",
    "# print(marketing_df.head())\n",
    "\n",
    "kde = gaussian_kde(marketing_df['MarketingOffersAcceptance'])\n",
    "\n",
    "bank_df_train['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "bank_df_test['MarketingOffersAcceptance'] = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.Channel Used for Transactions\n",
    "Reflects preferred banking channels and engagement level. \n",
    "faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)']\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  ServiceSupportFrequency  MonthsInactive  NPS  \\\n",
      "0        0              2  ...                        6               0    4   \n",
      "1        0              2  ...                       21               0    0   \n",
      "2        0              2  ...                        9               1    1   \n",
      "3  148,883              1  ...                        2               0    7   \n",
      "4        0              2  ...                       42               1    8   \n",
      "\n",
      "       Education Employment Status Marital Status  Housing Status  Dependants  \\\n",
      "0      Doctorate       blue-collar       Divorced          rented           1   \n",
      "1        College      entrepreneur       Divorced           owned           1   \n",
      "2     Uneducated       blue-collar        Married           owned           3   \n",
      "3    High School          services       Divorced           owned           1   \n",
      "4  Post-Graduate            admin.         Single           owned           0   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod  \n",
      "0                          0    Credit card (automatic)  \n",
      "1                          0  Bank transfer (automatic)  \n",
      "2                          0  Bank transfer (automatic)  \n",
      "3                          0           Electronic check  \n",
      "4                          0    Credit card (automatic)  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "transaction_channel_df = pd.read_csv('./data/main_payment_method/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# print(transaction_channel_df.head())\n",
    "methods = transaction_channel_df['PaymentMethod'].unique().tolist()\n",
    "print(methods)\n",
    "faked_data = [random.choice(methods) for _ in range(len(bank_df_train))]\n",
    "faked_data_2 = [random.choice(methods) for _ in range(len(bank_df_test))]\n",
    "\n",
    "bank_df_train['PaymentMethod'] = faked_data\n",
    "bank_df_test['PaymentMethod'] = faked_data_2\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27.Customer Satisfaction Surveys\n",
    "Provides direct feedback on satisfaction levels, predicting churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    3\n",
      "2    1\n",
      "3    5\n",
      "4    4\n",
      "5    3\n",
      "6    4\n",
      "7    2\n",
      "8    4\n",
      "9    4\n",
      "Name: CustomerSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "cust_satisfaction_df = pd.read_csv('./data/satisfaction score/Customer-Churn-Records.csv')\n",
    "\n",
    "kde = gaussian_kde(cust_satisfaction_df['Satisfaction Score'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 5)\n",
    "fake_data = np.round(fake_data).astype(int)\n",
    "\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 5)\n",
    "fake_data_2 = np.round(fake_data_2).astype(int)\n",
    "\n",
    "bank_df_train['CustomerSatisfaction'] = fake_data\n",
    "bank_df_test['CustomerSatisfaction'] = fake_data_2\n",
    "# print(len(bank_df_test))\n",
    "# print(len(fake_data_2))\n",
    "\n",
    "print(bank_df_train['CustomerSatisfaction'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.Feature Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    2\n",
      "2    3\n",
      "3    1\n",
      "4    5\n",
      "Name: FeatureSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with your overall delivery experience at Ali?                    1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['FeatureSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_test['FeatureSatisfaction'] = kde.resample(len(bank_df_test)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['FeatureSatisfaction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29.Support Satisfaction\n",
    "Scale on 1 to 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    3\n",
      "2    5\n",
      "3    3\n",
      "4    2\n",
      "Name: SupportSatisfaction, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "feature_df = pd.read_csv('./data/feature_and_support_satisfaction/Customer-survey-data.csv')\n",
    "feature_df = feature_df.dropna()\n",
    "kde = gaussian_kde(feature_df['How satisfied were you with the speed of delivery at Alis?                                1-5 where 1 = extremely dissatisfied and 5 = extremely satisfied'])\n",
    "bank_df_train['SupportSatisfaction'] = kde.resample(len(bank_df_train)).flatten().astype(int)\n",
    "bank_df_test['SupportSatisfaction'] = kde.resample(len(bank_df_test)).flatten().astype(int)\n",
    "\n",
    "print(bank_df_train['SupportSatisfaction'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.Service Support Frequency (per mth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         24\n",
      "1         19\n",
      "2         39\n",
      "3          0\n",
      "4          7\n",
      "          ..\n",
      "164879     3\n",
      "164931    25\n",
      "164961    38\n",
      "164998     3\n",
      "165012    14\n",
      "Name: ServiceSupportFrequency, Length: 23221, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "support_freq = pd.read_csv(\"./data/support_frequency.csv\")\n",
    "kde = gaussian_kde(support_freq['no_of_cases'])\n",
    "bank_df_train['ServiceSupportFrequency'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "\n",
    "print(bank_df_train['ServiceSupportFrequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.Relationship Count\n",
    "Reflects the breadth of the customer's relationship with the bank.\n",
    "Shld be correlated to 6: No. of products   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      47996\n",
      "1      13555\n",
      "2       5270\n",
      "3     148231\n",
      "4    9472289\n",
      "Name: RelationshipCount, dtype: int32\n",
      "9772872\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "relationship_count = pd.read_csv('./data/loan/credit_train.csv')\n",
    "relationship_count['Current Loan Amount'].fillna(0, inplace=True) \n",
    "\n",
    "if np.any(np.isinf(relationship_count['Current Loan Amount'])):\n",
    "    # Handle infinite values, such as replacing them with a large finite value\n",
    "    relationship_count['Current Loan Amount'].replace([np.inf, -np.inf], np.finfo(np.float64).max, inplace=True)\n",
    "\n",
    "\n",
    "median_loan_amount = relationship_count['Current Loan Amount'].median()\n",
    "below_median = relationship_count[relationship_count['Current Loan Amount'] < median_loan_amount]\n",
    "above_median = relationship_count[relationship_count['Current Loan Amount'] >= median_loan_amount]\n",
    "\n",
    "# print(above_median)\n",
    "kde_upper = gaussian_kde(above_median['Current Loan Amount'])\n",
    "kde_lower = gaussian_kde(below_median['Current Loan Amount'])\n",
    "\n",
    "bank_df_train['RelationshipCount'] = np.where(bank_df_train['CustomerSatisfaction'] >= 4, abs(kde_upper.resample(n_train).flatten()/12).astype(int) , abs(kde_lower.resample(n_train).flatten()/12).astype(int))\n",
    "\n",
    "\n",
    "# kde = gaussian_kde(relationship_count['Current Loan Amount'])\n",
    "# bank_df_train['RelationshipCount'] = abs(kde.resample(n_train).flatten()/12).astype(int)\n",
    "\n",
    "print(bank_df_train['RelationshipCount'].head())\n",
    "print(bank_df_train['RelationshipCount'].max())\n",
    "print(bank_df_train['RelationshipCount'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32. Income Source\n",
    "Indicates financial stability and potential churn risk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Private', 'Local-gov', 'Self-emp-not-inc', 'Federal-gov', 'State-gov', 'Self-emp-inc', 'Without-pay', 'Never-worked']\n",
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Marital Status  Housing Status  Dependants  \\\n",
      "0        0              2  ...        Divorced          rented           1   \n",
      "1        0              2  ...        Divorced           owned           1   \n",
      "2        0              2  ...         Married           owned           3   \n",
      "3  148,883              1  ...        Divorced           owned           1   \n",
      "4        0              2  ...          Single           owned           0   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod CustomerSatisfaction  \\\n",
      "0                          0    Credit card (automatic)                    5   \n",
      "1                          0  Bank transfer (automatic)                    3   \n",
      "2                          0  Bank transfer (automatic)                    1   \n",
      "3                          0           Electronic check                    5   \n",
      "4                          0    Credit card (automatic)                    4   \n",
      "\n",
      "   FeatureSatisfaction  SupportSatisfaction  RelationshipCount  \\\n",
      "0                    4                    2              47996   \n",
      "1                    2                    3              13555   \n",
      "2                    3                    5               5270   \n",
      "3                    1                    3             148231   \n",
      "4                    5                    2            9472289   \n",
      "\n",
      "       IncomeSource  \n",
      "0       Without-pay  \n",
      "1  Self-emp-not-inc  \n",
      "2       Without-pay  \n",
      "3         State-gov  \n",
      "4         State-gov  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "income_source_df = pd.read_csv('./data/income source/adult.csv')\n",
    "\n",
    "# print(transaction_channel_df.head())\n",
    "income_sourcs = income_source_df['workclass'].unique().tolist()\n",
    "income_sourcs.remove('?')\n",
    "print(income_sourcs)\n",
    "faked_data = [random.choice(income_sourcs) for _ in range(len(bank_df_train))]\n",
    "faked_data_2 = [random.choice(income_sourcs) for _ in range(len(bank_df_test))]\n",
    "\n",
    "bank_df_train['IncomeSource'] = faked_data\n",
    "bank_df_test['IncomeSource'] = faked_data_2\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33. Credit Utilization\n",
    "Reflects financial health and potential churn risk for credit customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  CustomerId         Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
      "0   0    15674932  Okwudilichukwu          668    France   Male   33       3   \n",
      "1   1    15749177   Okwudiliolisa          627    France   Male   33       1   \n",
      "2   2    15694510           Hsueh          678    France   Male   40      10   \n",
      "3   3    15741417             Kao          581    France   Male   34       2   \n",
      "4   4    15766172       Chiemenam          716     Spain   Male   33       5   \n",
      "\n",
      "   Balance  NumOfProducts  ...  Housing Status  Dependants  \\\n",
      "0        0              2  ...          rented           1   \n",
      "1        0              2  ...           owned           1   \n",
      "2        0              2  ...           owned           3   \n",
      "3  148,883              1  ...           owned           1   \n",
      "4        0              2  ...           owned           0   \n",
      "\n",
      "   MarketingOffersAcceptance              PaymentMethod CustomerSatisfaction  \\\n",
      "0                          0    Credit card (automatic)                    5   \n",
      "1                          0  Bank transfer (automatic)                    3   \n",
      "2                          0  Bank transfer (automatic)                    1   \n",
      "3                          0           Electronic check                    5   \n",
      "4                          0    Credit card (automatic)                    4   \n",
      "\n",
      "  FeatureSatisfaction  SupportSatisfaction  RelationshipCount  \\\n",
      "0                   4                    2              47996   \n",
      "1                   2                    3              13555   \n",
      "2                   3                    5               5270   \n",
      "3                   1                    3             148231   \n",
      "4                   5                    2            9472289   \n",
      "\n",
      "       IncomeSource  CreditUtilization  \n",
      "0       Without-pay                  0  \n",
      "1  Self-emp-not-inc                  1  \n",
      "2       Without-pay                  0  \n",
      "3         State-gov                  0  \n",
      "4         State-gov                  0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "credit_df = pd.read_csv('./data/credit utilization/BankChurners.csv')\n",
    "\n",
    "kde = gaussian_kde(credit_df['Avg_Utilization_Ratio'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 1)\n",
    "# fake_data = np.round(fake_data).astype(int)\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 1)\n",
    "\n",
    "bank_df_train['CreditUtilization'] = fake_data\n",
    "bank_df_test['CreditUtilization'] = fake_data_2\n",
    "\n",
    "print(bank_df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34. Response to Previous Retention Efforts\n",
    "Records success or failure of previous retention efforts, guiding future strategies. % 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "10   0\n",
      "11   0\n",
      "12   0\n",
      "13   0\n",
      "14   0\n",
      "15   0\n",
      "16   0\n",
      "17   0\n",
      "18   0\n",
      "19   0\n",
      "Name: Retention, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "retention_df = pd.read_csv('./data/retention/HR_comma_sep.csv')\n",
    "\n",
    "kde = gaussian_kde(retention_df['promotion_last_5years'])\n",
    "\n",
    "fake_data = np.maximum(kde.resample(len(bank_df_train)).flatten(), 0)\n",
    "fake_data = np.minimum(fake_data.flatten(), 1)\n",
    "\n",
    "fake_data_2 = np.maximum(kde.resample(len(bank_df_test)).flatten(), 0)\n",
    "fake_data_2 = np.minimum(fake_data_2.flatten(), 1)\n",
    "\n",
    "\n",
    "bank_df_train['Retention'] = fake_data\n",
    "bank_df_test['Retention'] = fake_data_2\n",
    "\n",
    "print(bank_df_train['Retention'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 35. Change in behavior before n after\n",
    "Average of percentage of increase/decrease (ranging from 0 - infinity, but most of the times it will be ard 0-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   1\n",
      "6   1\n",
      "7   1\n",
      "8   2\n",
      "9   1\n",
      "Name: ChangeInBehaviourMkt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bank_df_train['ChangeInBehaviourMkt'] = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "bank_df_test['ChangeInBehaviourMkt']= np.random.normal(1, 0.25, len(bank_df_test))\n",
    "# test = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "# # print(test)\n",
    "# bank_df_train['ChangeInBehaviourMkt'] = test.astype(float)\n",
    "\n",
    "print(bank_df_train['ChangeInBehaviourMkt'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 36. Change in behavior before n after for Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "Name: ChanegInBehaviourCust, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bank_df_train['ChanegInBehaviourCust'] = np.random.normal(1, 0.25, len(bank_df_train))\n",
    "bank_df_test['ChanegInBehaviourCust']= np.random.normal(1, 0.25, len(bank_df_test))\n",
    "\n",
    "print(bank_df_train['ChanegInBehaviourCust'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 37. Previous Lifecycle status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Dormant\n",
      "1    Reactivated\n",
      "2         Active\n",
      "3         Active\n",
      "4        Dormant\n",
      "5        Churned\n",
      "6    Reactivated\n",
      "7        Dormant\n",
      "8         Active\n",
      "9    Reactivated\n",
      "Name: PrevLifecycle, dtype: object\n"
     ]
    }
   ],
   "source": [
    "life_cycles = ['Active', 'Dormant', 'Reactivated'] #everything but churned\n",
    "\n",
    "bank_df_train['PrevLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['Exited'] == 1 else np.random.choice(life_cycles), axis=1)\n",
    "\n",
    "print(bank_df_train['PrevLifecycle'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38. Current Lifecycle status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PrevLifecycle CurrLifecycle\n",
      "0       Dormant   Reactivated\n",
      "1   Reactivated        active\n",
      "2        Active       Dormant\n",
      "3        Active        active\n",
      "4       Dormant       Dormant\n",
      "5       Churned       Churned\n",
      "6   Reactivated        active\n",
      "7       Dormant   Reactivated\n",
      "8        Active        active\n",
      "9   Reactivated        active\n"
     ]
    }
   ],
   "source": [
    "prev_active = ['Active', 'Dormant'] #excluding churn, also same for reactivated\n",
    "prev_dormant = ['Dormant', 'Reactivated'] #excluding churn\n",
    "\n",
    "# bank_df_train['CurrLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['PrevLifecycle'] == 'Churned' else \\\n",
    "#                                                     np.random.choice(prev_active) if (row['PrevLifecycle'] == 'Active' or row['PrevLifecycle'] == 'Reactivated') else \\\n",
    "#                                                     np.random.choice(prev_dormant) if row['PrevLifecycle'] == 'Dormant' else \\\n",
    "#                                                     np.nan, axis=1)\n",
    "bank_df_train['CurrLifecycle'] = bank_df_train.apply(lambda row: 'Churned' if row['PrevLifecycle'] == 'Churned' else \\\n",
    "                                                     'Reactivated' if (row['PrevLifecycle'] == 'Dormant' and row['TransactionFreq'] > 0) else \\\n",
    "                                                     'Dormant' if row['TransactionFreq'] == 0 else \\\n",
    "                                                     'active', axis=1)\n",
    "\n",
    "print(bank_df_train[['PrevLifecycle', 'CurrLifecycle']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39. Customer Happiness Status \n",
    "1 == happy, 0 == unhappy\n",
    "\n",
    "Customer satisfaction survey score \n",
    "\n",
    "Relationship Count \n",
    "\n",
    "Response to previous retention efforts (no more yay)\n",
    "\n",
    "if we want the top 15.9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: Happiness, dtype: int64\n",
      "percentage happy = 19.74075190560269\n"
     ]
    }
   ],
   "source": [
    "happiness_benchmark = 84.1\n",
    "\n",
    "# bank_df_train['Happiness'] = bank_df_train.apply(lambda row: 1 if row['CustomerSatisfaction'] + \\\n",
    "#                                                                   row['FeatureSatisfaction'] + \\\n",
    "#                                                                   row['SupportSatisfaction'] + \\\n",
    "#                                                                   row['NPS'] + \\\n",
    "#                                                                   row['Tenure'] >= happiness_benchmark else \\\n",
    "#                                                                   0, axis=1)\n",
    "\n",
    "\n",
    "# need to delete Custpercentile, RsPercentile and ResponsePercentile later\n",
    "bank_df_train['CustPercentile'] = bank_df_train['CustomerSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "bank_df_train['RsPercentile'] = bank_df_train['RelationshipCount'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "\n",
    "# print(bank_df_train['CustPercentile'].head(10))\n",
    "bank_df_train['Happiness'] = bank_df_train.apply(lambda row: 1 if (row['CustPercentile'] > happiness_benchmark and \\\n",
    "                                                                   row['RsPercentile'] > happiness_benchmark ) else 0, axis=1)\n",
    "bank_df_train.drop(columns=['CustPercentile', 'RsPercentile'], inplace=True)\n",
    "\n",
    "print(bank_df_train['Happiness'].head(10))\n",
    "print(\"percentage happy =\", (bank_df_train['Happiness'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40.Price Sensitivity %\n",
    "26. marketing offers accepted %\n",
    "35. change in behaviour %\n",
    "\n",
    "Mkting Offers Accepted\n",
    "Change in behavior before n after for mkting offer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    77\n",
      "1    51\n",
      "2    75\n",
      "3    45\n",
      "4    16\n",
      "5    17\n",
      "6    28\n",
      "7    21\n",
      "8    60\n",
      "9    54\n",
      "10   56\n",
      "11   75\n",
      "12   35\n",
      "13   53\n",
      "14   30\n",
      "15   74\n",
      "16   29\n",
      "17   83\n",
      "18   23\n",
      "19   65\n",
      "Name: PriceSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MarketingOffersAcceptance_df = bank_df_train['MarketingOffersAcceptance'].apply(lambda x: stats.percentileofscore(bank_df_train['MarketingOffersAcceptance'], x))\n",
    "ChangeInBehaviourMkt_df = bank_df_train['ChangeInBehaviourMkt'].apply(lambda x: stats.percentileofscore(bank_df_train['ChangeInBehaviourMkt'], x))\n",
    "# print(MarketingOffersAcceptance_df.head())\n",
    "# print(ChangeInBehaviourMkt_df.head())\n",
    "bank_df_train['PriceSensitivity'] = (MarketingOffersAcceptance_df + ChangeInBehaviourMkt_df) / 2\n",
    "\n",
    "print(bank_df_train['PriceSensitivity'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 41.Feature Driven % \n",
    "28. Customer satisfaction survey 0-5\n",
    "6. num products 1-4\n",
    "29. Feature Satisfaction 0-5\n",
    "\n",
    "Number of products last 1 year\n",
    "Feature Satisfaction Column (0 to 1)\n",
    "Feature Support freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    78\n",
      "1    52\n",
      "2    45\n",
      "3    43\n",
      "4    78\n",
      "5    55\n",
      "6    36\n",
      "7    35\n",
      "8    72\n",
      "9    49\n",
      "10   52\n",
      "11   23\n",
      "12   16\n",
      "13   49\n",
      "14   35\n",
      "15   39\n",
      "16   58\n",
      "17   71\n",
      "18   42\n",
      "19   49\n",
      "Name: FeatureSensitivity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(bank_df_train['NumOfProducts'].max())\n",
    "# print(bank_df_train['NumOfProducts'].min())\n",
    "\n",
    "# feature_driven = bank_df_train['CustomerSatisfaction'] + bank_df_train['NumOfProducts'] + bank_df_train['FeatureSatisfaction']\n",
    "# percentiles = np.percentile(feature_driven, [0, 25, 50, 75, 100]) \n",
    "\n",
    "# def assign_percentile(metric):\n",
    "#     if metric <= percentiles[1]:\n",
    "#         return ((metric / percentiles[1]) * 25)\n",
    "#     elif metric <= percentiles[2]:\n",
    "#         return (25 + ((metric - percentiles[1]) / (percentiles[2] - percentiles[1])) * 25)\n",
    "#     elif metric <= percentiles[3]:\n",
    "#         return (50 + ((metric - percentiles[2]) / (percentiles[3] - percentiles[2])) * 25)\n",
    "#     else:\n",
    "#         return (75 + ((metric - percentiles[3]) / (percentiles[4] - percentiles[3])) * 25)\n",
    "        \n",
    "# bank_df_train['FeatureSensitivity'] = feature_driven.apply(assign_percentile)\n",
    "# bank_df_train['FeatureSensitivity'] = bank_df_train['FeatureSensitivity'].replace(np.NaN, 0, regex=True)\n",
    "\n",
    "CustomerSatisfaction_df = bank_df_train['CustomerSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['CustomerSatisfaction'], x))\n",
    "NumOfProducts_df = bank_df_train['NumOfProducts'].apply(lambda x: stats.percentileofscore(bank_df_train['NumOfProducts'], x))\n",
    "FeatureSatisfaction_df = bank_df_train['FeatureSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['FeatureSatisfaction'], x))\n",
    "\n",
    "bank_df_train['FeatureSensitivity'] = (CustomerSatisfaction_df + NumOfProducts_df + FeatureSatisfaction_df) / 3\n",
    "\n",
    "print(bank_df_train['FeatureSensitivity'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42.Service Driven % \n",
    "31. service support freq per month number\n",
    "39. Customer Happiness Status binary\n",
    "36. Change in behavior before n after for Support %\n",
    "\n",
    "CALL Support frequency\n",
    "Support Satisfaction Column (0 to 1)\n",
    "Change in behavior before n after support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CallSupportFrequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\caboo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CallSupportFrequency'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# print(bank_df_train['ServiceSupportFrequency'])\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m CallSupportFrequency_df \u001b[38;5;241m=\u001b[39m \u001b[43mbank_df_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCallSupportFrequency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: stats\u001b[38;5;241m.\u001b[39mpercentileofscore(bank_df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCallSupportFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m], x))\n\u001b[0;32m      3\u001b[0m ServiceSupportFrequency_df \u001b[38;5;241m=\u001b[39m bank_df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mServiceSupportFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: stats\u001b[38;5;241m.\u001b[39mpercentileofscore(bank_df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mServiceSupportFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m], x))\n\u001b[0;32m      4\u001b[0m SupportSatisfaction_df \u001b[38;5;241m=\u001b[39m bank_df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupportSatisfaction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: stats\u001b[38;5;241m.\u001b[39mpercentileofscore(bank_df_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupportSatisfaction\u001b[39m\u001b[38;5;124m'\u001b[39m], x))\n",
      "File \u001b[1;32mc:\\Users\\caboo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\caboo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'CallSupportFrequency'"
     ]
    }
   ],
   "source": [
    "# print(bank_df_train['ServiceSupportFrequency'])\n",
    "CallSupportFrequency_df = bank_df_train['CallSupportFrequency'].apply(lambda x: stats.percentileofscore(bank_df_train['CallSupportFrequency'], x))\n",
    "ServiceSupportFrequency_df = bank_df_train['ServiceSupportFrequency'].apply(lambda x: stats.percentileofscore(bank_df_train['ServiceSupportFrequency'], x))\n",
    "SupportSatisfaction_df = bank_df_train['SupportSatisfaction'].apply(lambda x: stats.percentileofscore(bank_df_train['SupportSatisfaction'], x))\n",
    "ChanegInBehaviourCust_df = bank_df_train['ChanegInBehaviourCust'].apply(lambda x: stats.percentileofscore(bank_df_train['ChanegInBehaviourCust'], x))\n",
    "\n",
    "bank_df_train['ServiceSensitivity'] = (CallSupportFrequency_df + ServiceSupportFrequency_df + SupportSatisfaction_df + ChanegInBehaviourCust_df) / 4\n",
    "\n",
    "print(bank_df_train['ServiceSensitivity'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 43.Customer Personas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PriceSensitivity  FeatureSensitivity  ServiceSensitivity  \\\n",
      "0                     25                  42                  33   \n",
      "1                     27                  35                  38   \n",
      "2                     27                  38                  35   \n",
      "3                     41                  26                  32   \n",
      "4                     26                  30                  44   \n",
      "...                  ...                 ...                 ...   \n",
      "164879                30                  35                  35   \n",
      "164931                37                  34                  28   \n",
      "164961                43                  17                  40   \n",
      "164998                34                  34                  32   \n",
      "165012                32                  32                  36   \n",
      "\n",
      "           CustomerPersona  \n",
      "0       FeatureSensitivity  \n",
      "1       ServiceSensitivity  \n",
      "2       FeatureSensitivity  \n",
      "3         PriceSensitivity  \n",
      "4       ServiceSensitivity  \n",
      "...                    ...  \n",
      "164879  ServiceSensitivity  \n",
      "164931    PriceSensitivity  \n",
      "164961    PriceSensitivity  \n",
      "164998    PriceSensitivity  \n",
      "165012  ServiceSensitivity  \n",
      "\n",
      "[23221 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_normalize = ['PriceSensitivity', 'FeatureSensitivity', 'ServiceSensitivity']\n",
    "\n",
    "bank_df_train[columns_to_normalize] = bank_df_train[columns_to_normalize].div(bank_df_train[columns_to_normalize].sum(axis=1), axis=0) * 100\n",
    "bank_df_train['CustomerPersona'] = bank_df_train[columns_to_normalize].idxmax(axis=1)\n",
    "\n",
    "print(bank_df_train[['PriceSensitivity', 'FeatureSensitivity', 'ServiceSensitivity', 'CustomerPersona']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 44. Social Influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    1\n",
      "9    1\n",
      "Name: SocialInfluencer, dtype: int64\n",
      "percentage social influencer = 16.614271564532103\n"
     ]
    }
   ],
   "source": [
    "social_benchmark = 84.1\n",
    "\n",
    "bank_df_train['SocialInfluencer'] = bank_df_train['NPS'].apply(lambda x: stats.percentileofscore(bank_df_train['NPS'], x))\n",
    "bank_df_train['SocialInfluencer'] = bank_df_train.apply(lambda row: 1 if (row['SocialInfluencer'] > happiness_benchmark) else 0, axis=1)\n",
    "\n",
    "print(bank_df_train['SocialInfluencer'].head(10))\n",
    "print(\"percentage social influencer =\", (bank_df_train['SocialInfluencer'] == 1).mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "1. covarience matrix\n",
    "2. LDA\n",
    "3. apriori\n",
    "4. domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Aprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#domain knowledge...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training:\n",
    "1. Random forest\n",
    "2. XGBoost\n",
    "3. Logistic regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
