{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b45dc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05dc1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing of code, remove this afterwards, and add in the line to receive the processed data\n",
    "raw_train2 = pd.read_csv('train_data.csv')\n",
    "raw_train = pd.read_csv('train.csv')\n",
    "raw_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c1158f5-03a4-4ad9-a7ba-96d259a1458b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165029</th>\n",
       "      <td>165029</td>\n",
       "      <td>15667085</td>\n",
       "      <td>Meng</td>\n",
       "      <td>667</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131834.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165030</th>\n",
       "      <td>165030</td>\n",
       "      <td>15665521</td>\n",
       "      <td>Okechukwu</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131834.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165031</th>\n",
       "      <td>165031</td>\n",
       "      <td>15664752</td>\n",
       "      <td>Hsia</td>\n",
       "      <td>565</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127429.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>165032</td>\n",
       "      <td>15689614</td>\n",
       "      <td>Hsiung</td>\n",
       "      <td>554</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>161533.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71173.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165033</th>\n",
       "      <td>165033</td>\n",
       "      <td>15732798</td>\n",
       "      <td>Ulyanov</td>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61581.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165034 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  CustomerId         Surname  CreditScore Geography  Gender  \\\n",
       "0            0    15674932  Okwudilichukwu          668    France    Male   \n",
       "1            1    15749177   Okwudiliolisa          627    France    Male   \n",
       "2            2    15694510           Hsueh          678    France    Male   \n",
       "3            3    15741417             Kao          581    France    Male   \n",
       "4            4    15766172       Chiemenam          716     Spain    Male   \n",
       "...        ...         ...             ...          ...       ...     ...   \n",
       "165029  165029    15667085            Meng          667     Spain  Female   \n",
       "165030  165030    15665521       Okechukwu          792    France    Male   \n",
       "165031  165031    15664752            Hsia          565    France    Male   \n",
       "165032  165032    15689614          Hsiung          554     Spain  Female   \n",
       "165033  165033    15732798         Ulyanov          850    France    Male   \n",
       "\n",
       "         Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       33.0       3       0.00              2        1.0             0.0   \n",
       "1       33.0       1       0.00              2        1.0             1.0   \n",
       "2       40.0      10       0.00              2        1.0             0.0   \n",
       "3       34.0       2  148882.54              1        1.0             1.0   \n",
       "4       33.0       5       0.00              2        1.0             1.0   \n",
       "...      ...     ...        ...            ...        ...             ...   \n",
       "165029  33.0       2       0.00              1        1.0             1.0   \n",
       "165030  35.0       3       0.00              1        0.0             0.0   \n",
       "165031  31.0       5       0.00              1        1.0             1.0   \n",
       "165032  30.0       7  161533.00              1        0.0             1.0   \n",
       "165033  31.0       1       0.00              1        1.0             0.0   \n",
       "\n",
       "        EstimatedSalary  Exited  \n",
       "0             181449.97       0  \n",
       "1              49503.50       0  \n",
       "2             184866.69       0  \n",
       "3              84560.88       0  \n",
       "4              15068.83       0  \n",
       "...                 ...     ...  \n",
       "165029        131834.75       0  \n",
       "165030        131834.45       0  \n",
       "165031        127429.56       0  \n",
       "165032         71173.03       0  \n",
       "165033         61581.79       1  \n",
       "\n",
       "[165034 rows x 14 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a60a82b0-1433-4829-a914-da6e0749451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = raw_train.columns\n",
    "X = raw_train[cols[3:-1]].drop(columns=['Gender', 'Geography'])\n",
    "y = raw_train[\n",
    "[cols[-1]]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "990e79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE TO PREPROCESS THE DATASET\n",
    "\n",
    "cols = raw_train.columns\n",
    "X = raw_train.iloc[:,3:].drop(columns=['Gender', 'Geography'])\n",
    "#X = raw_train.drop(columns=['Gender', 'ChurnDate', 'FirstPersona', 'SecondPersona', 'ThirdPersona', 'CombinedPersonas', 'SocialInfluencer'])\n",
    "#X['Active'] = (X['CurrLifecycle'] == 'Active').astype(int)\n",
    "#X['Reactivated'] = (X['CurrLifecycle'] == 'Reactivated').astype(int)\n",
    "#X['Dormant'] = (X['CurrLifecycle'] == 'Dormant').astype(int)\n",
    "#X['Churned'] = (X['CurrLifecycle'] == 'Churned').astype(int)\n",
    "\n",
    "strat = raw_train['CurrLifecycle']\n",
    "all_train, all_test, strat_train, strat_test = train_test_split(X, strat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527da9d-0198-4547-b177-66b594943a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_a, y_train_r, y_train_d, y_train_c = all_train['Active'], all_train['Reactivated'], all_train['Dormant'], all_train['Churned']\n",
    "#y_test_a, y_test_r, y_test_d, y_test_c = all_test['Active'], all_test['Reactivated'], all_test['Dormant'], all_test['Churned']\n",
    "\n",
    "y_train_all = [all_train['Active'], all_train['Reactivated'], all_train['Dormant'], all_train['Churned']]\n",
    "y_test_all = [all_test['Active'], all_test['Reactivated'], all_test['Dormant'], all_test['Churned']]\n",
    "X_train = all_train.drop(columns=['Active', 'Reactivated', 'Dormant', 'Churned'])\n",
    "X_test = all_test.drop(columns=['Active', 'Reactivated', 'Dormant', 'Churned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f5e95b-58e6-4e4b-9246-86c61b0f92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WONT USE THIS\n",
    "y_train_a, y_train_r, y_train_d, y_train_c = y_train, y_train, y_train, y_train\n",
    "y_test_a, y_test_r, y_test_d, y_test_c = y_test, y_test, y_test, y_test\n",
    "\n",
    "y_train_all = [y_train_a, y_train_r, y_train_d, y_train_c]\n",
    "y_test_all = [y_test_a, y_test_r, y_test_d, y_test_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "374b0842-0a13-40ae-8290-2a6de236b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to ignore the DataConversionWarning\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d80892",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16c91119",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e391fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "lr_param_dist = {\n",
    "    'penalty': ['l1', 'l2'],  \n",
    "    #'C' : np.logspace(-4, 4, 20),\n",
    "    'C': [0.1, 1, 10, 100, 1000],  \n",
    "    'solver': ['liblinear', 'saga'] \n",
    "}\n",
    "\n",
    "#search_lr = RandomizedSearchCV(lr_model, param_distributions=lr_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "# Scale the data for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Perform optimization\n",
    "#search_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "#print(\"Best parameters found: \", search_lr.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "#best_model_lr = search_lr.best_estimator_\n",
    "#lr_predictions = best_model_lr.predict(X_test_scaled)\n",
    "#lr_probabilities = best_model_lr.predict_proba(X_test_scaled)[:,1]\n",
    "#test_score_lr = best_model_lr.score(X_test_scaled, y_test)\n",
    "#print(\"Test score of the best model: \", test_score_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bff1402f-0a6e-4e3a-80a9-8cc37762efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = []\n",
    "lr_results = []\n",
    "\n",
    "for i in range(4):\n",
    "    lr_model = LogisticRegression()\n",
    "    search_lr = RandomizedSearchCV(lr_model, param_distributions=lr_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "    search_lr.fit(X_train_scaled, y_train_all[i])\n",
    "\n",
    "    best_model_lr = search_lr.best_estimator_\n",
    "    lr_models.append(best_model_lr)\n",
    "    \n",
    "    test_score_lr = best_model_lr.score(X_test_scaled, y_test_all[i])\n",
    "    lr_results.append(test_score_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f794669a-a35c-4b1f-bc8a-381d28ca907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8233405035295543,\n",
       " 0.8233405035295543,\n",
       " 0.8233405035295543,\n",
       " 0.8233405035295543]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265bd94",
   "metadata": {},
   "source": [
    "## Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f01d54-5718-4eb9-97eb-4201bf9bf374",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81638087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "gb_param_dist = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': np.arange(0., 2., 0.2).tolist(),\n",
    "    'n_estimators': np.arange(100, 301, 100).tolist(),\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'min_samples_leaf': np.arange(6,15, 2).tolist(),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': np.arange(2,15, 2).tolist(),\n",
    "    'max_depth': np.arange(3,16, 3).tolist()\n",
    "}\n",
    "\n",
    "#search = BayesSearchCV(\n",
    "#    estimator=gb_model,\n",
    "#    search_spaces=gb_param_dist,\n",
    "#    n_iter=50,\n",
    "#    cv=5\n",
    "#)\n",
    "\n",
    "search = RandomizedSearchCV(gb_model, param_distributions=gb_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "\n",
    "# Perform optimization\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = search.best_estimator_\n",
    "gb_predictions = best_model.predict(X_test)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test score of the best model: \", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49c64141-910c-4b8d-aba0-4de956c26778",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "372aa2d6-d35b-4910-ad5b-bea4c623a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost parameter ranges\n",
    "xgb_param_dist = {\n",
    "    'booster': ['gbtree'],  \n",
    "    'learning_rate': np.linspace(0.05, 0.3, 6),  \n",
    "    'n_estimators': [100, 200],  \n",
    "    'objective': ['multi:softmax'],  \n",
    "    'num_class': [2],  \n",
    "    'eval_metric': ['logloss'],  \n",
    "    'max_depth': [3, 6, 9],  \n",
    "    'min_child_weight': [1, 5, 10],  \n",
    "    'gamma': [0, 0.1, 0.2],  \n",
    "    'subsample': [0.6, 0.8, 1.0],  \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  \n",
    "    'lambda': [0, 1, 2],  \n",
    "    'alpha': [0, 1, 2]  \n",
    "}\n",
    "\n",
    "xgb_param_dist2 = {\n",
    "    'booster': ['gbtree', 'dart'],  \n",
    "    'learning_rate': np.linspace(0.05, 0.3, 6),  \n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'objective': ['binary:logistic', 'multi:softmax'],  \n",
    "    'num_class': [2],\n",
    "    'eval_metric': ['logloss'],  \n",
    "    'max_depth': [3, 6, 9, 12],  \n",
    "    'min_child_weight': [1, 5, 10],  \n",
    "    'gamma': [0, 0.1, 0.2],  \n",
    "    'subsample': [0.6, 0.8, 1.0],  \n",
    "    'colsample_bytree': [0.6, 0.8],  \n",
    "    'lambda': [0, 1, 2],  \n",
    "    'alpha': [0, 1, 2]  \n",
    "}\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "#xgb_search = RandomizedSearchCV(xgb_model, param_distributions=xgb_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "# Perform optimization\n",
    "#xgb_search.fit(X_train, y_train)\n",
    "\n",
    "#print(\"Best parameters found: \", xgb_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "#best_xgb_model = xgb_search.best_estimator_\n",
    "#xgb_predictions = best_xgb_model.predict(X_test)\n",
    "#test_score = best_xgb_model.score(X_test, y_test)\n",
    "#print(\"Test score of the best XGBoost model: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4b015ce-12e7-46ab-9193-72dfefa29f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_models = []\n",
    "xgb_results = []\n",
    "\n",
    "for i in range(1):\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_search = RandomizedSearchCV(xgb_model, param_distributions=xgb_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "    xgb_search.fit(X_train, y_train_all[i])\n",
    "\n",
    "    best_model_xgb = xgb_search.best_estimator_\n",
    "    xgb_models.append(best_model_xgb)\n",
    "    \n",
    "    test_score_xgb = best_model_xgb.score(X_test, y_test_all[i])\n",
    "    xgb_results.append(test_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eda54242-b8e3-4f64-9787-7cccc17fe5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...),\n",
       " XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...),\n",
       " XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...),\n",
       " XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffac9f0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c9ef173",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "53d7f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_dist = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [None] + list(range(5, 11, 5)),\n",
    "    'min_samples_leaf': [1, 5],\n",
    "    'max_features': ['sqrt', None],\n",
    "    'min_samples_split': [2, 10]\n",
    "}\n",
    "#search = BayesSearchCV(\n",
    "    #estimator=rf_model,\n",
    "    #search_spaces=rf_param_dist,\n",
    "    #n_iter=50,\n",
    "    #cv=5\n",
    "#)\n",
    "#search = RandomizedSearchCV(rf_model, param_distributions=rf_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "# Perform optimization\n",
    "#search.fit(X_train, y_train)\n",
    "\n",
    "#print(\"Best parameters found: \", search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "#best_model = search.best_estimator_\n",
    "#rf_predictions = best_model.predict(X_test)\n",
    "#test_score = best_model.score(X_test, y_test)\n",
    "#print(\"Test score of the best model: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f62d0e8c-1b23-4830-b824-c4d8db255d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#search_rf = RandomizedSearchCV(rf_model, param_distributions=rf_param_dist, n_iter=5, scoring='f1_weighted', cv=5, random_state=42)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#search_rf.fit(X_train, y_train_all[i])\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#best_model_rf = search_rf.best_estimator_\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m best_model_rf \u001b[38;5;241m=\u001b[39m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m rf_models\u001b[38;5;241m.\u001b[39mappend(best_model_rf)\n\u001b[0;32m     14\u001b[0m test_score_rf \u001b[38;5;241m=\u001b[39m best_model_rf\u001b[38;5;241m.\u001b[39mscore(X_test, y_test_all[i])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_models = []\n",
    "rf_results = []\n",
    "\n",
    "for i in range(1):\n",
    "    rf_model = RandomForestClassifier()\n",
    "    #search_rf = RandomizedSearchCV(rf_model, param_distributions=rf_param_dist, n_iter=5, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "    #search_rf.fit(X_train, y_train_all[i])\n",
    "\n",
    "    #best_model_rf = search_rf.best_estimator_\n",
    "    best_model_rf = rf_model.fit(X_train, y_train_all[i])\n",
    "    rf_models.append(best_model_rf)\n",
    "    \n",
    "    test_score_rf = best_model_rf.score(X_test, y_test_all[i])\n",
    "    rf_results.append(test_score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f570407d-12a4-4506-bf73-6aa73bacac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                  min_samples_leaf=1, \n",
    "                                  min_samples_split=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5fa611a5-5a3b-4531-ab17-1b7d64eeca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rf = rf_model.fit(X_train, y_train_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da6f6609-6372-4321-af10-511364c0208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models.append(best_model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47eeac6a-c3f8-4053-866c-7b3757a6ea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...),\n",
       " XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...),\n",
       " XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...),\n",
       " XGBClassifier(alpha=2, base_score=None, booster='gbtree', callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric='logloss',\n",
       "               feature_types=None, gamma=0.1, grow_policy=None,\n",
       "               importance_type=None, interaction_constraints=None, lambda=2,\n",
       "               learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "               max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "               max_leaves=None, min_child_weight=10, missing=nan,\n",
       "               monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "               n_jobs=None, ...)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a376ce-13be-4da1-b99d-d1ed39575f04",
   "metadata": {},
   "source": [
    "## Send Code to The Next Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7bef7d48-cff7-458f-a1f5-919007c793b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(C=1000, penalty='l1', solver='saga'),\n",
       " LogisticRegression(C=10, solver='saga'),\n",
       " LogisticRegression(C=10, penalty='l1', solver='liblinear'),\n",
       " LogisticRegression(C=1, penalty='l1', solver='saga')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f888076b-e343-46c2-bf64-f6311766ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_dicts = []\n",
    "for model in lr_models:\n",
    "    model_dict = {\n",
    "        \"C\": model.C,\n",
    "        \"penalty\": model.penalty,\n",
    "        \"solver\": model.solver\n",
    "        # Add more attributes as needed\n",
    "    }\n",
    "    lr_model_dicts.append(model_dict)\n",
    "\n",
    "rf_model_dicts = []\n",
    "for model in rf_models:\n",
    "    model_dict = {\n",
    "        'n_estimators': model.n_estimators,\n",
    "        'criterion': model.criterion,\n",
    "        'max_depth': model.max_depth,\n",
    "        'min_samples_leaf': model.min_samples_leaf,\n",
    "        #'max_features': model.max_features,\n",
    "        'min_samples_split': model.min_samples_split\n",
    "    }\n",
    "    rf_model_dicts.append(model_dict)\n",
    "\n",
    "xgb_model_dicts = []\n",
    "for model in xgb_models:\n",
    "    model_dict = {\n",
    "        'booster': model.booster,  \n",
    "        'learning_rate': model.learning_rate,  \n",
    "        'n_estimators': model.n_estimators,  \n",
    "        'objective': model.objective,  \n",
    "        #'num_class': model.num_class,  \n",
    "        'eval_metric': model.eval_metric,  \n",
    "        'max_depth': model.max_depth,  \n",
    "        'min_child_weight': model.min_child_weight,  \n",
    "        'gamma': model.gamma,  \n",
    "        'subsample': model.subsample,  \n",
    "        'colsample_bytree': model.colsample_bytree,  \n",
    "        'lambda': getattr(model, 'lambda', None),  # Access lambda attribute using getattr()\n",
    "        'alpha': getattr(model, 'alpha', None) \n",
    "    }\n",
    "    if hasattr(model, 'num_class'):\n",
    "            model_dict['num_class'] = model.num_class\n",
    "    xgb_model_dicts.append(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "73c28a6e-649c-4c3f-82c4-3621fb4c9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_model_dicts, xgb_model_dicts, rf_model_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b7517c3-a743-430d-b51c-f94d1b89a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'C': 1000, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1, 'penalty': 'l1', 'solver': 'saga'}],\n",
       " [{'booster': 'gbtree',\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'objective': 'multi:softmax',\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 10,\n",
       "   'gamma': 0.1,\n",
       "   'subsample': 1.0,\n",
       "   'colsample_bytree': 0.8,\n",
       "   'lambda': None,\n",
       "   'alpha': None},\n",
       "  {'booster': 'gbtree',\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'objective': 'multi:softmax',\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 10,\n",
       "   'gamma': 0.1,\n",
       "   'subsample': 1.0,\n",
       "   'colsample_bytree': 0.8,\n",
       "   'lambda': None,\n",
       "   'alpha': None},\n",
       "  {'booster': 'gbtree',\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'objective': 'multi:softmax',\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 10,\n",
       "   'gamma': 0.1,\n",
       "   'subsample': 1.0,\n",
       "   'colsample_bytree': 0.8,\n",
       "   'lambda': None,\n",
       "   'alpha': None},\n",
       "  {'booster': 'gbtree',\n",
       "   'learning_rate': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'objective': 'multi:softmax',\n",
       "   'eval_metric': 'logloss',\n",
       "   'max_depth': 6,\n",
       "   'min_child_weight': 10,\n",
       "   'gamma': 0.1,\n",
       "   'subsample': 1.0,\n",
       "   'colsample_bytree': 0.8,\n",
       "   'lambda': None,\n",
       "   'alpha': None}],\n",
       " [{'n_estimators': 100,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'n_estimators': 100,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'n_estimators': 100,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2},\n",
       "  {'n_estimators': 100,\n",
       "   'criterion': 'gini',\n",
       "   'max_depth': None,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2}]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4feb8121-6513-480c-b6e4-eda41521c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_model_dicts, xgb_model_dicts, rf_model_dicts]\n",
    "#models = [lr_models, xgb_models, rf_models]\n",
    "\n",
    "# Convert the list to JSON\n",
    "json_data = json.dumps(models, indent=4)\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(\"Models.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1b54a5cd-b0bf-4848-89f0-904ffe2df162",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Gender', 'ChurnDate', 'FirstPersona', 'SecondPersona', 'ThirdPersona', 'CombinedPersonas', 'CurrLifecycle','SocialInfluencer']\n",
    "\n",
    "# Convert the list to JSON\n",
    "json_data = json.dumps(features)\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(\"FeatureDropped.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d5fa1-449d-462e-860f-af74df830434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
