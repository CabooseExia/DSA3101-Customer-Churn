{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45dc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05dc1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing of code, remove this afterwards, and add in the line to receive the processed data\n",
    "raw_train = pd.read_csv('train.csv')\n",
    "raw_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "990e79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = raw_train.columns\n",
    "X = raw_train[cols[3:-1]].drop(columns=['Gender', 'Geography'])\n",
    "y = raw_train[[cols[-1]]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "374b0842-0a13-40ae-8290-2a6de236b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to ignore the DataConversionWarning\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d80892",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c91119",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e391fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1228, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.79792787        nan 0.69481521 0.79767033 0.79416818        nan\n",
      "        nan        nan 0.73065467 0.73065467]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hera\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'solver': 'newton-cholesky', 'penalty': None, 'C': 10}\n",
      "Test score of the best model:  0.8233405035295543\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "lr_param_dist = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "#search = BayesSearchCV(\n",
    "    #estimator=lr_model,\n",
    "    #search_spaces=lr_param_dist,\n",
    "    #n_iter=50,\n",
    "    #cv=5\n",
    "#)\n",
    "search = RandomizedSearchCV(lr_model, param_distributions=lr_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "# Scale the data for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Perform optimization\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = search.best_estimator_\n",
    "lr_predictions = best_model.predict(X_test)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test score of the best model: \", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9341136",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8dde7-01f2-46b8-8665-0640fc108977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b265bd94",
   "metadata": {},
   "source": [
    "## Gradient Booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a352cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81638087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "gb_param_dist = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': np.arange(0., 2., 0.2).tolist(),\n",
    "    'n_estimators': np.arange(100, 301, 100).tolist(),\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'min_samples_leaf': np.arange(6,15, 2).tolist(),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': np.arange(2,15, 2).tolist(),\n",
    "    'max_depth': np.arange(3,16, 3).tolist()\n",
    "}\n",
    "\n",
    "#search = BayesSearchCV(\n",
    "#    estimator=gb_model,\n",
    "#    search_spaces=gb_param_dist,\n",
    "#    n_iter=50,\n",
    "#    cv=5\n",
    "#)\n",
    "\n",
    "search = RandomizedSearchCV(gb_model, param_distributions=gb_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "\n",
    "# Perform optimization\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = search.best_estimator_\n",
    "gb_predictions = best_model.predict(X_test)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test score of the best model: \", test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffac9f0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ef173",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "rf_param_dist = {\n",
    "    'n_estimators': np.arange(100,201, 100).tolist(),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': np.arange(3,13, 3).tolist(),\n",
    "    'min_samples_leaf': np.arange(6,21).tolist()[0::2],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': np.arange(2,11, 2).tolist()\n",
    "}\n",
    "\n",
    "#search = BayesSearchCV(\n",
    "    #estimator=rf_model,\n",
    "    #search_spaces=rf_param_dist,\n",
    "    #n_iter=50,\n",
    "    #cv=5\n",
    "#)\n",
    "search = RandomizedSearchCV(rf_model, param_distributions=rf_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "# Perform optimization\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = search.best_estimator_\n",
    "rf_predictions = best_model.predict(X_test)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test score of the best model: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a376ce-13be-4da1-b99d-d1ed39575f04",
   "metadata": {},
   "source": [
    "## Ensemble & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7d67b-97a5-42dd-9556-45490d2adf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = []\r\n",
    "for lr_pred,xgb_pred, rf_pred in zipl(__predictions ,gt_predictions, ft_prediction  s\r\n",
    "    counts = np.bincount([lr_pred xgb_pred, rf_predte)\r\n",
    "    majority_vote = np.argmax(coun    ensemble_pred.append(majority_vote)abels\r\n",
    "\r\n",
    "# Generate the confusion report = classification_report(y_test, ensemble_pred)\n",
    "tions)a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac6181-9980-4247-b63b-b34b6bd4f0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
