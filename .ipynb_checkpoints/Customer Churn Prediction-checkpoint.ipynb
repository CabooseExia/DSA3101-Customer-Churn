{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58b5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify\n",
    "from flask_cors import CORS\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(lgr, xgb, rf, train_data, test_data):\n",
    "    # Filter the existing active customers from the train_data\n",
    "    train_drop_index = train_data[train_data['Lifecycle'] in ('Dormant', 'Churned')].index\n",
    "    train_active = train_data.drop(train_drop_index)\n",
    "    \n",
    "    # Generate predictions for train_active (This train data only consists of existing active customers)\n",
    "    train_active_prediction = prediction(lgr, xgb, rf, train_active)\n",
    "    \n",
    "    # Generate predictions for test_data \n",
    "    # This test data consists of both active and churned customers to generate classification report for model performance evaluation\n",
    "    test_prediction = prediction(lgr, xgb, rf, test_data)\n",
    "    \n",
    "    # Generate classification report using the test predictions\n",
    "    report = classification_report(test_prediction['Lifecycle'], test_prediction['Predicted_Lifecycle'])\n",
    "    \n",
    "    # Filter out the existing active customers from the test data\n",
    "    test_drop_index = test_prediction[test_prediction['Lifecycle'] in ('Dormant', 'Churned')].index\n",
    "    test_active_prediction = test_prediction.drop(test_drop_index)\n",
    "    \n",
    "    # Concat the train_active_prediction and test_active_prediction data\n",
    "    predicted_data = pd.concat([train_active_prediction, test_active_prediction], ignore_index=True)\n",
    "    \n",
    "    # Discuss with frontend on how they want to receive the classification report and predicted data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb586f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(lgr, xgb, rf, data):\n",
    "    # Feature Extraction for data\n",
    "    features = data[data.columns not in ('Lifecycle')] #Add in columns to exclude accordingly\n",
    "    \n",
    "    # Generate predictions for data\n",
    "    for i in range(len(lgr)):\n",
    "        # lgr[0], xgb[0], rf[0] is the model with binary label Active/Non-Active\n",
    "        if i == 0:\n",
    "            data['lgr_Active_proba'] = lgr[0].predict_proba(features)\n",
    "            data['xgb_Active_proba'] = xgb[0].predict_proba(features)\n",
    "            data['rf_Active_proba'] = rf[0].predict_proba(features)\n",
    "            \n",
    "        # lgr[1], xgb[1], rf[1] is the model with binary label Reactivated/Non-Reactivated\n",
    "        elif i == 1:\n",
    "            data['lgr_Reactivated_proba'] = lgr[1].predict_proba(features)\n",
    "            data['xgb_Reactivated_proba'] = xgb[1].predict_proba(features)\n",
    "            data['rf_Reactivated_proba'] = rf[1].predict_proba(features)\n",
    "            \n",
    "        # lgr[2], xgb[2], rf[2] is the model with binary label Dormant/Non-Dormant\n",
    "        elif i == 2:\n",
    "            data['lgr_Dormant_proba'] = lgr[2].predict_proba(features)\n",
    "            data['xgb_Dormant_proba'] = xgb[2].predict_proba(features)\n",
    "            data['rf_Dormant_proba'] = rf[2].predict_proba(features)\n",
    "           \n",
    "        # lgr[3], xgb[3], rf[3] is the model with binary label Churned/Non-Churned\n",
    "        elif i == 3:\n",
    "            data['lgr_Churned_proba'] = lgr[3].predict_proba(features)\n",
    "            data['xgb_Churned_proba'] = xgb[3].predict_proba(features)\n",
    "            data['rf_Churned_proba'] = rf[3].predict_proba(features)\n",
    "    \n",
    "    # Calculate the average probability from the probabilities generated by each model (Ensemble Learning)\n",
    "    data['average_Active_proba'] = data[['lgr_Active_proba', 'xgb_Active_proba', 'rf_Active_proba']].agg(mean, axis = 1)\n",
    "    data['average_Reactivated_proba'] = data[['lgr_Reactivated_proba', 'xgb_Reactivated_proba', 'rf_Reactivated_proba']].agg(mean, axis = 1)\n",
    "    data['average_Dormant_proba'] = data[['lgr_Dormant_proba', 'xgb_Dormant_proba', 'rf_Dormant_proba']].agg(mean, axis = 1)\n",
    "    data['average_Churned_proba'] = data[['lgr_Churned_proba', 'xgb_Churned_proba', 'rf_Churned_proba']].agg(mean, axis = 1)\n",
    "    \n",
    "    # Based on the definition of lifecycle, it is not possible for a customer to have the below stated transitions\n",
    "    # Active -> Reactivated, Dormant -> Dormant, Dormant -> Active, Reactivated -> Reactivated\n",
    "    # Hence, set the probabilities of these cases to 0\n",
    "    data['average_Active_proba'] = np.where((data['Lifecycle'] == 'Dormant') & (data['average_Active_proba'] > 0), 0, data['average_Active_proba'])\n",
    "    data['average_Reactivated_proba'] = np.where((data['Lifecycle'] in ('Active', 'Reactivated')) & (data['average_Reactivated_proba'] > 0), 0, data['average_Reactivated_proba'])\n",
    "    data['average_Dormant_proba'] = np.where((data['Lifecycle'] == 'Dormant') & (data['average_Dormant_proba'] > 0), 0, data['average_Dormant_proba'])\n",
    "    \n",
    "    # The lifecycle with the highest probability will be the predicted lifecycle\n",
    "    max_proba = data[['average_Active_proba', 'average_Reactivated_proba', 'average_Dormant_proba', 'average_Churned_proba']].agg(max, axis = 1)\n",
    "    data['Predicted_Lifecycle'] = np.where(data['average_Active_proba'] == max_proba, 'Active', \\\n",
    "                                         +np.where(data['average_Reactivated_proba'] == max_proba, 'Reactivated', \\\n",
    "                                         +np.where(data['average_Dormant_proba'] == max_proba, 'Dormant', \\\n",
    "                                         +np.where(data['average_Churned_proba'] == max_proba, 'Churned'))))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60364b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(name)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/api/data')\n",
    "def get_data():\n",
    "    # Your code to fetch and process data from the desired source\n",
    "    # For simplicity, let's assume dummy data\n",
    "    data = test()\n",
    "    return jsonify(data)\n",
    "\n",
    "if name == 'main':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
