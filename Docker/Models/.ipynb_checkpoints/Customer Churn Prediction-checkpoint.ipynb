{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58b5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from flask import Flask, jsonify\n",
    "from flask_cors import CORS\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import xgboost as XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cb7fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}, {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}, {'C': 1000, 'penalty': 'l2', 'solver': 'liblinear'}, {'C': 1000, 'penalty': 'l2', 'solver': 'liblinear'}], [{'booster': 'gbtree', 'learning_rate': 0.05, 'n_estimators': 100, 'objective': 'multi:softmax', 'eval_metric': 'logloss', 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1.0, 'colsample_bytree': 1.0, 'lambda': None, 'alpha': None, 'num_class': 2}, {'booster': 'gbtree', 'learning_rate': 0.05, 'n_estimators': 100, 'objective': 'multi:softmax', 'eval_metric': 'logloss', 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1.0, 'colsample_bytree': 1.0, 'lambda': None, 'alpha': None, 'num_class': 2}, {'booster': 'gbtree', 'learning_rate': 0.05, 'n_estimators': 100, 'objective': 'multi:softmax', 'eval_metric': 'logloss', 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1.0, 'colsample_bytree': 1.0, 'lambda': None, 'alpha': None, 'num_class': 2}, {'booster': 'gbtree', 'learning_rate': 0.05, 'n_estimators': 100, 'objective': 'multi:softmax', 'eval_metric': 'logloss', 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0, 'subsample': 1.0, 'colsample_bytree': 1.0, 'lambda': None, 'alpha': None, 'num_class': 2}], [{'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}, {'n_estimators': 100, 'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 2}, {'n_estimators': 100, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}, {'n_estimators': 100, 'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}]]\n"
     ]
    }
   ],
   "source": [
    "# Read in the tuned hyperparameters\n",
    "try:\n",
    "    # Open the JSON file\n",
    "    with open('Models.json', 'r') as file:\n",
    "        # Load the models\n",
    "        models = json.load(file)\n",
    "    # File is successfully opened and loaded\n",
    "    print(models)\n",
    "except FileNotFoundError:\n",
    "    # Handle the FileNotFoundError\n",
    "    print(\"The file 'Models.json' does not exist or cannot be opened.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93cd118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CustomerID', 'Gender', 'ChurnDate', 'FirstPersona', 'SecondPersona', 'ThirdPersona', 'CombinedPersonas', 'CurrLifecycle', 'SocialInfluencer', 'CurrLifecycle_Active', 'CurrLifecycle_Reactivated', 'CurrLifecycle_Churned', 'CurrLifecycle_Dormant', 'PrevLifecycle_Active', 'PrevLifecycle_Churned', 'PrevLifecycle_Dormant', 'PrevLifecycle_Reactivated', 'PrevLifecycle', 'CustomerId']\n"
     ]
    }
   ],
   "source": [
    "# Read in the list of columns that were not used to train\n",
    "try:\n",
    "    # Open the JSON file\n",
    "    with open('FeatureDropped.json', 'r') as file:\n",
    "        # Load the models\n",
    "        features_dropped = json.load(file)\n",
    "    # File is successfully opened and loaded\n",
    "    print(features_dropped)\n",
    "except FileNotFoundError:\n",
    "    # Handle the FileNotFoundError\n",
    "    print(\"The file 'FeatureDropped.json' does not exist or cannot be opened.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57251247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the train and test data which are the original customer base split into train and test\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "input_features = [column for column in train_data.columns if column not in features_dropped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3930e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "train_data_encoded = train_data.copy()\n",
    "test_data_encoded = test_data.copy()\n",
    "\n",
    "train_data_encoded['MonthsInactive'] = train_data_encoded['MonthsInactive'].fillna(0)\n",
    "test_data_encoded['MonthsInactive'] = test_data_encoded['MonthsInactive'].fillna(0)\n",
    "\n",
    "for column in train_data_encoded.columns:\n",
    "    if train_data_encoded[column].dtype == 'object':\n",
    "        train_data_encoded[column] = label_encoder.fit_transform(train_data_encoded[column])\n",
    "        test_data_encoded[column] = label_encoder.fit_transform(test_data_encoded[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "053de666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data sets to do encoding and scaling for logistic regression\n",
    "train_lgr = train_data_encoded.copy()\n",
    "test_lgr = test_data_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba60a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset (except for the labels) for logistic regression\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_lgr_features = train_lgr[input_features]\n",
    "train_lgr_features = pd.DataFrame(scaler.fit_transform(train_lgr_features), columns = train_lgr_features.columns)\n",
    "\n",
    "test_lgr_features = test_lgr[input_features]\n",
    "test_lgr_features = pd.DataFrame(scaler.fit_transform(test_lgr_features), columns = test_lgr_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d8ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the lgr, xgb, and rf parameters into\n",
    "# a list of 4 dictionaries with key value pairs of hyperparamters for Active, Reactivated, Dormant, and Churned Classification\n",
    "lgr = models[0]\n",
    "xgb = models[1]\n",
    "rf = models[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717114d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all_lgr = [train_lgr['CurrLifecycle_Active'], train_lgr['CurrLifecycle_Reactivated'], train_lgr['CurrLifecycle_Dormant'], train_lgr['CurrLifecycle_Churned']]\n",
    "\n",
    "y_train_all = [train_data_encoded['CurrLifecycle_Active'], train_data_encoded['CurrLifecycle_Reactivated'], train_data_encoded['CurrLifecycle_Dormant'], train_data_encoded['CurrLifecycle_Churned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1426ce-d291-4fb7-8b28-d2e3dd306348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr_models_list = []\n",
    "xgb_models_list = []\n",
    "rf_models_list = []\n",
    "for i in range(4):\n",
    "    # Train the lgr models and store in the list\n",
    "    lgr_model = LogisticRegression(**lgr[i])\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(train_lgr_features, y_train_all_lgr[i])\n",
    "    lgr_model.fit(X_train_resampled, y_train_resampled)\n",
    "    lgr_models_list.append(lgr_model)\n",
    "    \n",
    "    # Train the xgb models and store in the list\n",
    "    xgb_model = XGB.XGBClassifier(**xgb[i])\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(train_data_encoded[input_features], y_train_all[i])\n",
    "    xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "    xgb_models_list.append(xgb_model)\n",
    "    \n",
    "    # Train the rf models and store in the list\n",
    "    rf_model = RandomForestClassifier(**rf[i])\n",
    "    rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "    rf_models_list.append(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb586f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to generate predictions from the trained models\n",
    "def prediction(lgr, xgb, rf, data, features):\n",
    "    # Generate predictions for data\n",
    "    for i in range(len(lgr)):\n",
    "        # lgr[0], xgb[0], rf[0] is the model with binary label Active/Non-Active\n",
    "        if i == 0:\n",
    "            data['lgr_Active_proba'] = lgr[0].predict_proba(data[features])[:, 1]\n",
    "            data['xgb_Active_proba'] = xgb[0].predict_proba(data[features])[:, 1]\n",
    "            data['rf_Active_proba'] = rf[0].predict_proba(data[features])[:, 1]\n",
    "            \n",
    "        # lgr[1], xgb[1], rf[1] is the model with binary label Reactivated/Non-Reactivated\n",
    "        elif i == 1:\n",
    "            data['lgr_Reactivated_proba'] = lgr[1].predict_proba(data[features])[:, 1]\n",
    "            data['xgb_Reactivated_proba'] = xgb[1].predict_proba(data[features])[:, 1]\n",
    "            data['rf_Reactivated_proba'] = rf[1].predict_proba(data[features])[:, 1]\n",
    "            \n",
    "        # lgr[2], xgb[2], rf[2] is the model with binary label Dormant/Non-Dormant\n",
    "        elif i == 2:\n",
    "            data['lgr_Dormant_proba'] = lgr[2].predict_proba(data[features])[:, 1]\n",
    "            data['xgb_Dormant_proba'] = xgb[2].predict_proba(data[features])[:, 1]\n",
    "            data['rf_Dormant_proba'] = rf[2].predict_proba(data[features])[:, 1]\n",
    "           \n",
    "        # lgr[3], xgb[3], rf[3] is the model with binary label Churned/Non-Churned\n",
    "        elif i == 3:\n",
    "            data['lgr_Churned_proba'] = lgr[3].predict_proba(data[features])[:, 1]\n",
    "            data['xgb_Churned_proba'] = xgb[3].predict_proba(data[features])[:, 1]\n",
    "            data['rf_Churned_proba'] = rf[3].predict_proba(data[features])[:, 1]\n",
    "    \n",
    "    # Calculate the average probability from the probabilities generated by each model (Ensemble Learning)\n",
    "    data['average_Active_proba'] = data[['lgr_Active_proba', 'xgb_Active_proba', 'rf_Active_proba']].mean(axis = 1)\n",
    "    data['average_Reactivated_proba'] = data[['lgr_Reactivated_proba', 'xgb_Reactivated_proba', 'rf_Reactivated_proba']].mean(axis = 1)\n",
    "    data['average_Dormant_proba'] = data[['lgr_Dormant_proba', 'xgb_Dormant_proba', 'rf_Dormant_proba']].mean(axis = 1)\n",
    "    data['average_Churned_proba'] = data[['lgr_Churned_proba', 'xgb_Churned_proba', 'rf_Churned_proba']].mean(axis = 1)\n",
    "    \n",
    "    # Based on the definition of lifecycle, it is not possible for a customer to have the below stated transitions\n",
    "    # Active -> Reactivated, Dormant -> Dormant, Dormant -> Active, Reactivated -> Reactivated\n",
    "    # Hence, set the probabilities of these cases to 0\n",
    "    data['average_Active_proba'] = np.where((data['CurrLifecycle_Dormant'] == 1) & (data['average_Active_proba'] > 0), 0, data['average_Active_proba'])\n",
    "    data['average_Reactivated_proba'] = np.where(((data['CurrLifecycle_Active'] == 1) | (data['CurrLifecycle_Reactivated'] == 1)) & (data['average_Reactivated_proba'] > 0), 0, data['average_Reactivated_proba'])\n",
    "    data['average_Dormant_proba'] = np.where((data['CurrLifecycle_Dormant'] == 1) & (data['average_Dormant_proba'] > 0), 0, data['average_Dormant_proba'])\n",
    "    \n",
    "    # Normalize the probablities such that each row adds up to 1\n",
    "    total_prob = data[['average_Active_proba', 'average_Reactivated_proba', 'average_Dormant_proba', 'average_Churned_proba']].sum(axis=1)\n",
    "    data['average_Active_proba'] = data['average_Active_proba'] / total_prob\n",
    "    data['average_Reactivated_proba'] = data['average_Reactivated_proba'] / total_prob\n",
    "    data['average_Dormant_proba'] = data['average_Dormant_proba'] / total_prob\n",
    "    data['average_Churned_proba'] = data['average_Churned_proba'] / total_prob\n",
    "    \n",
    "    # Rename the probabilities column\n",
    "    data['Active'] = data['average_Active_proba']\n",
    "    data['Reactivated'] = data['average_Reactivated_proba']\n",
    "    data['Dormant'] = data['average_Dormant_proba']\n",
    "    data['Churned'] = data['average_Churned_proba']\n",
    "    \n",
    "    # The lifecycle with the highest probability will be the predicted lifecycle\n",
    "    data['PredictedLifecycle'] = data[['Active', 'Reactivated', 'Dormant', 'Churned']].idxmax(axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the existing active customers from the train_data\n",
    "train_active = train_data_encoded[train_data_encoded['CurrLifecycle_Churned'] != 1].copy()\n",
    "\n",
    "# Returns the df with predictions for train_active (This train data only consists of existing active customers)\n",
    "# Note: train_active_prediction is the encoded dataframe\n",
    "train_active_prediction = prediction(lgr_models_list, xgb_models_list, rf_models_list, train_active, input_features)\n",
    "\n",
    "# Returns the df with predictions for test_data \n",
    "# This test data consists of both active and churned customers to generate classification report for model performance evaluation\n",
    "# Note: test_prediction is the encoded dataframe\n",
    "test_prediction = prediction(lgr_models_list, xgb_models_list, rf_models_list, test_data_encoded, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bf321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the probabilities and predicted Lifecycle columns to the non-encoded dataframe\n",
    "train_data = pd.concat([train_data, train_active_prediction.loc[:, 'average_Active_proba':'average_Churned_proba'], train_active_prediction['PredictedLifecycle']], axis=1)\n",
    "test_data = pd.concat([test_data, test_prediction.loc[:, 'average_Active_proba':'average_Churned_proba'], test_prediction['PredictedLifecycle']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccceab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the Predicted Lifecycles\n",
    "test_data['PredLifecycle_Active'] = (test_data['PredictedLifecycle'] == 'Active').astype(int)\n",
    "test_data['PredLifecycle_Reactivated'] = (test_data['PredictedLifecycle'] == 'Reactivated').astype(int)\n",
    "test_data['PredLifecycle_Dormant'] = (test_data['PredictedLifecycle'] == 'Dormant').astype(int)\n",
    "test_data['PredLifecycle_Churned'] = (test_data['PredictedLifecycle'] == 'Churned').astype(int)\n",
    "\n",
    "train_data['PredLifecycle_Active'] = (train_data['PredictedLifecycle'] == 'Active').astype(int)\n",
    "train_data['PredLifecycle_Reactivated'] = (train_data['PredictedLifecycle'] == 'Reactivated').astype(int)\n",
    "train_data['PredLifecycle_Dormant'] = (train_data['PredictedLifecycle'] == 'Dormant').astype(int)\n",
    "train_data['PredLifecycle_Churned'] = (train_data['PredictedLifecycle'] == 'Churned').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e07c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for Active/Non-Active\n",
    "report_table_Active = classification_report(test_data['CurrLifecycle_Active'], test_data['PredLifecycle_Active'])\n",
    "report_table_Active_dict = classification_report(test_data['CurrLifecycle_Active'], test_data['PredLifecycle_Active'], output_dict=True)\n",
    "print(report_table_Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1198940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for Reactivated/Non-Reactivated\n",
    "report_table_Reactivated = classification_report(test_data['CurrLifecycle_Reactivated'], test_data['PredLifecycle_Reactivated'])\n",
    "report_table_Reactivated_dict = classification_report(test_data['CurrLifecycle_Reactivated'], test_data['PredLifecycle_Reactivated'], output_dict=True)\n",
    "print(report_table_Reactivated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for Dormant/Non-Dormant\n",
    "report_table_Dormant = classification_report(test_data['CurrLifecycle_Dormant'], test_data['PredLifecycle_Dormant'], zero_division=0)\n",
    "report_table_Dormant_dict = classification_report(test_data['CurrLifecycle_Dormant'], test_data['PredLifecycle_Dormant'], zero_division=0, output_dict=True)\n",
    "print(report_table_Dormant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc0ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report for Churned/Non-Churned\n",
    "report_table_Churned = classification_report(test_data['CurrLifecycle_Churned'], test_data['PredLifecycle_Churned'])\n",
    "report_table_Churned_dict = classification_report(test_data['CurrLifecycle_Churned'], test_data['PredLifecycle_Churned'], output_dict=True)\n",
    "print(report_table_Churned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average of the reports\n",
    "report_lst = [report_table_Active_dict, report_table_Reactivated_dict, report_table_Dormant_dict, report_table_Churned_dict]\n",
    "report_dict = {'0': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}, \n",
    "              '1': {'precision': [], 'recall': [], 'f1-score': [], 'support': []},\n",
    "              'accuracy': [],\n",
    "              'macro avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []},\n",
    "              'weighted avg': {'precision': [], 'recall': [], 'f1-score': [], 'support': []}}\n",
    "\n",
    "for report in report_lst:\n",
    "    for key1, pair1 in report.items():\n",
    "        if key1=='accuracy':\n",
    "            report_dict['accuracy'].append(pair1)\n",
    "        else:\n",
    "            for key2, pair2 in pair1.items():\n",
    "                report_dict[key1][key2].append(pair2)\n",
    "                \n",
    "for report in report_lst:\n",
    "    for key1, pair1 in report.items():\n",
    "        if key1=='accuracy':\n",
    "            report_dict[key1] = round(np.mean(report_dict[key1]), 2)\n",
    "        else:\n",
    "            for key2, pair2 in pair1.items():\n",
    "                report_dict[key1][key2] = round(np.mean(report_dict[key1][key2]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58627885",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288bd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification report as json\n",
    "json_data = json.dumps(report_dict)\n",
    "\n",
    "with open(\"Report_Dict.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the train_data and test_data data\n",
    "predicted_data = pd.concat([train_data, test_data], ignore_index=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a39a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b06673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as csv for the API file to read\n",
    "predicted_data.to_csv(\"Predicted_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
