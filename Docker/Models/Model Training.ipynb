{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45dc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import xgboost as xgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05dc1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the train and test data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1158f5-03a4-4ad9-a7ba-96d259a1458b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the proportion of lifecycle\n",
    "print(\"Total =\", len(train_data), '\\n')\n",
    "\n",
    "print(\"Churned =\", len(train_data[train_data['CurrLifecycle_Churned'] == 1]))\n",
    "print(\"Not churn =\", len(train_data[train_data['CurrLifecycle_Churned'] == 0]))\n",
    "print(\"Churn percentage =\", (len(train_data[train_data['CurrLifecycle_Churned'] == 1])/len(train_data))*100, '\\n')\n",
    "\n",
    "print(\"Active =\", len(train_data[train_data['CurrLifecycle_Active'] == 1]))\n",
    "print(\"Not active =\", len(train_data[train_data['CurrLifecycle_Active'] == 0]))\n",
    "print(\"Active percentage =\", (len(train_data[train_data['CurrLifecycle_Active'] == 1])/len(train_data))*100, '\\n')\n",
    "\n",
    "print(\"Reactivated =\", len(train_data[train_data['CurrLifecycle_Reactivated'] == 1]))\n",
    "print(\"Not Reactivated =\", len(train_data[train_data['CurrLifecycle_Reactivated'] == 0]))\n",
    "print(\"Reactivated percentage =\", (len(train_data[train_data['CurrLifecycle_Reactivated'] == 1])/len(train_data))*100, '\\n')\n",
    "\n",
    "print(\"Dormant =\", len(train_data[train_data['CurrLifecycle_Dormant'] == 1]))\n",
    "print(\"Not Dormant =\", len(train_data[train_data['CurrLifecycle_Dormant'] == 0]))\n",
    "print(\"Dormant percentage =\", (len(train_data[train_data['CurrLifecycle_Dormant'] == 1])/len(train_data))*100, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a82b0-1433-4829-a914-da6e0749451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = raw_train.columns\n",
    "X = raw_train[cols[3:-1]].drop(columns=['Gender', 'Geography'])\n",
    "y = raw_train[\n",
    "[cols[-1]]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE TO PREPROCESS THE DATASET\n",
    "\n",
    "cols = raw_train.columns\n",
    "#X = raw_train.iloc[:,3:].drop(columns=['Gender', 'Geography'])\n",
    "X = raw_train.drop(columns=['Gender', 'ChurnDate', 'FirstPersona', 'SecondPersona', 'ThirdPersona', 'CombinedPersonas', 'SocialInfluencer'])\n",
    "X['Active'] = (X['CurrLifecycle'] == 'Active').astype(int)\n",
    "X['Reactivated'] = (X['CurrLifecycle'] == 'Reactivated').astype(int)\n",
    "X['Dormant'] = (X['CurrLifecycle'] == 'Dormant').astype(int)\n",
    "X['Churned'] = (X['CurrLifecycle'] == 'Churned').astype(int)\n",
    "\n",
    "strat = raw_train['CurrLifecycle']\n",
    "all_train, all_test, strat_train, strat_test = train_test_split(X, strat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527da9d-0198-4547-b177-66b594943a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = [all_train['Active'], all_train['Reactivated'], all_train['Dormant'], all_train['Churned']]\n",
    "y_test_all = [all_test['Active'], all_test['Reactivated'], all_test['Dormant'], all_test['Churned']]\n",
    "X_train = all_train.drop(columns=['Active', 'Reactivated', 'Dormant', 'Churned'])\n",
    "X_test = all_test.drop(columns=['Active', 'Reactivated', 'Dormant', 'Churned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c2dd4-efd2-4153-a9c0-3dccb7090a2f",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa5c48-113c-4d2e-a4cb-723e7df3abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dropped = ['CustomerID', 'Gender', 'ChurnDate', 'FirstPersona', 'SecondPersona', 'ThirdPersona', 'CombinedPersonas', \n",
    "                   'CurrLifecycle', 'SocialInfluencer', \n",
    "                   'CurrLifecycle_Active', 'CurrLifecycle_Reactivated', 'CurrLifecycle_Churned', 'CurrLifecycle_Dormant', \n",
    "                   'PrevLifecycle_Active', 'PrevLifecycle_Churned', 'PrevLifecycle_Dormant', 'PrevLifecycle_Reactivated',\n",
    "                   'PrevLifecycle', 'CustomerId']\n",
    "\n",
    "input_features = [column for column in train_data.columns if column not in features_dropped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab50749a-b174-4b92-8e9c-360c8eeafb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['MonthsInactive'] = train_data['MonthsInactive'].fillna(0)\n",
    "test_data['MonthsInactive'] = test_data['MonthsInactive'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5449f8-51d5-4561-9a1d-43671ccd1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables for logistic regression\n",
    "label_encoder = LabelEncoder()\n",
    "train_data_encoded = train_data.copy()\n",
    "test_data_encoded = test_data.copy()\n",
    "\n",
    "for column in train_data_encoded.columns:\n",
    "    if train_data_encoded[column].dtype == 'object':\n",
    "        train_data_encoded[column] = label_encoder.fit_transform(train_data_encoded[column])\n",
    "        test_data_encoded[column] = label_encoder.fit_transform(test_data_encoded[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f539e4-0125-43fc-8e61-96c7ea380f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data sets to do encoding and scaling for logistic regression\n",
    "train_lgr = train_data_encoded.copy()\n",
    "test_lgr = test_data_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1bc35-7276-4bef-99dd-c1814e1901e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset (except for the labels) for logistic regression\n",
    "scaler = StandardScaler()\n",
    "\n",
    "label_columns = ['CurrLifecycle_Active', 'CurrLifecycle_Reactivated', 'CurrLifecycle_Dormant', 'CurrLifecycle_Churned']\n",
    "feature_columns = [column for column in train_lgr.columns if column not in label_columns]\n",
    "\n",
    "train_lgr_features = train_lgr[feature_columns]\n",
    "train_lgr_labels = train_lgr[label_columns]\n",
    "\n",
    "train_lgr_features = pd.DataFrame(scaler.fit_transform(train_lgr_features), columns = train_lgr_features.columns)\n",
    "train_lgr = pd.concat([train_lgr_features, train_lgr_labels], axis = 1)\n",
    "\n",
    "test_lgr_features = test_lgr[feature_columns]\n",
    "test_lgr_labels = test_lgr[label_columns]\n",
    "\n",
    "test_lgr_features = pd.DataFrame(scaler.transform(test_lgr_features), columns = test_lgr_features.columns)\n",
    "test_lgr = pd.concat([test_lgr_features, test_lgr_labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c009ca-15c5-4c45-8221-8ddd200dde33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all_lgr = [train_lgr['CurrLifecycle_Active'], train_lgr['CurrLifecycle_Reactivated'], train_lgr['CurrLifecycle_Dormant'], train_lgr['CurrLifecycle_Churned']]\n",
    "y_test_all_lgr = [test_lgr['CurrLifecycle_Active'], test_lgr['CurrLifecycle_Reactivated'], test_lgr['CurrLifecycle_Dormant'], test_lgr['CurrLifecycle_Churned']]\n",
    "\n",
    "y_train_all = [train_data_encoded['CurrLifecycle_Active'], train_data_encoded['CurrLifecycle_Reactivated'], train_data_encoded['CurrLifecycle_Dormant'], train_data_encoded['CurrLifecycle_Churned']]\n",
    "y_test_all = [test_data_encoded['CurrLifecycle_Active'], test_data_encoded['CurrLifecycle_Reactivated'], test_data_encoded['CurrLifecycle_Dormant'], test_data_encoded['CurrLifecycle_Churned']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d80892",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b0842-0a13-40ae-8290-2a6de236b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to ignore the DataConversionWarning\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c91119",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e391fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "lr_param_dist = {\n",
    "    'penalty': ['l1', 'l2'],  \n",
    "    #'C' : np.logspace(-4, 4, 20),\n",
    "    'C': [0.1, 1, 10, 100, 1000],  \n",
    "    'solver': ['liblinear', 'saga'] \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1402f-0a6e-4e3a-80a9-8cc37762efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = []\n",
    "lr_results = []\n",
    "\n",
    "for i in range(4):\n",
    "    lr_model = LogisticRegression()\n",
    "    search_lr = RandomizedSearchCV(lr_model, param_distributions=lr_param_dist, n_iter=5, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "    search_lr.fit(train_lgr[input_features], y_train_all_lgr[i])\n",
    "\n",
    "    best_model_lr = search_lr.best_estimator_\n",
    "    lr_models.append(best_model_lr)\n",
    "    \n",
    "    test_score_lr = best_model_lr.score(test_lgr[input_features], y_test_all_lgr[i])\n",
    "    lr_results.append(test_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b265bd94",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c64141-910c-4b8d-aba0-4de956c26778",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372aa2d6-d35b-4910-ad5b-bea4c623a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost parameter ranges\n",
    "xgb_param_dist = {\n",
    "    'booster': ['gbtree'],  \n",
    "    'learning_rate': np.linspace(0.05, 0.3, 6),  \n",
    "    'n_estimators': [100, 200],  \n",
    "    'objective': ['multi:softmax'],  \n",
    "    'num_class': [2],  \n",
    "    'eval_metric': ['logloss'],  \n",
    "    'max_depth': [3, 6, 9],  \n",
    "    'min_child_weight': [1, 5, 10],  \n",
    "    'gamma': [0, 0.1, 0.2],  \n",
    "    'subsample': [0.6, 0.8, 1.0],  \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  \n",
    "    'lambda': [0, 1, 2],  \n",
    "    'alpha': [0, 1, 2]  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b015ce-12e7-46ab-9193-72dfefa29f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_models = []\n",
    "xgb_results = []\n",
    "\n",
    "for i in range(4):\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    xgb_search = RandomizedSearchCV(xgb_model, param_distributions=xgb_param_dist, n_iter=10, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "    xgb_search.fit(train_data_encoded[input_features], y_train_all[i])\n",
    "\n",
    "    best_model_xgb = xgb_search.best_estimator_\n",
    "    xgb_models.append(best_model_xgb)\n",
    "    \n",
    "    test_score_xgb = best_model_xgb.score(test_data_encoded[input_features], y_test_all[i])\n",
    "    xgb_results.append(test_score_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da350fc-35e4-40ac-a43f-03effc023293",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {'booster': 'gbtree',\n",
    "   'learning_rate': 0.05,\n",
    "   'n_estimators': 100,\n",
    "   'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "   'eval_metric': 'logloss',\n",
    "   'max_depth': 3,\n",
    "   'min_child_weight': 1,\n",
    "   'gamma': 0,\n",
    "   'subsample': 1.0,\n",
    "   'colsample_bytree': 1.0,\n",
    "   'lambda': None,\n",
    "   'alpha': None}\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(train_data_encoded[input_features], y_train_all[3])\n",
    "score = model.score(test_data_encoded[input_features], y_test_all[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffac9f0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ef173",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_dist = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': [None] + list(range(5, 11, 5)),\n",
    "    'min_samples_leaf': [1, 5],\n",
    "    'min_samples_split': [2, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d0e8c-1b23-4830-b824-c4d8db255d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models = []\n",
    "rf_results = []\n",
    "\n",
    "for i in range(4):\n",
    "    rf_model = RandomForestClassifier()\n",
    "    search_rf = RandomizedSearchCV(rf_model, param_distributions=rf_param_dist, n_iter=5, scoring='f1_weighted', cv=5, random_state=42)\n",
    "\n",
    "    search_rf.fit(train_data_encoded[input_features], y_train_all[i])\n",
    "\n",
    "    best_model_rf = search_rf.best_estimator_\n",
    "    #best_model_rf = rf_model.fit(train_data_encoded[input_features], y_train_all[i])\n",
    "    rf_models.append(best_model_rf)\n",
    "    \n",
    "    test_score_rf = best_model_rf.score(test_data_encoded[input_features], y_test_all[i])\n",
    "    rf_results.append(test_score_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a376ce-13be-4da1-b99d-d1ed39575f04",
   "metadata": {},
   "source": [
    "## Saving the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888076b-e343-46c2-bf64-f6311766ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_dicts = []\n",
    "for model in lr_models:\n",
    "    model_dict = {\n",
    "        \"C\": model.C,\n",
    "        \"penalty\": model.penalty,\n",
    "        \"solver\": model.solver\n",
    "        # Add more attributes as needed\n",
    "    }\n",
    "    lr_model_dicts.append(model_dict)\n",
    "\n",
    "rf_model_dicts = []\n",
    "for model in rf_models:\n",
    "    model_dict = {\n",
    "        'n_estimators': model.n_estimators,\n",
    "        'criterion': model.criterion,\n",
    "        'max_depth': model.max_depth,\n",
    "        'min_samples_leaf': model.min_samples_leaf,\n",
    "        #'max_features': model.max_features,\n",
    "        'min_samples_split': model.min_samples_split\n",
    "    }\n",
    "    rf_model_dicts.append(model_dict)\n",
    "\n",
    "xgb_model_dicts = []\n",
    "for model in xgb_models:\n",
    "    model_dict = {\n",
    "        'booster': model.booster,  \n",
    "        'learning_rate': model.learning_rate,  \n",
    "        'n_estimators': model.n_estimators,  \n",
    "        'objective': model.objective,  \n",
    "        #'objective': 'binary:logistic',\n",
    "        'eval_metric': model.eval_metric,  \n",
    "        'max_depth': model.max_depth,  \n",
    "        'min_child_weight': model.min_child_weight,  \n",
    "        'gamma': model.gamma,  \n",
    "        'subsample': model.subsample,  \n",
    "        'colsample_bytree': model.colsample_bytree,  \n",
    "        'lambda': getattr(model, 'lambda', None),  # Access lambda attribute using getattr()\n",
    "        'alpha': getattr(model, 'alpha', None),\n",
    "        'num_class': 2\n",
    "    }\n",
    "    xgb_model_dicts.append(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c28a6e-649c-4c3f-82c4-3621fb4c9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_model_dicts, xgb_model_dicts, rf_model_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb8121-6513-480c-b6e4-eda41521c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lr_model_dicts, xgb_model_dicts, rf_model_dicts]\n",
    "\n",
    "\n",
    "# Convert the list to JSON\n",
    "json_data = json.dumps(models, indent=4)\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(\"Models.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54a5cd-b0bf-4848-89f0-904ffe2df162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dropped features to JSON\n",
    "json_data = json.dumps(features_dropped)\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(\"FeatureDropped.json\", \"w\") as json_file:\n",
    "    json_file.write(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
